# ğŸ” Fraud Detection Data Pipeline

> Pipeline de detecÃ§Ã£o de fraudes bancÃ¡rias usando arquitetura Medallion com Apache Spark

[![Spark](https://img.shields.io/badge/Apache%20Spark-4.0.1-E25A1C?logo=apachespark&logoColor=white)](https://spark.apache.org/)
[![Python](https://img.shields.io/badge/Python-3.13-3776AB?logo=python&logoColor=white)](https://python.org/)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?logo=docker&logoColor=white)](https://docker.com/)
[![Status](https://img.shields.io/badge/Status-Em%20Desenvolvimento-yellow)](https://github.com/afborda/spark-medallion-fraud-detection)

---

## ğŸ“‹ Sobre o Projeto

Este projeto implementa um **pipeline de dados** para detecÃ§Ã£o de fraudes em transaÃ§Ãµes bancÃ¡rias, utilizando a arquitetura **Medallion** (Bronze â†’ Silver â†’ Gold) com processamento distribuÃ­do via Apache Spark.

### ğŸ¯ Objetivos

- Processar transaÃ§Ãµes bancÃ¡rias em larga escala
- Identificar padrÃµes de fraude atravÃ©s de regras de negÃ³cio
- Implementar arquitetura de dados moderna e escalÃ¡vel
- Preparar dados para anÃ¡lise e machine learning

---

## ğŸ—ï¸ Arquitetura

### Arquitetura Atual (Batch)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ARQUITETURA MEDALLION                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   ğŸ“¥ RAW          ğŸ”¶ BRONZE        âšª SILVER        ğŸ¥‡ GOLD     â”‚
â”‚   â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€        â”‚
â”‚   JSON           Parquet         Parquet         Parquet       â”‚
â”‚   (origem)       (bruto)         (limpo)         (agregado)    â”‚
â”‚                                                                 â”‚
â”‚   customers  â”€â”€â–º customers   â”€â”€â–º customers   â”€â”€â–º customer_     â”‚
â”‚   .json          /               /               summary/      â”‚
â”‚                                                                 â”‚
â”‚   transactionsâ”€â”€â–º transactionsâ”€â”€â–º transactionsâ”€â”€â–º fraud_       â”‚
â”‚   .json          /               /               detection/    â”‚
â”‚                                                  (partitioned) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Arquitetura Objetivo (Streaming + Lakehouse)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        LAKEHOUSE ARCHITECTURE                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ ShadowTrafficâ”‚â”€â”€â”€â–ºâ”‚  Kafka  â”‚â”€â”€â”€â–ºâ”‚ Spark Streaming â”‚â”€â”€â”€â–ºâ”‚ MinIO Lake  â”‚ â”‚
â”‚  â”‚  (Generator) â”‚    â”‚ Topics  â”‚    â”‚   ETL Jobs      â”‚    â”‚ Bronze/     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚customersâ”‚    â”‚                 â”‚    â”‚ Silver/Gold â”‚ â”‚
â”‚                      â”‚ orders  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚                    â”‚        â”‚
â”‚                                              â”‚                    â–¼        â”‚
â”‚                                              â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  PostgreSQL  â”‚ â”‚
â”‚                                                           â”‚Data Warehouseâ”‚ â”‚
â”‚                                                           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                   â”‚        â”‚
â”‚                                                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”  â”‚
â”‚                                                     â”‚                   â”‚  â”‚
â”‚                                                â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”â”‚
â”‚                                                â”‚Metabase â”‚      â”‚Streamlitâ”‚â”‚
â”‚                                                â”‚Dashboardâ”‚      â”‚  Apps   â”‚â”‚
â”‚                                                â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜â”‚
â”‚                                                     â”‚                â”‚     â”‚
â”‚                                                     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                             â”‚              â”‚
â”‚                                                       â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”        â”‚
â”‚                                                       â”‚  Traefik  â”‚        â”‚
â”‚                                                       â”‚Rev. Proxy â”‚        â”‚
â”‚                                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Camadas

| Camada | DescriÃ§Ã£o | Formato |
|--------|-----------|---------|
| **Raw** | Dados brutos originais | JSON Lines |
| **Bronze** | Dados ingeridos com metadados | Parquet |
| **Silver** | Dados limpos e validados | Parquet |
| **Gold** | Dados agregados para anÃ¡lise | Parquet |

---

## ğŸ› ï¸ Stack TecnolÃ³gica

| Tecnologia | VersÃ£o | PropÃ³sito |
|------------|--------|-----------|
| **Apache Spark** | 4.0.1 | Processamento distribuÃ­do |
| **PySpark** | 4.0.1 | Interface Python para Spark |
| **PostgreSQL** | 16 | Banco de dados relacional |
| **Apache Kafka** | 7.5.0 | Streaming de eventos |
| **MinIO** | latest | Object storage (S3-compatible) |
| **Docker** | Compose | ContainerizaÃ§Ã£o |

---

## ğŸ“ Estrutura do Projeto

```
spark-medallion-fraud-detection/
â”œâ”€â”€ ğŸ“„ docker-compose.yml      # Infraestrutura containerizada
â”œâ”€â”€ ğŸ“„ .gitignore
â”œâ”€â”€ ğŸ“„ README.md
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/
â”‚   â””â”€â”€ generate_data.py       # Gerador de dados sintÃ©ticos
â”‚
â”œâ”€â”€ ğŸ“‚ spark/
â”‚   â””â”€â”€ jobs/
â”‚       â”œâ”€â”€ bronze_layer.py    # IngestÃ£o: JSON â†’ Parquet
â”‚       â”œâ”€â”€ silver_layer.py    # Limpeza e validaÃ§Ã£o
â”‚       â”œâ”€â”€ gold_layer.py      # AgregaÃ§Ãµes e mÃ©tricas
â”‚       â””â”€â”€ fraud_detection.py # Regras de detecÃ§Ã£o de fraude
â”‚
â””â”€â”€ ğŸ“‚ data/
    â”œâ”€â”€ raw/                   # Dados JSON originais
    â”œâ”€â”€ bronze/                # Parquet bruto
    â”œâ”€â”€ silver/                # Parquet limpo
    â””â”€â”€ gold/                  # Parquet agregado
```

---

## ğŸš€ Como Executar

### PrÃ©-requisitos

- Docker e Docker Compose
- Python 3.13+
- Java 17+

### 1. Clonar o repositÃ³rio

```bash
git clone https://github.com/afborda/spark-medallion-fraud-detection.git
cd spark-medallion-fraud-detection
```

### 2. Subir a infraestrutura

```bash
docker compose up -d
```

### 3. Configurar ambiente Python

```bash
python3 -m venv venv
source venv/bin/activate
pip install pyspark==4.0.1
```

### 4. Gerar dados sintÃ©ticos

```bash
python scripts/generate_data.py
```

### 5. Executar o pipeline

```bash
# Bronze Layer - IngestÃ£o
python spark/jobs/bronze_layer.py

# Silver Layer - Limpeza
python spark/jobs/silver_layer.py

# Gold Layer - AgregaÃ§Ãµes
python spark/jobs/gold_layer.py

# Fraud Detection - Regras de NegÃ³cio
python spark/jobs/fraud_detection.py
```

---

## ğŸ“Š Resultados

### EvoluÃ§Ã£o dos Testes de Performance

| Teste | TransaÃ§Ãµes | Dados Raw | Tempo Total | Throughput | Cluster |
|-------|------------|-----------|-------------|------------|---------|
| Inicial | 500 | ~1 MB | ~10s | 50/s | Local |
| Escala 1 | 50,000 | 11 MB | ~30s | 1,700/s | Local |
| Escala 2 | 1,000,000 | 216 MB | ~2.5min | 6,700/s | 5 Workers |
| Escala 3 | 5,000,000 | 1.1 GB | ~3min | 28,000/s | 5 Workers |
| **Escala 4** | **10,000,000** | **2.2 GB** | **~3.5min** | **47,600/s** | **5 Workers** |

### ConfiguraÃ§Ã£o Atual do Cluster

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SPARK CLUSTER (Docker)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚                    â”‚  SPARK MASTER   â”‚                          â”‚
â”‚                    â”‚  Port: 7077     â”‚                          â”‚
â”‚                    â”‚  UI: 8081       â”‚                          â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                             â”‚                                   â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚     â”‚           â”‚           â”‚           â”‚           â”‚          â”‚
â”‚ â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”      â”‚
â”‚ â”‚Worker1â”‚ â”‚ Worker2 â”‚ â”‚ Worker3 â”‚ â”‚ Worker4 â”‚ â”‚ Worker5 â”‚      â”‚
â”‚ â”‚2 coresâ”‚ â”‚ 2 cores â”‚ â”‚ 2 cores â”‚ â”‚ 2 cores â”‚ â”‚ 2 cores â”‚      â”‚
â”‚ â”‚ 3GB   â”‚ â”‚  3GB    â”‚ â”‚  3GB    â”‚ â”‚  3GB    â”‚ â”‚  3GB    â”‚      â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                 â”‚
â”‚              Total: 10 cores | 15 GB RAM                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Performance por Camada (10M transaÃ§Ãµes - Ãšltimo Teste) ğŸš€

| Camada | Tempo | Registros | Tamanho |
|--------|-------|-----------|---------|
| ğŸ”¶ Bronze | 50s | 10,100,000 | 838 MB |
| âšª Silver | 74s | 10,100,000 | 861 MB |
| ğŸ¥‡ Gold | 40s | AgregaÃ§Ãµes | 866 MB |
| ğŸš¨ Fraud Detection | 45s | 10,000,000 | (incluso) |
| **TOTAL** | **~210s** | - | **2.6 GB** |

### CompressÃ£o Parquet (10M transaÃ§Ãµes)

| Camada | Formato | Tamanho | Economia |
|--------|---------|---------|----------|
| Raw | JSON | 2.2 GB | - |
| Bronze | Parquet | 838 MB | **62%** |
| Silver | Parquet | 861 MB | **61%** |
| Gold | Parquet | 866 MB | **61%** |

### ğŸ“ˆ Escalabilidade Comprovada

| MÃ©trica | Local (50K) | Cluster (1M) | Cluster (5M) | Cluster (10M) | Melhoria |
|---------|-------------|--------------|--------------|---------------|----------|
| TransaÃ§Ãµes | 50,000 | 1,000,000 | 5,000,000 | **10,000,000** | **200Ã—** |
| Dados | 11 MB | 216 MB | 1.1 GB | **2.2 GB** | **200Ã—** |
| Tempo | ~30s | ~150s | ~180s | **~210s** | **7Ã—** |
| **Throughput** | 1,700/s | 6,700/s | 28,000/s | **47,600/s** | **28Ã—** |

> **ConclusÃ£o:** Com 200Ã— mais dados (50K â†’ 10M), o tempo aumentou apenas 7Ã— (30s â†’ 210s). O throughput subiu de 1,700 para **47,600 transaÃ§Ãµes/segundo** - uma melhoria de **28Ã—**!

### EstatÃ­sticas de Fraude (10M transaÃ§Ãµes)

| NÃ­vel de Risco | Quantidade | % do Total | CritÃ©rio |
|----------------|------------|------------|----------|
| ğŸ”´ Alto Risco | ~80,000 | 0.8% | Valor > R$1000 **E** horÃ¡rio 2h-5h |
| ğŸŸ  Risco MÃ©dio | ~2,000,000 | 20% | Valor > R$1000 **OU** horÃ¡rio 2h-5h |
| ğŸŸ¢ Baixo Risco | ~7,920,000 | 79% | Nenhuma regra acionada |
| **TOTAL** | **10,000,000** | 100% | - |

### Dados Atuais

| Entidade | Registros |
|----------|-----------|
| Clientes | 100,000 |
| TransaÃ§Ãµes | 10,000,000 |
| Fraudes (is_fraud) | ~500,000 (5.0%) |

---

## ğŸ“ˆ Progresso do Projeto

### ğŸ“Š RelatÃ³rio de Status (Novembro 2025)

#### âœ… O QUE ESTÃ FEITO

| Item | Status | ObservaÃ§Ãµes |
|------|--------|-------------|
| **Infraestrutura Docker** | âœ… | PostgreSQL, MinIO, Kafka, Zookeeper, Spark (1 Master + 5 Workers) |
| **Bronze Layer** | âœ… | `bronze_layer.py`, `medallion_bronze.py`, `streaming_bronze.py` |
| **Silver Layer** | âœ… | `silver_layer.py`, `medallion_silver.py`, `streaming_silver.py` |
| **Gold Layer** | âœ… | `gold_layer.py`, `medallion_gold.py`, `streaming_gold.py` |
| **Fraud Detection bÃ¡sico** | âœ… | `fraud_detection.py` com regras simples + flags avanÃ§adas |
| **IntegraÃ§Ã£o MinIO** | âœ… | Jobs `*_to_minio.py` e medallion |
| **IntegraÃ§Ã£o PostgreSQL** | âœ… | `load_to_postgres.py`, `kafka_to_postgres_batch.py`, `streaming_to_postgres.py` |
| **GeraÃ§Ã£o de Dados** | âœ… | `generate_data.py`, `generate_10m_transactions.py`, ShadowTraffic |
| **Kafka Producer** | âœ… | `kafka_producer.py` |
| **Streaming Pipeline** | âœ… | Bronzeâ†’Silverâ†’Gold streaming |
| **Batch Pipeline** | âœ… | Bronzeâ†’Silverâ†’Gold batch |
| **DocumentaÃ§Ã£o Regras** | âœ… | `docs/REGRAS_FRAUDE.md` (14 regras documentadas) |
| **Escala 10M transaÃ§Ãµes** | âœ… | Testado com sucesso (~3.5min, 47.6k tx/s) |

#### âŒ O QUE ESTÃ FALTANDO

##### ğŸ”´ CRÃTICO (Alto Impacto)

| Item | Planejado | Atual | AÃ§Ã£o NecessÃ¡ria |
|------|-----------|-------|-----------------|
| **8 Regras de Fraude Completas** | 8 regras complexas | 2 regras + 8 flags | Implementar regras faltantes |
| **Dashboard Metabase** | Configurado e rodando | âŒ NÃ£o existe | Adicionar ao docker-compose |
| **Dashboard Streamlit** | `streamlit/dashboard.py` | âŒ NÃ£o existe | Criar pasta e arquivo |
| **Escala 50GB** | Objetivo principal | 2.2GB testado | Gerar e processar 50GB |

##### ğŸŸ  IMPORTANTE (MÃ©dio Impacto)

| Item | Planejado | Atual | AÃ§Ã£o NecessÃ¡ria |
|------|-----------|-------|-----------------|
| **Entidade Cards** | Tabela de cartÃµes | âŒ NÃ£o existe | Criar schema e dados |
| **Entidade Devices** | Tabela de dispositivos | âŒ NÃ£o existe | Criar schema e dados |
| **Chargebacks** | Processamento de disputas | âŒ NÃ£o existe | Criar pipeline |
| **Blocklist** | Lista de bloqueio | âŒ NÃ£o existe | Criar tabela e lÃ³gica |
| **Audit Log** | Log de compliance | âŒ NÃ£o existe | Implementar logging |
| **Traefik** | Reverse proxy + SSL | âŒ NÃ£o existe | Adicionar ao docker-compose |

##### ğŸŸ¡ DESEJÃVEL (Baixo Impacto)

| Item | Planejado | Atual | AÃ§Ã£o NecessÃ¡ria |
|------|-----------|-------|-----------------|
| **Notebooks** | `notebooks/exploration.ipynb` | âŒ NÃ£o existe | Criar anÃ¡lise exploratÃ³ria |
| **DicionÃ¡rio de Dados** | `docs/data_dictionary.md` | âŒ NÃ£o existe | Documentar campos |
| **Arquitetura Doc** | `docs/architecture.md` | âŒ NÃ£o existe | Criar diagrama |

#### ğŸ¯ FASES DO PROJETO

| Fase | DescriÃ§Ã£o | Status | % |
|------|-----------|--------|---|
| **FASE 1** | Ambiente Docker + Dados | âœ… Completo | 100% |
| **FASE 2** | Pipeline Bronze/Silver/Gold | âœ… Completo | 100% |
| **FASE 3** | Regras de Fraude (8 regras) | âš ï¸ Parcial | 40% |
| **FASE 4** | Operacional (Audit/Blocklist/Chargeback) | âŒ NÃ£o iniciado | 0% |
| **FASE 5** | VisualizaÃ§Ã£o (Metabase/Streamlit) | âŒ NÃ£o iniciado | 0% |
| **FASE 6** | Escala 50GB + DocumentaÃ§Ã£o | âš ï¸ Parcial | 30% |

#### ğŸ“‹ REGRAS DE FRAUDE: Planejado vs. Implementado

| # | Regra Planejada | Status |
|---|-----------------|--------|
| 1 | **Clonagem** (mesma conta, cidades diferentes, <30min) | âŒ |
| 2 | **Teste de CartÃ£o** (3+ tx < R$10 em 5min) | âŒ |
| 3 | **Gasto Anormal** (valor > 50% mÃ©dia mensal) | âš ï¸ Parcial |
| 4 | **Account Takeover** (device desconhecido + >R$500) | âŒ |
| 5 | **Anomalia GeogrÃ¡fica** (distÃ¢ncia > 3x raio habitual) | âš ï¸ Parcial |
| 6 | **HorÃ¡rio AtÃ­pico** (fora do horÃ¡rio usual) | âš ï¸ Parcial |
| 7 | **Categoria Suspeita** (alto risco + primeira compra) | âŒ |
| 8 | **Incompatibilidade de Idade** (perfil vs compra) | âŒ |

---

### âœ… ConcluÃ­do (Detalhado)

- [x] **Infraestrutura Docker** - PostgreSQL, MinIO, Kafka, Spark
- [x] **GeraÃ§Ã£o de Dados** - Script para dados sintÃ©ticos com argparse
- [x] **Bronze Layer** - IngestÃ£o JSON â†’ Parquet
- [x] **Silver Layer** - Limpeza e validaÃ§Ã£o
- [x] **Gold Layer** - AgregaÃ§Ãµes (customer_summary, fraud_summary)
- [x] **Fraud Detection** - Regras de negÃ³cio para detecÃ§Ã£o
  - âœ… TransaÃ§Ãµes > R$1000 (high_value)
  - âœ… HorÃ¡rios suspeitos 2h-5h (suspicious_hour)
  - âœ… NÃ­veis de risco: Alto/MÃ©dio/Baixo
  - âœ… Particionamento por risk_level
  - âœ… 8 Flags de comportamento (cross_state, night, high_value, velocity, gps_mismatch, etc.)
- [x] **PostgreSQL Integration** - Gold Layer no Data Warehouse (5M registros)
- [x] **MinIO Data Lake** - Bronze Layer no storage S3-compatible (414 MB)
- [x] **Cluster Spark DistribuÃ­do** - 5 Workers (10 cores, 15GB RAM)
- [x] **Escala 10M transaÃ§Ãµes** - Pipeline completo em ~3.5min (47.6k tx/s) ğŸš€
- [x] **DocumentaÃ§Ã£o de Regras** - 14 regras documentadas em `docs/REGRAS_FRAUDE.md`

### ğŸ”„ Em Desenvolvimento

- [ ] **8 Regras de Fraude Completas** - Implementar regras avanÃ§adas
- [ ] **Escalar para 50GB** - Testar limites do cluster com volumes maiores

### ğŸ“‹ Planejado

- [ ] **Metabase** - Dashboards de BI
- [ ] **Streamlit** - Apps interativos
- [ ] **Traefik** - Reverse proxy com domÃ­nios
- [ ] **Cards/Devices** - Entidades adicionais
- [ ] **Chargebacks/Blocklist/Audit** - Pipeline operacional

---

## ğŸ–¥ï¸ Infraestrutura

### VPS OVH
| Recurso | EspecificaÃ§Ã£o |
|---------|---------------|
| **Modelo** | VPS-3 |
| **vCores** | 8 |
| **RAM** | 24 GB |
| **Disco** | 200 GB |
| **Objetivo** | Processar ~50 GB de dados |

### ServiÃ§os Docker

| ServiÃ§o | Container | Porta | Status |
|---------|-----------|-------|--------|
| Spark Master | fraud_spark_master | 7077, 8081 | âœ… Rodando |
| Spark Worker 1-5 | fraud_spark_worker_* | - | âœ… 5 Workers |
| PostgreSQL | fraud_postgres | 5432 | âœ… Rodando |
| MinIO Console | fraud_minio | 9003 | âœ… Rodando |
| MinIO API | fraud_minio | 9002 | âœ… Rodando |
| Kafka | fraud_kafka | 9092 | âœ… Rodando |
| Zookeeper | fraud_zookeeper | 2181 | âœ… Rodando |
| Metabase | - | - | ğŸ“‹ Planejado |
| Streamlit | - | - | ğŸ“‹ Planejado |
| Traefik | - | 80/443 | ğŸ“‹ Planejado |

### Executar no Cluster DistribuÃ­do

```bash
# Gerar dados (local)
python scripts/generate_data.py --customers 10000 --transactions 1000000

# Executar pipeline no cluster Docker
docker exec fraud_spark_master /opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --executor-memory 2g \
  --total-executor-cores 8 \
  /jobs/bronze_layer.py

docker exec fraud_spark_master /opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  /jobs/silver_layer.py

docker exec fraud_spark_master /opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  /jobs/gold_layer.py

docker exec fraud_spark_master /opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  /jobs/fraud_detection.py
```

---

## ğŸ“š Conceitos Aplicados

- **Arquitetura Medallion** - PadrÃ£o de organizaÃ§Ã£o de data lakes
- **Apache Spark** - Processamento distribuÃ­do em memÃ³ria
- **Parquet** - Formato colunar otimizado para analytics
- **Data Quality** - Limpeza, validaÃ§Ã£o e padronizaÃ§Ã£o
- **AgregaÃ§Ãµes** - groupBy, sum, count, avg
- **LÃ³gica Condicional** - when/otherwise para regras de negÃ³cio
- **Particionamento** - partitionBy para otimizaÃ§Ã£o de queries

---

## ğŸ¤ ContribuiÃ§Ã£o

Este Ã© um projeto de aprendizado. SugestÃµes e melhorias sÃ£o bem-vindas!

---

## ğŸ“ LicenÃ§a

MIT License - veja [LICENSE](LICENSE) para detalhes.

---

<p align="center">
  <i>Desenvolvido como projeto de aprendizado em Data Engineering</i>
</p>
