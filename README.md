# ğŸ” Fraud Detection Data Pipeline

> Pipeline de detecÃ§Ã£o de fraudes bancÃ¡rias usando arquitetura Medallion com Apache Spark

[![Spark](https://img.shields.io/badge/Apache%20Spark-4.0.1-E25A1C?logo=apachespark&logoColor=white)](https://spark.apache.org/)
[![Python](https://img.shields.io/badge/Python-3.13-3776AB?logo=python&logoColor=white)](https://python.org/)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?logo=docker&logoColor=white)](https://docker.com/)
[![Status](https://img.shields.io/badge/Status-Em%20Desenvolvimento-yellow)](https://github.com/afborda/spark-medallion-fraud-detection)

---

## ğŸ“‹ Sobre o Projeto

Este projeto implementa um **pipeline de dados** para detecÃ§Ã£o de fraudes em transaÃ§Ãµes bancÃ¡rias, utilizando a arquitetura **Medallion** (Bronze â†’ Silver â†’ Gold) com processamento distribuÃ­do via Apache Spark.

### ğŸ¯ Objetivos

- Processar transaÃ§Ãµes bancÃ¡rias em larga escala
- Identificar padrÃµes de fraude atravÃ©s de regras de negÃ³cio
- Implementar arquitetura de dados moderna e escalÃ¡vel
- Preparar dados para anÃ¡lise e machine learning

---

## ğŸ—ï¸ Arquitetura

### Arquitetura Atual (Batch)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ARQUITETURA MEDALLION                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   ğŸ“¥ RAW          ğŸ”¶ BRONZE        âšª SILVER        ğŸ¥‡ GOLD     â”‚
â”‚   â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€â”€â”€        â”‚
â”‚   JSON           Parquet         Parquet         Parquet       â”‚
â”‚   (origem)       (bruto)         (limpo)         (agregado)    â”‚
â”‚                                                                 â”‚
â”‚   customers  â”€â”€â–º customers   â”€â”€â–º customers   â”€â”€â–º customer_     â”‚
â”‚   .json          /               /               summary/      â”‚
â”‚                                                                 â”‚
â”‚   transactionsâ”€â”€â–º transactionsâ”€â”€â–º transactionsâ”€â”€â–º fraud_       â”‚
â”‚   .json          /               /               detection/    â”‚
â”‚                                                  (partitioned) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Arquitetura Objetivo (Streaming + Lakehouse)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        LAKEHOUSE ARCHITECTURE                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ ShadowTrafficâ”‚â”€â”€â”€â–ºâ”‚  Kafka  â”‚â”€â”€â”€â–ºâ”‚ Spark Streaming â”‚â”€â”€â”€â–ºâ”‚ MinIO Lake  â”‚ â”‚
â”‚  â”‚  (Generator) â”‚    â”‚ Topics  â”‚    â”‚   ETL Jobs      â”‚    â”‚ Bronze/     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚customersâ”‚    â”‚                 â”‚    â”‚ Silver/Gold â”‚ â”‚
â”‚                      â”‚ orders  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚                    â”‚        â”‚
â”‚                                              â”‚                    â–¼        â”‚
â”‚                                              â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  PostgreSQL  â”‚ â”‚
â”‚                                                           â”‚Data Warehouseâ”‚ â”‚
â”‚                                                           â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                   â”‚        â”‚
â”‚                                                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”  â”‚
â”‚                                                     â”‚                   â”‚  â”‚
â”‚                                                â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”â”‚
â”‚                                                â”‚Metabase â”‚      â”‚Streamlitâ”‚â”‚
â”‚                                                â”‚Dashboardâ”‚      â”‚  Apps   â”‚â”‚
â”‚                                                â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜â”‚
â”‚                                                     â”‚                â”‚     â”‚
â”‚                                                     â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                             â”‚              â”‚
â”‚                                                       â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”        â”‚
â”‚                                                       â”‚  Traefik  â”‚        â”‚
â”‚                                                       â”‚Rev. Proxy â”‚        â”‚
â”‚                                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Camadas

| Camada | DescriÃ§Ã£o | Formato |
|--------|-----------|---------|
| **Raw** | Dados brutos originais | JSON Lines |
| **Bronze** | Dados ingeridos com metadados | Parquet |
| **Silver** | Dados limpos e validados | Parquet |
| **Gold** | Dados agregados para anÃ¡lise | Parquet |

---

## ğŸ› ï¸ Stack TecnolÃ³gica

| Tecnologia | VersÃ£o | PropÃ³sito |
|------------|--------|-----------|
| **Apache Spark** | 4.0.1 | Processamento distribuÃ­do |
| **PySpark** | 4.0.1 | Interface Python para Spark |
| **PostgreSQL** | 16 | Banco de dados relacional |
| **Apache Kafka** | 7.5.0 | Streaming de eventos |
| **MinIO** | latest | Object storage (S3-compatible) |
| **Docker** | Compose | ContainerizaÃ§Ã£o |

---

## ğŸ“ Estrutura do Projeto

```
spark-medallion-fraud-detection/
â”œâ”€â”€ ğŸ“„ docker-compose.yml      # Infraestrutura containerizada
â”œâ”€â”€ ğŸ“„ .gitignore
â”œâ”€â”€ ğŸ“„ README.md
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/
â”‚   â””â”€â”€ generate_data.py       # Gerador de dados sintÃ©ticos
â”‚
â”œâ”€â”€ ğŸ“‚ spark/
â”‚   â””â”€â”€ jobs/
â”‚       â”œâ”€â”€ bronze_layer.py    # IngestÃ£o: JSON â†’ Parquet
â”‚       â”œâ”€â”€ silver_layer.py    # Limpeza e validaÃ§Ã£o
â”‚       â”œâ”€â”€ gold_layer.py      # AgregaÃ§Ãµes e mÃ©tricas
â”‚       â””â”€â”€ fraud_detection.py # Regras de detecÃ§Ã£o de fraude
â”‚
â””â”€â”€ ğŸ“‚ data/
    â”œâ”€â”€ raw/                   # Dados JSON originais
    â”œâ”€â”€ bronze/                # Parquet bruto
    â”œâ”€â”€ silver/                # Parquet limpo
    â””â”€â”€ gold/                  # Parquet agregado
```

---

## ğŸš€ Como Executar

### PrÃ©-requisitos

- Docker e Docker Compose
- Python 3.13+
- Java 17+

### 1. Clonar o repositÃ³rio

```bash
git clone https://github.com/afborda/spark-medallion-fraud-detection.git
cd spark-medallion-fraud-detection
```

### 2. Subir a infraestrutura

```bash
docker compose up -d
```

### 3. Configurar ambiente Python

```bash
python3 -m venv venv
source venv/bin/activate
pip install pyspark==4.0.1
```

### 4. Gerar dados sintÃ©ticos

```bash
python scripts/generate_data.py
```

### 5. Executar o pipeline

```bash
# Bronze Layer - IngestÃ£o
python spark/jobs/bronze_layer.py

# Silver Layer - Limpeza
python spark/jobs/silver_layer.py

# Gold Layer - AgregaÃ§Ãµes
python spark/jobs/gold_layer.py

# Fraud Detection - Regras de NegÃ³cio
python spark/jobs/fraud_detection.py
```

---

## ğŸ“Š Resultados

### Dados Processados

| Entidade | Registros |
|----------|-----------|
| Clientes | 100 |
| TransaÃ§Ãµes | 500 |

### EstatÃ­sticas de Fraude (Gold Layer)

| MÃ©trica | Valor |
|---------|-------|
| Total de transaÃ§Ãµes | 500 |
| Fraudes detectadas | 19 |
| Valor total fraudado | R$ 62.260,93 |
| Taxa de fraude | 3.8% |

### DetecÃ§Ã£o por Regras de NegÃ³cio

| NÃ­vel de Risco | Quantidade | CritÃ©rio |
|----------------|------------|----------|
| ğŸ”´ Alto Risco | 4 | Valor > R$1000 **E** horÃ¡rio 2h-5h |
| ğŸŸ  Risco MÃ©dio | 83 | Valor > R$1000 **OU** horÃ¡rio 2h-5h |
| ğŸŸ¢ Baixo Risco | 413 | Nenhuma regra acionada |

---

## ğŸ“ˆ Progresso do Projeto

### âœ… ConcluÃ­do

- [x] **Infraestrutura Docker** - PostgreSQL, MinIO, Kafka, Spark
- [x] **GeraÃ§Ã£o de Dados** - Script para dados sintÃ©ticos
- [x] **Bronze Layer** - IngestÃ£o JSON â†’ Parquet
- [x] **Silver Layer** - Limpeza e validaÃ§Ã£o
- [x] **Gold Layer** - AgregaÃ§Ãµes (customer_summary, fraud_summary)
- [x] **Fraud Detection** - Regras de negÃ³cio para detecÃ§Ã£o
  - âœ… TransaÃ§Ãµes > R$1000 (high_value)
  - âœ… HorÃ¡rios suspeitos 2h-5h (suspicious_hour)
  - âœ… NÃ­veis de risco: Alto/MÃ©dio/Baixo
  - âœ… Particionamento por risk_level

### ğŸ”„ Em Desenvolvimento

- [ ] **PostgreSQL Integration** - Salvar Gold no Data Warehouse
- [ ] **MinIO Data Lake** - Storage S3-compatible
- [ ] **Escalar para 50GB** - Volume de produÃ§Ã£o

### ğŸ“‹ Planejado

- [ ] **ShadowTraffic** - GeraÃ§Ã£o de dados em streaming
- [ ] **Kafka Streaming** - Processamento em tempo real
- [ ] **Spark Structured Streaming** - ETL em tempo real
- [ ] **Metabase** - Dashboards de BI
- [ ] **Streamlit** - Apps interativos
- [ ] **Traefik** - Reverse proxy com domÃ­nios

---

## ğŸ–¥ï¸ Infraestrutura

### VPS OVH
| Recurso | EspecificaÃ§Ã£o |
|---------|---------------|
| **Modelo** | VPS-3 |
| **vCores** | 8 |
| **RAM** | 24 GB |
| **Disco** | 200 GB |
| **Objetivo** | Processar ~50 GB de dados |

### ServiÃ§os Docker

| ServiÃ§o | Porta | DescriÃ§Ã£o | Status |
|---------|-------|-----------|--------|
| PostgreSQL | 5432 | Data Warehouse | âœ… Rodando |
| MinIO Console | 9003 | Object storage UI | âœ… Rodando |
| MinIO API | 9002 | Object storage API | âœ… Rodando |
| Kafka | 9092 | Message broker | âœ… Rodando |
| Zookeeper | 2181 | Kafka coordination | âœ… Rodando |
| Spark UI | 8081 | Interface Spark | âœ… Rodando |
| Metabase | - | BI Dashboards | ğŸ“‹ Planejado |
| Streamlit | - | Data Apps | ğŸ“‹ Planejado |
| Traefik | 80/443 | Reverse Proxy | ğŸ“‹ Planejado |

---

## ğŸ“š Conceitos Aplicados

- **Arquitetura Medallion** - PadrÃ£o de organizaÃ§Ã£o de data lakes
- **Apache Spark** - Processamento distribuÃ­do em memÃ³ria
- **Parquet** - Formato colunar otimizado para analytics
- **Data Quality** - Limpeza, validaÃ§Ã£o e padronizaÃ§Ã£o
- **AgregaÃ§Ãµes** - groupBy, sum, count, avg
- **LÃ³gica Condicional** - when/otherwise para regras de negÃ³cio
- **Particionamento** - partitionBy para otimizaÃ§Ã£o de queries

---

## ğŸ¤ ContribuiÃ§Ã£o

Este Ã© um projeto de aprendizado. SugestÃµes e melhorias sÃ£o bem-vindas!

---

## ğŸ“ LicenÃ§a

MIT License - veja [LICENSE](LICENSE) para detalhes.

---

<p align="center">
  <i>Desenvolvido como projeto de aprendizado em Data Engineering</i>
</p>
