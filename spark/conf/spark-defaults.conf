# ============================================
# SPARK DEFAULTS - Configurações Globais
# ============================================
# NOTA: Credenciais sensíveis são injetadas via variáveis de ambiente
# no docker-compose.yml (env_file ou environment), NÃO aqui.
#
# CLUSTER: 2 workers × 2 cores × 5GB = 4 cores + 10GB total
# ============================================

# S3/MinIO - Configurações de conexão (SEM SENHAS)
spark.hadoop.fs.s3a.path.style.access       true
spark.hadoop.fs.s3a.impl                    org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.connection.ssl.enabled  false

# Event Log (para Spark History Server)
spark.eventLog.enabled                      true
spark.eventLog.dir                          /opt/spark/spark-events
spark.history.fs.logDirectory               /opt/spark/spark-events

# ============================================
# OTIMIZAÇÕES DE MEMÓRIA E PERFORMANCE
# ============================================

# Memory overhead para JVM (além do executor memory)
spark.executor.memoryOverhead               512m
spark.driver.memoryOverhead                 384m

# Fração de memória para execução vs storage
spark.memory.fraction                       0.6
spark.memory.storageFraction                0.5

# ============================================
# PARALELISMO (4 cores total)
# ============================================
spark.default.parallelism                   4
spark.sql.shuffle.partitions                8

# ============================================
# NETWORK E TIMEOUT (evita jobs travados)
# ============================================
spark.network.timeout                       600s
spark.executor.heartbeatInterval            30s
spark.rpc.message.maxSize                   256

# ============================================
# SERIALIZAÇÃO
# ============================================
spark.serializer                            org.apache.spark.serializer.KryoSerializer
spark.kryoserializer.buffer.max             512m

# ============================================
# STREAMING
# ============================================
spark.streaming.stopGracefullyOnShutdown    true
spark.streaming.backpressure.enabled        true
