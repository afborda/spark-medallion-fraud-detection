# ğŸ“¦ Pipeline BATCH - Dados Brasileiros

> Scripts para processamento em lote de dados brasileiros gerados localmente.

## ğŸ“‹ VisÃ£o Geral

Este diretÃ³rio contÃ©m os jobs Spark para processamento **BATCH** (em lote) dos dados brasileiros.

**Fonte de Dados:** Arquivos JSON gerados pelo script `scripts/generate_brazilian_data.py`

## ğŸ”„ Fluxo do Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PIPELINE BATCH (Dados ğŸ‡§ğŸ‡·)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚   /data/raw/*.json                                                  â”‚
â”‚         â”‚                                                           â”‚
â”‚         â–¼                                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚   â”‚ bronze_brazilianâ”‚  IngestÃ£o: JSON â†’ Parquet (MinIO)            â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚            â”‚                                                        â”‚
â”‚            â–¼                                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚   â”‚ silver_brazilianâ”‚  Limpeza: Tipos, Duplicatas, Derivados       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚            â”‚                                                        â”‚
â”‚            â–¼                                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚   â”‚ gold_brazilian  â”‚  AgregaÃ§Ãµes: Fraud Score, MÃ©tricas           â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚            â”‚                                                        â”‚
â”‚            â–¼                                                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚   â”‚ load_to_postgresâ”‚  ExportaÃ§Ã£o: Parquet â†’ PostgreSQL            â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Scripts Principais (USAR ESTES)

| Script | DescriÃ§Ã£o | Entrada | SaÃ­da |
|--------|-----------|---------|-------|
| `bronze_brazilian.py` | IngestÃ£o de JSON bruto | `/data/raw/*.json` | `s3a://fraud-data/medallion/bronze/` |
| `silver_brazilian.py` | Limpeza e transformaÃ§Ã£o | Bronze (Parquet) | `s3a://fraud-data/medallion/silver/` |
| `gold_brazilian.py` | AgregaÃ§Ãµes e Fraud Score | Silver (Parquet) | `s3a://fraud-data/medallion/gold/` |
| `load_to_postgres.py` | Carga para PostgreSQL | Gold (Parquet) | PostgreSQL (Metabase) |

## ğŸš€ Como Executar

```bash
# 1. Bronze Layer
docker exec fraud_spark_master /opt/spark/bin/spark-submit \
    --master spark://spark-master:7077 \
    /jobs/production/bronze_brazilian.py

# 2. Silver Layer
docker exec fraud_spark_master /opt/spark/bin/spark-submit \
    --master spark://spark-master:7077 \
    /jobs/production/silver_brazilian.py

# 3. Gold Layer
docker exec fraud_spark_master /opt/spark/bin/spark-submit \
    --master spark://spark-master:7077 \
    /jobs/production/gold_brazilian.py

# 4. Load to PostgreSQL
docker exec fraud_spark_master /opt/spark/bin/spark-submit \
    --master spark://spark-master:7077 \
    /jobs/production/load_to_postgres.py
```

## âš ï¸ Scripts Legados (DEPRECADOS)

Os scripts `medallion_*.py` sÃ£o versÃµes antigas que foram usadas para testes com dados do Kafka.
**Use os scripts `*_brazilian.py`** para o pipeline batch de produÃ§Ã£o.

## ğŸ–¥ï¸ Como Executar

### No Cluster Spark (ProduÃ§Ã£o)

```bash
# Entrar no container spark-master
docker exec -it spark-master bash

# Bronze Layer
spark-submit \
  --master spark://spark-master:7077 \
  --jars /jars/hadoop-aws-3.3.4.jar,/jars/aws-java-sdk-bundle-1.12.262.jar,/jars/postgresql-42.7.4.jar \
  /spark/jobs/production/medallion_bronze.py

# Silver Layer
spark-submit \
  --master spark://spark-master:7077 \
  --jars /jars/hadoop-aws-3.3.4.jar,/jars/aws-java-sdk-bundle-1.12.262.jar,/jars/postgresql-42.7.4.jar \
  /spark/jobs/production/medallion_silver.py

# Gold Layer
spark-submit \
  --master spark://spark-master:7077 \
  --jars /jars/hadoop-aws-3.3.4.jar,/jars/aws-java-sdk-bundle-1.12.262.jar,/jars/postgresql-42.7.4.jar \
  /spark/jobs/production/medallion_gold.py
```

### ExecuÃ§Ã£o Local (Desenvolvimento)

```bash
# Com Spark instalado localmente
spark-submit \
  --master local[*] \
  --jars /path/to/hadoop-aws-3.3.4.jar,/path/to/aws-java-sdk-bundle-1.12.262.jar,/path/to/postgresql-42.7.4.jar \
  medallion_silver.py
```

## âš™ï¸ ConfiguraÃ§Ãµes NecessÃ¡rias

### JARs ObrigatÃ³rios
- `hadoop-aws-3.3.4.jar` - ConexÃ£o com MinIO/S3
- `aws-java-sdk-bundle-1.12.262.jar` - SDK AWS para S3
- `postgresql-42.7.4.jar` - Driver PostgreSQL

### VariÃ¡veis de Ambiente
Os scripts usam valores hardcoded, mas podem ser externalizados:
- MinIO: `minio:9000`, `minioadmin:minioadmin`
- PostgreSQL: `postgres:5432`, `postgres:postgres`

## ğŸ“Š Ordem de ExecuÃ§Ã£o

**IMPORTANTE**: Sempre execute na ordem correta!

```
1. medallion_bronze.py  (Kafka â†’ MinIO bronze/)
2. medallion_silver.py  (MinIO bronze/ â†’ MinIO silver/)
3. medallion_gold.py    (MinIO silver/ â†’ MinIO gold/ + PostgreSQL)
```

## ğŸ” Monitoramento

- **Spark UI**: http://localhost:8080
- **MinIO Console**: http://localhost:9001
- **PostgreSQL**: porta 5432

## ğŸ“ Notas de Desenvolvimento

- Cada script Ã© idempotente (pode ser re-executado)
- Dados sÃ£o particionados por `event_date` para otimizaÃ§Ã£o
- Silver usa Parquet com compressÃ£o snappy
- Gold cria 3 nÃ­veis de risco: Alto, MÃ©dio, Baixo
