# üéì Aprendizado Apache Airflow - Progresso do Abner

> **√öltima atualiza√ß√£o:** 2025-12-05
> **Status:** Em andamento - M√≥dulo 3 CONCLU√çDO ‚úÖ
> **M√©todo:** Ensino linha por linha, digitando c√≥digo, com perguntas de fixa√ß√£o

---

## üìö M√©todo de Ensino Acordado

```
1. CONCEITO   ‚Üí Explica√ß√£o te√≥rica (o que √©, pra que serve)
2. ANALOGIA   ‚Üí Compara√ß√£o com algo do mundo real
3. C√ìDIGO     ‚Üí Aluno digita, professor explica linha por linha
4. EXERC√çCIO  ‚Üí Pergunta para fixar o conhecimento
5. PR√ìXIMO    ‚Üí S√≥ avan√ßa quando entendeu
```

**Regras:**
- N√£o copiar/colar c√≥digo pronto - sempre digitar
- Entender cada linha antes de avan√ßar
- Objetivo: saber fazer sozinho sem IA

---

## ‚úÖ Conceitos J√° Aprendidos

### M√≥dulo 1: Fundamentos (CONCLU√çDO ‚úÖ)

#### 1.1 O que √© Orquestra√ß√£o
- **Aprendido:** Orquestrador ‚â† Processador
- **Analogia:** Chef de cozinha (Airflow) vs Cozinheiros (Spark, Kafka)
- **Pergunta respondida:** "Quem √© o orquestrador no seu projeto hoje?" ‚Üí Resposta: Voc√™ mesmo (executa scripts manualmente)

#### 1.2 O que √© DAG (Directed Acyclic Graph)
- **Aprendido:** 
  - Graph = coisas conectadas
  - Directed = tem dire√ß√£o (setas)
  - Acyclic = sem ciclos (n√£o volta pro in√≠cio)
- **Analogia:** Mapa de metr√¥ com dire√ß√£o √∫nica
- **Pergunta respondida:** "Por que Acyclic?" ‚Üí Resposta: Para evitar loop infinito

#### 1.3 Estrutura de um DAG
- **Aprendido:** 4 partes principais:
  1. IMPORTS - ferramentas do Airflow
  2. DEFAULT_ARGS - configura√ß√µes padr√£o (retries, email)
  3. DEFINI√á√ÉO DO DAG - nome, schedule, tags
  4. TASKS E DEPEND√äNCIAS - o que fazer e em que ordem
- **Analogia:** Receita de bolo (ingredientes, instru√ß√µes, passos)

#### 1.4 Primeiro DAG - Hello World
- **Arquivo criado:** `airflow/dags/hello_world.py`
- **Conceitos aplicados:**
  - `from airflow import DAG`
  - `from airflow.operators.python import PythonOperator`
  - `default_args` com owner, retries, retry_delay, email
  - `with DAG(...) as dag:` para criar o DAG
  - `PythonOperator` para executar fun√ß√µes Python
  - `task_id` e `python_callable`
  - Depend√™ncias com `>>` (task_a >> task_b)

#### 1.5 Paralelismo
- **Aprendido:** Usar lista `[]` para tasks em paralelo
- **Exemplo:** `task_inicio >> [task_hello, task_fim]`
- **Pergunta respondida:** Escolheu C, era B (lista Python)

---

## üìç Onde Paramos

**Pr√≥ximo passo:** M√≥dulo 4 - Operadores Avan√ßados e TaskFlow API

**Pendente:**
- [ ] TaskFlow API (@task, @dag) - forma moderna de escrever DAGs
- [ ] Sensors (esperar arquivos/condi√ß√µes)
- [ ] XCom - passar dados entre tasks
- [ ] DAG Factory pattern

---

## üó∫Ô∏è Roteiro Completo

### M√≥dulo 1: Fundamentos ‚úÖ CONCLU√çDO
- [x] O que √© orquestra√ß√£o
- [x] O que √© DAG
- [x] Estrutura de um DAG
- [x] Primeiro DAG (Hello World)
- [x] Paralelismo com listas

### M√≥dulo 2: Docker e UI ‚úÖ CONCLU√çDO
- [x] Docker Compose para Airflow (arquivo separado)
- [x] Integra√ß√£o com Traefik (dom√≠nio airflow.abnerfonseca.com.br)
- [x] Resolu√ß√£o de problemas (permiss√µes, URL encoding)
- [x] Acessar UI do Airflow
- [x] Executar DAG manualmente
- [x] Ver execu√ß√£o com tasks verdes

### M√≥dulo 3: Integra√ß√£o com Spark ‚úÖ CONCLU√çDO
- [x] BashOperator para executar docker exec
- [x] Docker-in-Docker (montar socket)
- [x] Dockerfile customizado com Docker CLI
- [x] DAG medallion_pipeline completo
- [x] Execu√ß√£o bem sucedida: Bronze ‚Üí Silver ‚Üí Gold ‚Üí Postgres
- [x] Pipeline executou ~65M registros em ~1h40min

### M√≥dulo 4: Operadores Avan√ßados (PR√ìXIMO üëà)
- [ ] TaskFlow API (@task, @dag)
- [ ] Sensors (esperar arquivos/condi√ß√µes)
- [ ] XCom - passar dados entre tasks
- [ ] Branching (condicionais)

### M√≥dulo 5: Produ√ß√£o
- [ ] DAG Factory pattern
- [ ] Testes com pytest
- [ ] CI/CD

---

## üìù Arquivos Criados

| Arquivo | Status | Descri√ß√£o |
|---------|--------|-----------|
| `airflow/dags/hello_world.py` | ‚úÖ Completo | Primeiro DAG de exemplo |
| `airflow/dags/medallion_pipeline.py` | ‚úÖ Completo | Pipeline Spark completo |
| `airflow/APRENDIZADO_AIRFLOW.md` | ‚úÖ Ativo | Este arquivo de progresso |
| `docker-compose.airflow.yml` | ‚úÖ Completo | Docker Compose do Airflow |
| `Dockerfile.airflow` | ‚úÖ Completo | Imagem customizada com Docker CLI |
| `airflow/logs/` | ‚úÖ Criado | Logs do Airflow |
| `airflow/plugins/` | ‚úÖ Criado | Plugins customizados |

---

## üîë Comandos/C√≥digos Importantes Aprendidos

```python
# Imports b√°sicos
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime, timedelta

# Default args
default_args = {
    'owner': 'abner',
    'retries': 3,
    'retry_delay': timedelta(minutes=5),
}

# Criar DAG
with DAG(
    dag_id='nome_do_dag',
    default_args=default_args,
    schedule_interval='@daily',
    start_date=datetime(2025, 12, 1),
    catchup=False,
) as dag:

# Criar task
task = PythonOperator(
    task_id='nome_task',
    python_callable=funcao_python,
)

# Depend√™ncias
task_a >> task_b           # sequencial
task_a >> [task_b, task_c] # paralelo
```

```bash
# Comandos Docker para Airflow

# Criar database airflow no PostgreSQL existente
docker exec -it fraud_postgres psql -U fraud_user -d fraud_db -c "CREATE DATABASE airflow;"

# Inicializar Airflow (criar tabelas e usu√°rio admin)
docker compose -f docker-compose.yml -f docker-compose.airflow.yml run --rm airflow-init

# Subir Airflow (webserver + scheduler)
docker compose -f docker-compose.yml -f docker-compose.airflow.yml up -d airflow-webserver airflow-scheduler

# Verificar status
docker ps --filter "name=airflow"

# Ver logs
docker logs fraud_airflow_webserver
docker logs fraud_airflow_scheduler
```

```yaml
# Estrutura do docker-compose.airflow.yml

# Template reutiliz√°vel
x-airflow-common: &airflow-common
  image: apache/airflow:2.10.3
  environment:
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://user:pass@host/db

# Servi√ßos
services:
  airflow-init:      # Inicializa√ß√£o (roda uma vez)
  airflow-webserver: # UI (porta 8888)
  airflow-scheduler: # Agendador
```

---

## üêõ Problemas Resolvidos

### 1. Permiss√£o de pastas (Permission denied)
**Problema:** Container Airflow n√£o conseguia escrever em `logs/`
**Solu√ß√£o:** `sudo chmod -R 777 airflow/logs airflow/plugins airflow/dags`

### 2. URL Encoding (senha com caracteres especiais)
**Problema:** Senha `fraud_password@@!!_2` quebrava a URL de conex√£o
**Solu√ß√£o:** URL encoding manual: `@` = `%40`, `!` = `%21`
```
fraud_password@@!!_2 ‚Üí fraud_password%40%40%21%21_2
```

### 3. Docker-in-Docker (executar docker de dentro do Airflow)
**Problema:** Airflow em container n√£o tinha acesso ao Docker do host
**Solu√ß√£o:**
1. Montar socket: `- /var/run/docker.sock:/var/run/docker.sock`
2. Criar Dockerfile.airflow com Docker CLI instalado
3. Rodar como root: `user: "0:0"`

---

## üèÜ Resultados do Pipeline Medallion

**Execu√ß√£o bem sucedida em 2025-12-05:**

| Task | Tempo | Registros |
|------|-------|-----------|
| bronze_ingestion | ~20 min | 51M transa√ß√µes |
| silver_transformation | ~25 min | 51M registros |
| gold_aggregation | ~40 min | M√©tricas + Alertas |
| load_to_postgres | ~15 min | ~65M registros |
| **TOTAL** | **~1h40min** | **Pipeline completo!** |

---

## üí¨ Instru√ß√µes para Pr√≥xima Sess√£o

**Para a IA continuar de onde paramos:**

1. Ler este arquivo primeiro
2. Continuar do "Onde Paramos" (M√≥dulo 3 - Integra√ß√£o com Spark)
3. Manter o m√©todo de ensino (explicar ‚Üí digitar ‚Üí perguntar)
4. Atualizar este arquivo ao final com "salvar"

**Para o aluno:**
- Comando "salvar" = atualiza este documento com o progresso
- N√£o pular etapas
- Perguntar se n√£o entender

---

## üåê Acessos Configurados

| Servi√ßo | URL Local | URL Dom√≠nio |
|---------|-----------|-------------|
| Airflow UI | http://localhost:8888 | https://airflow.abnerfonseca.com.br |
| Login | admin / admin | admin / admin |
