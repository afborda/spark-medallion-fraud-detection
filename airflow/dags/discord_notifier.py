"""
ğŸ”” DISCORD NOTIFIER - Envia notificaÃ§Ãµes formatadas para o Discord
===================================================================

FunÃ§Ãµes para enviar notificaÃ§Ãµes ricas (embeds) para o Discord via webhook.
Usado pelo Streaming Supervisor para alertar sobre eventos importantes.

Tipos de notificaÃ§Ãµes:
- âœ… Jobs iniciados com sucesso
- âš ï¸ Jobs reiniciados apÃ³s falha
- âŒ Falhas crÃ­ticas
- ğŸ“Š Status geral do cluster
"""

import requests
import json
from datetime import datetime


# Webhook do Discord
DISCORD_WEBHOOK_URL = "https://discord.com/api/webhooks/1447677762252046417/oVsnCG8DHcmE17solRpRtOHpLVwo8d_G0pE0JiEQ-MIQrUk-mPVR8Zvi-9jvK7zb2uj4"

# Cores para diferentes tipos de mensagens (formato decimal)
COLOR_SUCCESS = 3066993   # Verde (0x2ecc71)
COLOR_WARNING = 16776960  # Amarelo (0xffff00)
COLOR_ERROR = 15158332    # Vermelho (0xe74c3c)
COLOR_INFO = 3447003      # Azul (0x3498db)


def send_discord_notification(webhook_url, embeds, username="ğŸ¤– Spark Supervisor", content=None):
    """
    Envia notificaÃ§Ã£o para o Discord usando webhook.
    
    Args:
        webhook_url: URL do webhook do Discord
        embeds: Lista de embeds (dicionÃ¡rios)
        username: Nome do bot
        content: Mensagem de texto simples (opcional)
    """
    payload = {
        "username": username,
        "embeds": embeds if isinstance(embeds, list) else [embeds]
    }
    
    if content:
        payload["content"] = content
    
    try:
        response = requests.post(
            webhook_url,
            json=payload,
            headers={"Content-Type": "application/json"},
            timeout=10
        )
        response.raise_for_status()
        return True
    except Exception as e:
        print(f"âŒ Erro ao enviar notificaÃ§Ã£o Discord: {e}")
        return False


def notify_jobs_started(jobs_info, cluster_status):
    """
    Notifica que jobs foram iniciados com sucesso.
    
    Args:
        jobs_info: Lista de dicionÃ¡rios com info dos jobs iniciados
        cluster_status: DicionÃ¡rio com status do cluster
    """
    timestamp = datetime.now().isoformat()
    
    # Calcula recursos usados
    total_cores = cluster_status.get('total_cores', 0)
    cores_used = cluster_status.get('cores_used', 0)
    usage_percent = (cores_used * 100 // total_cores) if total_cores > 0 else 0
    
    # Cria descriÃ§Ã£o dos jobs
    jobs_description = ""
    for job in jobs_info:
        jobs_description += f"â€¢ **{job['name']}**\n"
        jobs_description += f"  â”” Cores: {job['cores']} | MemÃ³ria: {job['memory']}\n"
    
    embed = {
        "title": "ğŸš€ Jobs de Streaming Iniciados",
        "description": f"{len(jobs_info)} job(s) iniciado(s) com sucesso",
        "color": COLOR_SUCCESS,
        "fields": [
            {
                "name": "ğŸ“‹ Jobs Iniciados",
                "value": jobs_description or "Nenhum job iniciado",
                "inline": False
            },
            {
                "name": "ğŸ’» Recursos do Cluster",
                "value": f"**Cores:** {cores_used}/{total_cores} ({usage_percent}%)\n"
                         f"**Workers:** {cluster_status.get('alive_workers', 0)}",
                "inline": True
            },
            {
                "name": "âš™ï¸ ConfiguraÃ§Ã£o",
                "value": f"**Limite:** 60% (6 cores)\n"
                         f"**Reserva batch:** 40% (4 cores)",
                "inline": True
            }
        ],
        "footer": {
            "text": "Spark Fraud Detection Pipeline"
        },
        "timestamp": timestamp
    }
    
    send_discord_notification(DISCORD_WEBHOOK_URL, embed)


def notify_jobs_already_running(jobs_running, cluster_status):
    """
    Notifica que todos os jobs jÃ¡ estÃ£o rodando (check de saÃºde OK).
    
    Args:
        jobs_running: Lista de nomes dos jobs rodando
        cluster_status: DicionÃ¡rio com status do cluster
    """
    timestamp = datetime.now().isoformat()
    
    total_cores = cluster_status.get('total_cores', 0)
    cores_used = cluster_status.get('cores_used', 0)
    usage_percent = (cores_used * 100 // total_cores) if total_cores > 0 else 0
    
    embed = {
        "title": "âœ… Streaming Health Check",
        "description": "Todos os jobs estÃ£o rodando normalmente",
        "color": COLOR_INFO,
        "fields": [
            {
                "name": "ğŸ“Š Jobs Ativos",
                "value": "\n".join([f"â€¢ {job}" for job in jobs_running]) or "Nenhum",
                "inline": False
            },
            {
                "name": "ğŸ’» Cluster Status",
                "value": f"**Cores:** {cores_used}/{total_cores} ({usage_percent}%)\n"
                         f"**Workers:** {cluster_status.get('alive_workers', 0)}\n"
                         f"**Apps:** {cluster_status.get('active_apps', 0)}",
                "inline": True
            }
        ],
        "footer": {
            "text": "VerificaÃ§Ã£o a cada 5 minutos"
        },
        "timestamp": timestamp
    }
    
    # Envia apenas se for uma situaÃ§Ã£o especial (nÃ£o enviar a cada 5 min)
    # Pode ser ativado para debug
    # send_discord_notification(DISCORD_WEBHOOK_URL, embed)


def notify_job_failure(job_name, error_message, cluster_status, attempted_restart=False):
    """
    Notifica falha crÃ­tica de um job.
    
    Args:
        job_name: Nome do job que falhou
        error_message: Mensagem de erro
        cluster_status: Status do cluster
        attempted_restart: Se tentou reiniciar
    """
    timestamp = datetime.now().isoformat()
    
    title = "âŒ Falha CrÃ­tica no Streaming" if not attempted_restart else "âš ï¸ Job Reiniciado ApÃ³s Falha"
    color = COLOR_ERROR if not attempted_restart else COLOR_WARNING
    
    embed = {
        "title": title,
        "description": f"O job **{job_name}** apresentou falha",
        "color": color,
        "fields": [
            {
                "name": "ğŸ”´ Job Afetado",
                "value": f"**{job_name}**",
                "inline": True
            },
            {
                "name": "ğŸ“Š Status Cluster",
                "value": f"**Cores livres:** {cluster_status.get('cores_free', 0)}\n"
                         f"**Workers:** {cluster_status.get('alive_workers', 0)}",
                "inline": True
            },
            {
                "name": "ğŸ’¥ Erro",
                "value": f"```{error_message[:1000]}```",  # Limita tamanho
                "inline": False
            }
        ],
        "footer": {
            "text": "Verificar logs do Spark Master para mais detalhes"
        },
        "timestamp": timestamp
    }
    
    if attempted_restart:
        embed["fields"].append({
            "name": "ğŸ”„ AÃ§Ã£o Tomada",
            "value": "Tentativa automÃ¡tica de reiniciar o job",
            "inline": False
        })
    
    send_discord_notification(DISCORD_WEBHOOK_URL, embed, content="@here" if not attempted_restart else None)


def notify_cluster_unhealthy(cluster_status, reason):
    """
    Notifica que o cluster Spark estÃ¡ com problemas.
    
    Args:
        cluster_status: Status do cluster
        reason: Motivo do problema
    """
    timestamp = datetime.now().isoformat()
    
    embed = {
        "title": "ğŸš¨ Cluster Spark com Problemas",
        "description": "O cluster Spark nÃ£o estÃ¡ saudÃ¡vel",
        "color": COLOR_ERROR,
        "fields": [
            {
                "name": "âš ï¸ Problema Detectado",
                "value": reason,
                "inline": False
            },
            {
                "name": "ğŸ“Š Status Atual",
                "value": f"**Workers ativos:** {cluster_status.get('alive_workers', 0)}\n"
                         f"**Cores totais:** {cluster_status.get('total_cores', 0)}\n"
                         f"**Apps ativos:** {cluster_status.get('active_apps', 0)}",
                "inline": True
            },
            {
                "name": "ğŸ”§ AÃ§Ã£o NecessÃ¡ria",
                "value": "Verificar status dos containers:\n"
                         "```\n"
                         "docker ps\n"
                         "docker logs fraud_spark_master\n"
                         "```",
                "inline": False
            }
        ],
        "footer": {
            "text": "Os jobs de streaming podem estar parados"
        },
        "timestamp": timestamp
    }
    
    send_discord_notification(DISCORD_WEBHOOK_URL, embed, content="@here")


def notify_supervisor_execution(status, jobs_started=None, jobs_failed=None, cluster_status=None):
    """
    Notifica resultado da execuÃ§Ã£o do supervisor.
    
    Args:
        status: 'success', 'partial', 'failed'
        jobs_started: Lista de jobs iniciados
        jobs_failed: Lista de jobs que falharam
        cluster_status: Status do cluster
    """
    timestamp = datetime.now().isoformat()
    
    if status == 'success':
        color = COLOR_SUCCESS
        title = "âœ… Supervisor Executado com Sucesso"
        description = "Todos os jobs estÃ£o rodando normalmente"
    elif status == 'partial':
        color = COLOR_WARNING
        title = "âš ï¸ ExecuÃ§Ã£o Parcial do Supervisor"
        description = "Alguns jobs foram iniciados, mas outros falharam"
    else:
        color = COLOR_ERROR
        title = "âŒ Falha na ExecuÃ§Ã£o do Supervisor"
        description = "NÃ£o foi possÃ­vel garantir todos os jobs rodando"
    
    fields = []
    
    if jobs_started:
        fields.append({
            "name": "âœ… Jobs Iniciados",
            "value": "\n".join([f"â€¢ {job}" for job in jobs_started]) or "Nenhum",
            "inline": True
        })
    
    if jobs_failed:
        fields.append({
            "name": "âŒ Falhas",
            "value": "\n".join([f"â€¢ {job}" for job in jobs_failed]) or "Nenhum",
            "inline": True
        })
    
    if cluster_status:
        total_cores = cluster_status.get('total_cores', 0)
        cores_used = cluster_status.get('cores_used', 0)
        usage_percent = (cores_used * 100 // total_cores) if total_cores > 0 else 0
        
        fields.append({
            "name": "ğŸ’» Cluster",
            "value": f"**Cores:** {cores_used}/{total_cores} ({usage_percent}%)\n"
                     f"**Workers:** {cluster_status.get('alive_workers', 0)}",
            "inline": True
        })
    
    embed = {
        "title": title,
        "description": description,
        "color": color,
        "fields": fields,
        "footer": {
            "text": "PrÃ³xima verificaÃ§Ã£o em 5 minutos"
        },
        "timestamp": timestamp
    }
    
    # Menciona @here apenas em falhas
    content = "@here" if status == 'failed' else None
    send_discord_notification(DISCORD_WEBHOOK_URL, embed, content=content)


# FunÃ§Ã£o de teste
if __name__ == "__main__":
    print("ğŸ§ª Testando notificaÃ§Ãµes Discord...")
    
    # Teste 1: Jobs iniciados
    test_jobs = [
        {"name": "streaming_to_postgres", "cores": 4, "memory": "1g"},
        {"name": "streaming_realtime_dashboard", "cores": 2, "memory": "1g"}
    ]
    test_cluster = {
        "alive_workers": 5,
        "total_cores": 10,
        "cores_used": 6,
        "cores_free": 4,
        "active_apps": 2
    }
    
    print("ğŸ“¤ Enviando: Jobs iniciados...")
    notify_jobs_started(test_jobs, test_cluster)
    
    print("âœ… Teste concluÃ­do! Verifique o Discord.")


# ================================================================
# ğŸ… NOTIFICAÃ‡Ã•ES DO BATCH PIPELINE (Medallion)
# ================================================================

def notify_batch_started(dag_run_id, scheduled_time):
    """
    Notifica que o pipeline batch iniciou.
    
    Args:
        dag_run_id: ID da execuÃ§Ã£o da DAG
        scheduled_time: HorÃ¡rio agendado
    """
    timestamp = datetime.now().isoformat()
    
    embed = {
        "title": "ğŸ… Pipeline Batch Iniciado",
        "description": "O pipeline Medallion (Bronze â†’ Silver â†’ Gold â†’ Postgres) iniciou",
        "color": COLOR_INFO,
        "fields": [
            {
                "name": "ğŸ“‹ Etapas",
                "value": "```\n"
                         "1. ğŸ”§ Preparar recursos (streaming â†’ 40%)\n"
                         "2. ğŸ¥‰ Bronze - IngestÃ£o de dados brutos\n"
                         "3. ğŸ¥ˆ Silver - Limpeza e transformaÃ§Ã£o\n"
                         "4. ğŸ¥‡ Gold - AgregaÃ§Ãµes e mÃ©tricas\n"
                         "5. ğŸ—„ï¸ Postgres - Carregar para BI\n"
                         "6. ğŸ”„ Restaurar streaming (100%)\n"
                         "```",
                "inline": False
            },
            {
                "name": "âš™ï¸ Recursos",
                "value": "**Batch:** 6 cores (60%)\n"
                         "**Streaming:** 4 cores (40%)",
                "inline": True
            },
            {
                "name": "ğŸ• Agendamento",
                "value": f"**HorÃ¡rio:** {scheduled_time}\n"
                         f"**Run ID:** `{dag_run_id[:20]}...`",
                "inline": True
            }
        ],
        "footer": {
            "text": "Medallion Pipeline - Spark Fraud Detection"
        },
        "timestamp": timestamp
    }
    
    send_discord_notification(DISCORD_WEBHOOK_URL, embed)


def notify_batch_task_completed(task_name, duration_seconds, records_processed=None):
    """
    Notifica que uma etapa do batch foi concluÃ­da.
    
    Args:
        task_name: Nome da task (bronze, silver, gold, postgres)
        duration_seconds: DuraÃ§Ã£o em segundos
        records_processed: NÃºmero de registros processados (opcional)
    """
    # Mapeia task para emoji e descriÃ§Ã£o
    task_info = {
        "bronze_ingestion": ("ğŸ¥‰", "Bronze", "IngestÃ£o de dados brutos"),
        "silver_transformation": ("ğŸ¥ˆ", "Silver", "Limpeza e transformaÃ§Ã£o"),
        "gold_aggregation": ("ğŸ¥‡", "Gold", "AgregaÃ§Ãµes e mÃ©tricas"),
        "load_to_postgres": ("ğŸ—„ï¸", "Postgres", "Carregamento para BI"),
        "prepare_resources": ("ğŸ”§", "Recursos", "PreparaÃ§Ã£o de recursos"),
        "restore_resources": ("ğŸ”„", "Restaurar", "RestauraÃ§Ã£o de streaming"),
    }
    
    emoji, layer, description = task_info.get(task_name, ("ğŸ“¦", task_name, ""))
    
    # Formata duraÃ§Ã£o
    minutes = int(duration_seconds // 60)
    seconds = int(duration_seconds % 60)
    duration_str = f"{minutes}m {seconds}s" if minutes > 0 else f"{seconds}s"
    
    # NÃ£o notifica cada task individualmente para evitar spam
    # Apenas loga - a notificaÃ§Ã£o final Ã© mais importante
    print(f"âœ… {emoji} {layer}: {duration_str}")


def notify_batch_completed(dag_run_id, total_duration_seconds, tasks_status):
    """
    Notifica que o pipeline batch foi concluÃ­do com sucesso.
    
    Args:
        dag_run_id: ID da execuÃ§Ã£o
        total_duration_seconds: DuraÃ§Ã£o total em segundos
        tasks_status: DicionÃ¡rio com status de cada task
    """
    timestamp = datetime.now().isoformat()
    
    # Formata duraÃ§Ã£o total
    minutes = int(total_duration_seconds // 60)
    seconds = int(total_duration_seconds % 60)
    duration_str = f"{minutes}m {seconds}s" if minutes > 0 else f"{seconds}s"
    
    # Cria resumo das tasks
    tasks_summary = ""
    for task_name, status in tasks_status.items():
        emoji = "âœ…" if status == "success" else "âŒ"
        task_display = task_name.replace("_", " ").title()
        tasks_summary += f"{emoji} {task_display}\n"
    
    embed = {
        "title": "ğŸ‰ Pipeline Batch ConcluÃ­do!",
        "description": "Todas as etapas do Medallion Pipeline foram executadas com sucesso",
        "color": COLOR_SUCCESS,
        "fields": [
            {
                "name": "ğŸ“Š Resumo das Etapas",
                "value": f"```\n{tasks_summary}```",
                "inline": False
            },
            {
                "name": "â±ï¸ DuraÃ§Ã£o Total",
                "value": duration_str,
                "inline": True
            },
            {
                "name": "ğŸ”„ PrÃ³xima ExecuÃ§Ã£o",
                "value": "AmanhÃ£ Ã s 00:00",
                "inline": True
            }
        ],
        "footer": {
            "text": f"Run ID: {dag_run_id[:30]}"
        },
        "timestamp": timestamp
    }
    
    send_discord_notification(DISCORD_WEBHOOK_URL, embed)


def notify_batch_failed(dag_run_id, failed_task, error_message, tasks_completed):
    """
    Notifica que o pipeline batch falhou.
    
    Args:
        dag_run_id: ID da execuÃ§Ã£o
        failed_task: Task que falhou
        error_message: Mensagem de erro
        tasks_completed: Lista de tasks que completaram antes da falha
    """
    timestamp = datetime.now().isoformat()
    
    # Mapeia task para nome amigÃ¡vel
    task_names = {
        "bronze_ingestion": "ğŸ¥‰ Bronze - IngestÃ£o",
        "silver_transformation": "ğŸ¥ˆ Silver - TransformaÃ§Ã£o",
        "gold_aggregation": "ğŸ¥‡ Gold - AgregaÃ§Ã£o",
        "load_to_postgres": "ğŸ—„ï¸ Postgres - Carregamento",
        "prepare_resources": "ğŸ”§ Preparar Recursos",
        "restore_resources": "ğŸ”„ Restaurar Streaming",
    }
    
    failed_task_name = task_names.get(failed_task, failed_task)
    
    # Cria lista de tasks completadas
    completed_str = "\n".join([f"âœ… {task_names.get(t, t)}" for t in tasks_completed]) or "Nenhuma"
    
    embed = {
        "title": "âŒ Pipeline Batch Falhou!",
        "description": f"O pipeline parou na etapa: **{failed_task_name}**",
        "color": COLOR_ERROR,
        "fields": [
            {
                "name": "ğŸ”´ Task com Falha",
                "value": failed_task_name,
                "inline": True
            },
            {
                "name": "âœ… Tasks Completadas",
                "value": completed_str,
                "inline": True
            },
            {
                "name": "ğŸ’¥ Erro",
                "value": f"```\n{error_message[:800]}\n```",
                "inline": False
            },
            {
                "name": "ğŸ”§ AÃ§Ã£o AutomÃ¡tica",
                "value": "Streaming restaurado para 100% (se aplicÃ¡vel)",
                "inline": False
            },
            {
                "name": "ğŸ“‹ Investigar",
                "value": "```\n"
                         "# Ver logs da DAG:\n"
                         "Airflow UI â†’ DAGs â†’ medallion_pipeline â†’ Logs\n\n"
                         "# Ver logs do Spark:\n"
                         "docker logs fraud_spark_master\n"
                         "```",
                "inline": False
            }
        ],
        "footer": {
            "text": f"Run ID: {dag_run_id[:30]}"
        },
        "timestamp": timestamp
    }
    
    send_discord_notification(DISCORD_WEBHOOK_URL, embed, content="@here")
