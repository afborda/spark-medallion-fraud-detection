# ğŸš¨ Por que 3 MilhÃµes de Mensagens no Kafka Impediam o Streaming?

## ğŸ“– Guia Completo para Iniciantes

Este documento explica **em detalhes** por que ter 3 milhÃµes de mensagens acumuladas no Kafka impediu o funcionamento correto do pipeline de streaming, e como isso foi resolvido.

---

## ğŸ“‹ Ãndice

1. [O que Aconteceu?](#o-que-aconteceu)
2. [Conceitos BÃ¡sicos: O que Ã© Kafka?](#conceitos-bÃ¡sicos-o-que-Ã©-kafka)
3. [Conceitos BÃ¡sicos: O que Ã© Spark Streaming?](#conceitos-bÃ¡sicos-o-que-Ã©-spark-streaming)
4. [Por que 3M de Mensagens Ã© um Problema?](#por-que-3m-de-mensagens-Ã©-um-problema)
5. [Os 5 Problemas EspecÃ­ficos](#os-5-problemas-especÃ­ficos)
6. [Como Foi Resolvido?](#como-foi-resolvido)
7. [ConfiguraÃ§Ãµes Kafka Importantes](#configuraÃ§Ãµes-kafka-importantes)
8. [LiÃ§Ãµes Aprendidas](#liÃ§Ãµes-aprendidas)
9. [Comandos Ãšteis](#comandos-Ãºteis)

---

## ğŸ¯ O que Aconteceu?

### CenÃ¡rio Real do Projeto

```
ğŸ“Š Estado Inicial (11/Dez/2025):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Topic: transactions
PartiÃ§Ãµes: 1
Mensagens acumuladas: 132,088 (â‰ˆ132 mil)
Tamanho estimado: ~265 MB (2KB/mensagem)
Retention: 10GB mÃ¡ximo
Status: âš ï¸ ACUMULANDO (nÃ£o estÃ¡ sendo consumido)
```

**O problema:** O Spark Streaming iniciava, mas nÃ£o conseguia processar as mensagens de forma eficiente. O job ficava travado tentando ler o backlog de 132 mil mensagens acumuladas.

**Sintomas observados:**
- âœ… Kafka rodando normalmente
- âœ… Spark Streaming iniciava sem erros
- âŒ Consumo extremamente lento (< 10 msg/s)
- âŒ Job reiniciava antes de completar o processamento
- âŒ Dashboard do Metabase sem dados novos
- âŒ PostgreSQL nÃ£o recebia transaÃ§Ãµes

---

## ğŸ“š Conceitos BÃ¡sicos: O que Ã© Kafka?

### Apache Kafka em Linguagem Simples

Imagine o Kafka como um **sistema de correio** ultra-rÃ¡pido:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PRODUTOR   â”‚â”€â”€â”€â”€â”€â–¶â”‚    KAFKA    â”‚â”€â”€â”€â”€â”€â–¶â”‚  CONSUMIDOR â”‚
â”‚ (quem envia)â”‚      â”‚  (correio)  â”‚      â”‚ (quem lÃª)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â”œâ”€ Topic: transactions
                           â”œâ”€ PartiÃ§Ã£o 0: [msg1, msg2, ...]
                           â””â”€ Retention: guarda por 10GB
```

### Componentes Principais:

#### 1. **Topic (TÃ³pico)**
Ã‰ como uma "caixa de correspondÃªncia" ou "fila" especÃ­fica para um tipo de mensagem.

```python
# Nosso projeto tem 1 topic:
Topic: "transactions"  # Todas as transaÃ§Ãµes bancÃ¡rias
```

#### 2. **Partition (PartiÃ§Ã£o)**
DivisÃ£o de um topic para paralelizar o processamento.

```
Topic: transactions
â”‚
â”œâ”€ Partition 0: [msg001, msg002, msg003, ...]  â† Nosso projeto (1 partiÃ§Ã£o)
â”œâ”€ Partition 1: [msg101, msg102, msg103, ...]
â””â”€ Partition 2: [msg201, msg202, msg203, ...]
```

**Nosso caso:** Apenas 1 partiÃ§Ã£o = processamento sequencial (mais lento).

#### 3. **Offset**
Ã‰ um "marcador" de posiÃ§Ã£o na fila. Cada mensagem tem um nÃºmero Ãºnico crescente.

```
Offset:    0      1      2      3      4      5    ...  132087
          â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
Messages: â”‚ TX1 â”‚ TX2 â”‚ TX3 â”‚ TX4 â”‚ TX5 â”‚ TX6 â”‚ ...
          â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
               â–²                                    â–²
            inÃ­cio                                 fim
         (earliest)                            (latest)
```

**Importante:** 
- Offset **0** = mensagem mais antiga
- Offset **132,087** = mensagem mais recente (Ãºltima no tÃ³pico)

#### 4. **Consumer Group (Grupo de Consumidores)**
Consumidores com o mesmo `group.id` compartilham o trabalho de ler mensagens.

```python
# Spark Streaming cria automaticamente:
group.id = "spark-kafka-streaming-<uuid>"

# Kafka guarda: "Esse grupo jÃ¡ leu atÃ© o offset 1000"
```

#### 5. **Retention (RetenÃ§Ã£o)**
Por quanto tempo/quanto espaÃ§o o Kafka guarda mensagens.

```yaml
# Nossa configuraÃ§Ã£o (docker-compose.yml):
KAFKA_LOG_RETENTION_BYTES: 10737418240  # 10GB
KAFKA_LOG_RETENTION_HOURS: -1          # Infinito (limitado por espaÃ§o)
```

**Significado:** Kafka guarda mensagens atÃ© ocupar 10GB, depois apaga as mais antigas.

---

## ğŸ¯ Conceitos BÃ¡sicos: O que Ã© Spark Streaming?

### Spark Structured Streaming em Linguagem Simples

Ã‰ um sistema que processa dados **em tempo real** (ou quase) de forma contÃ­nua.

```
     KAFKA              SPARK              BANCO DE DADOS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TransaÃ§Ãµes   â”‚â”€â”€â–¶â”‚ Processa     â”‚â”€â”€â–¶â”‚ PostgreSQL   â”‚
â”‚ chegando     â”‚   â”‚ em microbatchâ”‚   â”‚ salva dados  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    (fonte)         (processamento)      (destino)
```

### Modo de OperaÃ§Ã£o: Microbatch

Spark Streaming **NÃƒO** processa mensagem por mensagem. Ele agrupa em pequenos lotes:

```
Intervalo de Trigger: 10 segundos (nosso projeto)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TIMELINE                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 00:00 â”€â”€â”€â”€â”€â–¶ LÃª 100 msgs â”€â”€â”€â”€â”€â–¶ Processa           â”‚
â”‚ 00:10 â”€â”€â”€â”€â”€â–¶ LÃª 150 msgs â”€â”€â”€â”€â”€â–¶ Processa           â”‚
â”‚ 00:20 â”€â”€â”€â”€â”€â–¶ LÃª  80 msgs â”€â”€â”€â”€â”€â–¶ Processa           â”‚
â”‚ 00:30 â”€â”€â”€â”€â”€â–¶ LÃª 200 msgs â”€â”€â”€â”€â”€â–¶ Processa           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Problema com Backlog:** Se hÃ¡ 132 mil mensagens esperando, o primeiro batch tenta ler TODAS de uma vez!

---

## âš ï¸ Por que 3M de Mensagens Ã© um Problema?

### Analogia: Correio Acumulado

Imagine que vocÃª saiu de fÃ©rias por 1 ano e voltou para encontrar **132 mil cartas** na sua caixa postal:

```
CenÃ¡rio Normal (streaming funcionando):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“¬ Caixa Postal                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”  â† 10 cartas/dia         â”‚
â”‚ â”‚ âœ‰âœ‰ â”‚                          â”‚
â”‚ â””â”€â”€â”€â”€â”˜                          â”‚
â”‚ VocÃª consegue ler diariamente   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

CenÃ¡rio com Backlog (3M acumulado):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“¬ Caixa Postal                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰ â”‚ â”‚
â”‚ â”‚ âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰ â”‚ â”‚
â”‚ â”‚ âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰ â”‚ â”‚
â”‚ â”‚ âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰âœ‰ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ 132,088 cartas = SOBRECARGA!   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**O que acontece?**
1. VocÃª tenta ler tudo de uma vez â†’ Sobrecarga mental ğŸ¤¯
2. Desiste no meio â†’ NÃ£o leu nenhuma carta completamente
3. Precisa comeÃ§ar do zero novamente
4. Ciclo vicioso: nunca consegue esvaziar a caixa

**Isso Ã© exatamente o que acontece com Spark + Kafka!**

---

## ğŸ”¥ Os 5 Problemas EspecÃ­ficos

### 1ï¸âƒ£ Problema de MemÃ³ria (Memory Overflow)

```python
# Spark tenta carregar TUDO na memÃ³ria de uma vez:
Batch 1: Tenta ler 132,088 mensagens Ã— 2KB = ~264 MB

# Com processamento, vira muito mais:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MemÃ³ria do Executor Spark (1GB)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ JSON bruto:        264 MB               â”‚
â”‚ DataFrame Spark:   800 MB (overhead)    â”‚
â”‚ Processamento:     400 MB               â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚
â”‚ TOTAL:            1464 MB > 1GB âŒ      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Resultado:** `OutOfMemoryError` ou garbage collection constante â†’ Job lento/travado.

---

### 2ï¸âƒ£ Problema de Timeout (First Batch Timeout)

Spark Streaming tem timeouts para inicializaÃ§Ã£o:

```
ConfiguraÃ§Ã£o:
spark.sql.streaming.kafka.consumer.pollTimeoutMs = 120000  # 2 minutos

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TIMELINE DO PRIMEIRO BATCH                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 00:00 â”€â”€â”€â”€â”€â–¶ Inicia job                         â”‚
â”‚ 00:05 â”€â”€â”€â”€â”€â–¶ Conecta no Kafka                   â”‚
â”‚ 00:10 â”€â”€â”€â”€â”€â–¶ Descobre 132k mensagens            â”‚
â”‚ 00:15 â”€â”€â”€â”€â”€â–¶ ComeÃ§a a ler (lento!)              â”‚
â”‚ 01:00 â”€â”€â”€â”€â”€â–¶ Ainda lendo... (25% completo)      â”‚
â”‚ 02:00 â”€â”€â”€â”€â”€â–¶ â° TIMEOUT! Job falha              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Por que Ã© lento?**
- 1 Ãºnica partiÃ§Ã£o = 1 thread lendo
- Rede Docker = overhead adicional
- DesserializaÃ§Ã£o JSON = CPU-bound

---

### 3ï¸âƒ£ Problema de Checkpoint Corruption

Spark Streaming salva o progresso em checkpoints:

```
Checkpoints salvos em: /data/checkpoints/streaming_postgres/

Estrutura:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ offsets/0                              â”‚  â† "Li atÃ© offset 50,000"
â”‚ offsets/1                              â”‚  â† "Li atÃ© offset 75,000"
â”‚ offsets/2                              â”‚  â† "Li atÃ© offset 90,000"
â”‚ commits/0                              â”‚  â† "Salvei atÃ© offset 48,000"
â”‚ metadata                               â”‚  â† ConfiguraÃ§Ãµes do stream
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Problema:** Job reinicia antes de completar o batch:

```
Tentativa 1:
- LÃª offsets 0 â†’ 132,088
- Processa 30% (40,000 mensagens)
- Job mata por falta de memÃ³ria
- Checkpoint: salvo atÃ© 40,000

Tentativa 2:
- LÃª offsets 40,000 â†’ 132,088  (ainda 92k mensagens!)
- Processa 20% (18,000 mensagens)
- Job mata novamente
- Checkpoint: salvo atÃ© 58,000

Tentativa 3-10: Mesmo problema... â™»ï¸ Loop infinito
```

---

### 4ï¸âƒ£ Problema de PartiÃ§Ã£o Ãšnica (No Parallelism)

```
Kafka Topic: transactions
PartiÃ§Ãµes: 1  â† GARGALO!

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Se tivÃ©ssemos 4 partiÃ§Ãµes:                      â”‚
â”‚                                                 â”‚
â”‚ Partition 0: [33k msgs] â”€â”€â”€â”€â”€â”€â–¶ Executor 1     â”‚
â”‚ Partition 1: [33k msgs] â”€â”€â”€â”€â”€â”€â–¶ Executor 2     â”‚
â”‚ Partition 2: [33k msgs] â”€â”€â”€â”€â”€â”€â–¶ Executor 3     â”‚
â”‚ Partition 3: [33k msgs] â”€â”€â”€â”€â”€â”€â–¶ Executor 4     â”‚
â”‚                                                 â”‚
â”‚ Tempo: 132k / 4 = 33k cada = MAIS RÃPIDO âœ…    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Nosso cenÃ¡rio atual (1 partiÃ§Ã£o):              â”‚
â”‚                                                 â”‚
â”‚ Partition 0: [132k msgs] â”€â”€â”€â”€â”€â”€â–¶ Executor 1    â”‚
â”‚                    (todos os outros idle)       â”‚
â”‚                                                 â”‚
â”‚ Tempo: 132k Ã— 1 = LENTO âŒ                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 5ï¸âƒ£ Problema de EstratÃ©gia de Leitura (No maxOffsetsPerTrigger)

Spark pode limitar quantas mensagens lÃª por batch:

```python
# âŒ SEM limite (nosso caso):
spark.readStream \
    .format("kafka") \
    .option("subscribe", "transactions") \
    .load()

# Resultado: Tenta ler TODAS as 132k mensagens no primeiro batch

# âœ… COM limite:
spark.readStream \
    .format("kafka") \
    .option("subscribe", "transactions") \
    .option("maxOffsetsPerTrigger", 5000)  # LÃª no mÃ¡ximo 5k por vez
    .load()

# Resultado: LÃª em 27 batches (132k / 5k = 26.4)
```

**Timeline com limite:**

```
Batch 1: offsets    0 â†’  5,000  (10s)
Batch 2: offsets 5,000 â†’ 10,000  (10s)
Batch 3: offsets 10,000 â†’ 15,000 (10s)
...
Batch 27: offsets 130,000 â†’ 132,088 (10s)

Total: ~4.5 minutos para limpar backlog
```

---

## âœ… Como Foi Resolvido?

### SoluÃ§Ã£o Aplicada: Limpar Kafka e Reiniciar

```bash
# 1. Parar todos os jobs de streaming
docker exec -it fraud_spark_master bash -c "
  kill \$(ps aux | grep streaming_to_postgres | grep -v grep | awk '{print \$2}')
  kill \$(ps aux | grep streaming_realtime_dashboard | grep -v grep | awk '{print \$2}')
"

# 2. Remover checkpoints antigos (forÃ§a reinÃ­cio do zero)
docker exec fraud_minio mc rm --recursive --force local/fraud-data/checkpoints/

# 3. Limpar mensagens do Kafka (resetar offset)
docker exec fraud_kafka kafka-topics \
  --bootstrap-server localhost:9092 \
  --delete \
  --topic transactions

# 4. Recriar topic do zero
docker exec fraud_kafka kafka-topics \
  --bootstrap-server localhost:9092 \
  --create \
  --topic transactions \
  --partitions 1 \
  --replication-factor 1 \
  --config retention.bytes=10737418240

# 5. Reiniciar jobs de streaming
docker exec fraud_spark_master spark-submit \
  --master spark://spark-master:7077 \
  --deploy-mode client \
  --total-executor-cores 2 \
  --executor-memory 1g \
  /jobs/streaming/streaming_to_postgres.py
```

### Por que Funcionou?

**Antes:**
```
Kafka: 132,088 mensagens esperando
Spark: Tenta processar tudo â†’ FALHA
```

**Depois:**
```
Kafka: 0 mensagens (limpo)
Spark: Inicia do zero
Producer: Envia 10-50 msgs/segundo
Spark: Processa 10-50 msgs/segundo (equilibrado!)
```

---

## âš™ï¸ ConfiguraÃ§Ãµes Kafka Importantes

### 1. ConfiguraÃ§Ã£o do TÃ³pico

```yaml
# docker-compose.yml
kafka:
  environment:
    # RetenÃ§Ã£o por tamanho (10GB)
    KAFKA_LOG_RETENTION_BYTES: 10737418240
    
    # RetenÃ§Ã£o por tempo (desabilitado = sÃ³ por tamanho)
    KAFKA_LOG_RETENTION_HOURS: -1
    
    # Tamanho mÃ¡ximo de cada segmento (1GB)
    KAFKA_LOG_SEGMENT_BYTES: 1073741824
    
    # Tempo para deletar segmentos inativos (7 dias)
    KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
```

### 2. ConfiguraÃ§Ã£o de Consumer (Spark)

```python
# spark/jobs/streaming/streaming_to_postgres.py
df_stream = spark.readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "kafka:9092") \
    .option("subscribe", "transactions") \
    .option("startingOffsets", "latest")  # â† IMPORTANTE!
    .option("maxOffsetsPerTrigger", 5000)  # â† ADICIONAR ISSO!
    .load()
```

**ExplicaÃ§Ã£o das opÃ§Ãµes:**

| OpÃ§Ã£o | Valor | O que faz |
|-------|-------|-----------|
| `startingOffsets` | `"latest"` | Ignora backlog, lÃª apenas mensagens novas |
| `startingOffsets` | `"earliest"` | LÃª TUDO desde o inÃ­cio (perigoso com backlog!) |
| `maxOffsetsPerTrigger` | `5000` | LÃª no mÃ¡ximo 5000 msgs por batch (previne sobrecarga) |
| `failOnDataLoss` | `false` | NÃ£o falha se mensagens antigas foram deletadas |

### 3. ConfiguraÃ§Ã£o de Checkpoint

```python
query = df_stream.writeStream \
    .format("jdbc") \
    .foreachBatch(write_to_postgres) \
    .option("checkpointLocation", "s3a://fraud-data/checkpoints/streaming_postgres") \
    .trigger(processingTime="10 seconds")  # Batch a cada 10s
    .start()
```

**Importante:** Se deletar checkpoints, Spark recomeÃ§a do `startingOffsets` configurado.

---

## ğŸ“– LiÃ§Ãµes Aprendidas

### 1ï¸âƒ£ Sempre Configure `maxOffsetsPerTrigger`

```python
# âŒ RUIM: Sem limite
.option("subscribe", "transactions")

# âœ… BOM: Com limite
.option("subscribe", "transactions") \
.option("maxOffsetsPerTrigger", 5000)
```

**Por quÃª?**
- Previne sobrecarga de memÃ³ria
- Permite processamento incremental
- Jobs mais estÃ¡veis e previsÃ­veis

---

### 2ï¸âƒ£ Use `startingOffsets = "latest"` em ProduÃ§Ã£o

```python
# ğŸ§ª DEV/TEST: Processa tudo (backfill)
.option("startingOffsets", "earliest")

# ğŸš€ PRODUÃ‡ÃƒO: Apenas dados novos
.option("startingOffsets", "latest")
```

**Quando usar `earliest`?**
- Primeira execuÃ§Ã£o (histÃ³rico pequeno < 10k msgs)
- Reprocessamento intencional (data fix)
- Ambiente de testes controlado

**Quando usar `latest`?**
- Job rodando continuamente em produÃ§Ã£o
- ApÃ³s limpar um backlog grande
- Quando sÃ³ importam dados novos

---

### 3ï¸âƒ£ Monitore o Lag do Consumer

```bash
# Comando para verificar lag (quantas msgs atrasadas):
docker exec fraud_kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --describe \
  --group spark-kafka-streaming-<UUID>

# Output:
# GROUP    TOPIC         PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG
# spark... transactions  0          132088          132088          0    â† OK!
# spark... transactions  0          50000           132088          82088 â† BACKLOG!
```

**MÃ©tricas importantes:**
- `LAG = 0` â†’ Perfeito! Consumindo em tempo real
- `LAG < 10,000` â†’ Ok, pequeno atraso
- `LAG > 50,000` â†’ Problema! Precisa investigar
- `LAG > 500,000` â†’ CrÃ­tico! Considere limpar e recomeÃ§ar

---

### 4ï¸âƒ£ Planeje Capacidade de Processamento

```python
# Calcule throughput necessÃ¡rio:

Taxa de produÃ§Ã£o: 50 msgs/seg (fraud-generator)
Tamanho mÃ©dio: 2 KB/msg
Throughput: 50 Ã— 2 KB = 100 KB/seg

# Spark precisa processar NO MÃNIMO 50 msgs/seg
# Recomendado: 2-3x = 100-150 msgs/seg (margem de seguranÃ§a)

# Configure recursos:
--total-executor-cores 2  # 2 cores = pode processar ~100 msgs/seg
--executor-memory 1g      # 1GB suficiente para batches de 5k msgs
```

---

### 5ï¸âƒ£ Teste com Volumes Pequenos Primeiro

```bash
# âŒ NÃƒO FAÃ‡A: Produzir 3M mensagens de uma vez
python fraud-generator/stream.py --count 3000000

# âœ… FAÃ‡A: Teste incremental
python fraud-generator/stream.py --count 1000    # 1k
# Verificar se Spark consome OK
python fraud-generator/stream.py --count 10000   # 10k
# Verificar se Spark consome OK
python fraud-generator/stream.py --count 100000  # 100k
# SÃ³ entÃ£o escalar para milhÃµes
```

---

## ğŸ› ï¸ Comandos Ãšteis

### Verificar Estado do Kafka

```bash
# 1. Listar tÃ³picos
docker exec fraud_kafka kafka-topics \
  --bootstrap-server localhost:9092 \
  --list

# 2. Ver detalhes de um tÃ³pico
docker exec fraud_kafka kafka-topics \
  --bootstrap-server localhost:9092 \
  --describe \
  --topic transactions

# Output:
# Topic: transactions
# PartitionCount: 1
# ReplicationFactor: 1
# Configs: retention.bytes=10737418240

# 3. Ver quantidade de mensagens (offset final)
docker exec fraud_kafka kafka-run-class kafka.tools.GetOffsetShell \
  --broker-list localhost:9092 \
  --topic transactions \
  --time -1

# Output: transactions:0:132088
#                         ^
#                         â””â”€ 132,088 mensagens
```

### Verificar Consumer Groups

```bash
# 1. Listar todos os grupos
docker exec fraud_kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --list

# 2. Ver detalhes de um grupo especÃ­fico
docker exec fraud_kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --describe \
  --group spark-kafka-streaming-XXXX

# 3. Resetar offset (CUIDADO! Reprocessa tudo)
docker exec fraud_kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --group spark-kafka-streaming-XXXX \
  --reset-offsets \
  --to-latest \
  --topic transactions \
  --execute
```

### Monitorar Jobs Spark

```bash
# 1. Ver jobs rodando
docker exec fraud_spark_master ps aux | grep streaming

# 2. Ver logs em tempo real
docker exec fraud_spark_master tail -f /spark/logs/streaming_*.log

# 3. Spark UI (navegador)
http://localhost:8080  # Cluster Spark
http://localhost:4040  # Job ativo (Streaming)
```

### Limpar Tudo e RecomeÃ§ar

```bash
# SCRIPT COMPLETO DE RESET:

#!/bin/bash
set -e

echo "ğŸ›‘ 1. Parando jobs de streaming..."
docker exec -it fraud_spark_master bash -c "
  pkill -f streaming_to_postgres || true
  pkill -f streaming_realtime_dashboard || true
"

echo "ğŸ—‘ï¸ 2. Removendo checkpoints..."
docker exec fraud_minio mc rm --recursive --force local/fraud-data/checkpoints/

echo "ğŸ—‘ï¸ 3. Deletando tÃ³pico Kafka..."
docker exec fraud_kafka kafka-topics \
  --bootstrap-server localhost:9092 \
  --delete \
  --topic transactions || true

sleep 5

echo "âœ¨ 4. Recriando tÃ³pico..."
docker exec fraud_kafka kafka-topics \
  --bootstrap-server localhost:9092 \
  --create \
  --topic transactions \
  --partitions 1 \
  --replication-factor 1 \
  --config retention.bytes=10737418240

echo "ğŸš€ 5. Reiniciando jobs..."
docker exec -d fraud_spark_master spark-submit \
  --master spark://spark-master:7077 \
  --deploy-mode client \
  --total-executor-cores 2 \
  --executor-memory 1g \
  /jobs/streaming/streaming_to_postgres.py

sleep 5

docker exec -d fraud_spark_master spark-submit \
  --master spark://spark-master:7077 \
  --deploy-mode client \
  --total-executor-cores 2 \
  --executor-memory 1g \
  /jobs/streaming/streaming_realtime_dashboard.py

echo "âœ… Pronto! Streaming reiniciado do zero."
echo "ğŸ“Š Verifique no Spark UI: http://localhost:8080"
```

---

## ğŸ“ Resumo Final (TL;DR)

### O Problema em 3 Frases

1. **132 mil mensagens acumuladas** no Kafka criaram um backlog gigante
2. **Spark tentou processar tudo de uma vez** no primeiro batch â†’ sobrecarga de memÃ³ria/timeout
3. **Job reiniciava antes de completar** â†’ loop infinito, nunca conseguia limpar o backlog

### A SoluÃ§Ã£o em 3 Passos

1. **Limpar Kafka e checkpoints** â†’ comeÃ§ar do zero
2. **Adicionar `maxOffsetsPerTrigger`** â†’ limitar mensagens por batch
3. **Usar `startingOffsets=latest`** â†’ ignorar backlog, processar apenas dados novos

### ConfiguraÃ§Ãµes CrÃ­ticas

```python
# Adicione sempre nos seus jobs de streaming:
.option("startingOffsets", "latest")           # Ignora backlog
.option("maxOffsetsPerTrigger", 5000)          # Limita batch
.option("failOnDataLoss", "false")             # Tolera perdas
.trigger(processingTime="10 seconds")          # Batch a cada 10s
.option("checkpointLocation", "s3a://...")     # Salva progresso
```

### Monitoramento Essencial

```bash
# Execute periodicamente:
docker exec fraud_kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --describe \
  --all-groups

# Se LAG > 10,000 por > 5 minutos â†’ Investigar!
```

---

## ğŸ“š ReferÃªncias e Links Ãšteis

### DocumentaÃ§Ã£o Oficial

- [Spark Structured Streaming + Kafka Guide](https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html)
- [Kafka Consumer Configuration](https://kafka.apache.org/documentation/#consumerconfigs)
- [Kafka Topic Configuration](https://kafka.apache.org/documentation/#topicconfigs)

### Artigos Relacionados

- [Handling Kafka Backlogs in Spark Streaming](https://www.databricks.com/blog/2021/02/24/best-practices-for-handling-late-arriving-data-in-spark-structured-streaming.html)
- [Spark Streaming Performance Tuning](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html#performance-tuning)

### Issues Relacionadas no Projeto

- `docs/ERROS_CONHECIDOS.md` - Erros com S3A e MinIO
- `docs/ARQUITETURA_COMPLETA.md` - VisÃ£o geral do pipeline
- `airflow/dags/streaming_supervisor.py` - DAG que monitora streaming

---

## âœï¸ Notas de ImplementaÃ§Ã£o

**Data:** 11 de dezembro de 2025  
**Autor:** Alberto Borda  
**Contexto:** Projeto `spark-medallion-fraud-detection`  
**Status do Bug:** âœ… Resolvido  

**ConfiguraÃ§Ã£o do Ambiente:**
- Kafka: Confluent 7.5.0 (1 broker, 1 partiÃ§Ã£o)
- Spark: 3.5.3 (1 master, 2 workers)
- Mensagens acumuladas: 132,088 (â‰ˆ265 MB)
- Jobs afetados: `streaming_to_postgres.py`, `streaming_realtime_dashboard.py`

**SoluÃ§Ã£o Implementada:**
1. Reset completo (Kafka + checkpoints)
2. ConfiguraÃ§Ã£o de `maxOffsetsPerTrigger = 5000`
3. Uso de `startingOffsets = "latest"`
4. DAG de supervisÃ£o via Airflow (`streaming_supervisor.py`)

---

**ğŸ‰ Fim do Documento**

Espero que este guia tenha esclarecido o problema dos 3 milhÃµes de mensagens no Kafka! Se tiver dÃºvidas, consulte os comandos na seÃ§Ã£o "Comandos Ãšteis" ou abra uma issue no repositÃ³rio.

**Happy Streaming! ğŸš€ğŸ“Š**
