# ğŸ Baking Dependencies - Imutabilidade de Infraestrutura

> **Data:** 2025-12-04  
> **PadrÃ£o:** Baking Dependencies / Immutable Infrastructure  
> **Contexto:** RefatoraÃ§Ã£o para eliminar configuraÃ§Ãµes manuais de JARs e credenciais hardcoded

---

## ğŸ“‹ Ãndice

1. [O Problema (Antes)](#o-problema-antes)
2. [A SoluÃ§Ã£o (Depois)](#a-soluÃ§Ã£o-depois)
3. [Arquivos Criados/Modificados](#arquivos-criadosmodificados)
4. [BenefÃ­cios](#benefÃ­cios)
5. [Como Funciona](#como-funciona)
6. [Comandos para Aplicar](#comandos-para-aplicar)

---

## ğŸ”´ O Problema (Antes)

### ConfiguraÃ§Ã£o de JARs Repetida em Cada Script

Cada script Spark precisava especificar manualmente os JARs necessÃ¡rios:

```python
# âŒ ANTES: Repetido em TODOS os scripts
spark = SparkSession.builder \
    .appName("BronzeLayer") \
    .config("spark.jars", "/jars/hadoop-aws-3.3.4.jar,/jars/aws-java-sdk-bundle-1.12.262.jar,/jars/postgresql-42.7.4.jar") \
    .config("spark.hadoop.fs.s3a.access.key", "minioadmin") \
    .config("spark.hadoop.fs.s3a.secret.key", "minioadmin123@@!!_2") \
    .config("spark.hadoop.fs.s3a.endpoint", "http://minio:9000") \
    .config("spark.hadoop.fs.s3a.path.style.access", "true") \
    .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem") \
    .getOrCreate()
```

### Problemas Identificados

| Problema | Impacto |
|----------|---------|
| ğŸ” **DuplicaÃ§Ã£o** | Mesma configuraÃ§Ã£o copiada em 10+ scripts |
| ğŸ”“ **SeguranÃ§a** | Credenciais hardcoded no cÃ³digo fonte |
| ğŸ› **ManutenÃ§Ã£o** | Mudar versÃ£o do JAR = alterar todos os scripts |
| ğŸš« **InconsistÃªncia** | FÃ¡cil esquecer um JAR em um script novo |
| ğŸ“¦ **Portabilidade** | DependÃªncia de caminhos especÃ­ficos |

---

## ğŸŸ¢ A SoluÃ§Ã£o (Depois)

### Baking Dependencies: JARs na Imagem Docker

```dockerfile
# Dockerfile.spark
FROM apache/spark:3.5.3

# JARs "assados" na imagem - sempre disponÃ­veis
COPY jars/*.jar /opt/spark/jars/

# ConfiguraÃ§Ãµes globais (sem secrets!)
COPY spark/conf/spark-defaults.conf /opt/spark/conf/
```

### Credenciais via Environment Variables

```yaml
# docker-compose.yml
spark-master:
  build:
    context: .
    dockerfile: Dockerfile.spark
  environment:
    - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY}
    - MINIO_SECRET_KEY=${MINIO_SECRET_KEY}
```

### Scripts Limpos e Focados

```python
# âœ… DEPOIS: Script limpo e seguro
from config import get_spark_session, apply_s3a_configs

spark = get_spark_session("BronzeLayer")
spark = apply_s3a_configs(spark)

# Agora sÃ³ a lÃ³gica de negÃ³cio!
```

---

## ğŸ“ Arquivos Criados/Modificados

### Novos Arquivos

| Arquivo | PropÃ³sito |
|---------|-----------|
| `Dockerfile.spark` | Imagem customizada com JARs embutidos |
| `spark/conf/spark-defaults.conf` | ConfiguraÃ§Ãµes S3A globais (sem secrets) |

### Arquivos Modificados

| Arquivo | MudanÃ§a |
|---------|---------|
| `docker-compose.yml` | Todos os serviÃ§os Spark usam `build:` ao invÃ©s de `image:` |
| `.env.example` | Adicionadas variÃ¡veis MINIO_ACCESS_KEY e MINIO_SECRET_KEY |
| `spark/jobs/config.py` | FunÃ§Ã£o `apply_s3a_configs()` lÃª credenciais de env vars |
| `spark/jobs/production/*.py` | Removidas configs duplicadas, usam `apply_s3a_configs()` |
| `spark/jobs/streaming/*.py` | Removidas configs duplicadas, usam `apply_s3a_configs()` |

---

## âœ… BenefÃ­cios

### Comparativo Antes Ã— Depois

| Aspecto | âŒ Antes | âœ… Depois |
|---------|----------|----------|
| **SeguranÃ§a** | Senhas no cÃ³digo Git | Env vars (nunca versionadas) |
| **ManutenÃ§Ã£o** | Alterar 10+ arquivos | Alterar 1 Dockerfile |
| **ConsistÃªncia** | JARs podem divergir | Mesma imagem = mesmos JARs |
| **CÃ³digo** | ~15 linhas de config por script | ~2 linhas |
| **Deploy** | "Works on my machine" | Imagem idÃªntica em qualquer lugar |
| **Debug** | "Qual JAR estÃ¡ faltando?" | Sempre completo |

### Por Que "Baking" (Assar)?

A analogia Ã© com assar um bolo:
- **Frying (Fritar):** Configurar em runtime = adicionar ingredientes na hora
- **Baking (Assar):** Tudo jÃ¡ estÃ¡ na imagem = bolo pronto para servir

> **Regra de Ouro:** Se algo nÃ£o muda entre deploys, deve estar NA imagem, nÃ£o configurado em runtime.

---

## âš™ï¸ Como Funciona

### 1. Build da Imagem (Uma vez)

```bash
docker compose build
```

Isso cria uma imagem `fraud-spark` com:
- Apache Spark 3.5.3
- hadoop-aws-3.3.4.jar
- aws-java-sdk-bundle-1.12.262.jar  
- postgresql-42.7.4.jar
- spark-defaults.conf configurado

### 2. Runtime (Cada execuÃ§Ã£o)

O `docker-compose.yml` injeta as credenciais:

```yaml
environment:
  - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY}
  - MINIO_SECRET_KEY=${MINIO_SECRET_KEY}
```

### 3. CÃ³digo Python lÃª do ambiente

```python
# config.py
def apply_s3a_configs(spark):
    return spark.builder \
        .config("spark.hadoop.fs.s3a.access.key", os.getenv("MINIO_ACCESS_KEY")) \
        .config("spark.hadoop.fs.s3a.secret.key", os.getenv("MINIO_SECRET_KEY")) \
        .getOrCreate()
```

### Fluxo Visual

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     BUILD TIME                               â”‚
â”‚  Dockerfile.spark                                            â”‚
â”‚  â”œâ”€â”€ COPY jars/*.jar â†’ /opt/spark/jars/                     â”‚
â”‚  â””â”€â”€ COPY spark-defaults.conf â†’ /opt/spark/conf/            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     RUN TIME                                 â”‚
â”‚  docker-compose.yml                                          â”‚
â”‚  â”œâ”€â”€ environment: MINIO_ACCESS_KEY, MINIO_SECRET_KEY        â”‚
â”‚  â””â”€â”€ .env file (gitignored)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PYTHON CODE                              â”‚
â”‚  config.py â†’ apply_s3a_configs(spark)                       â”‚
â”‚  â”œâ”€â”€ os.getenv("MINIO_ACCESS_KEY")                          â”‚
â”‚  â””â”€â”€ Retorna SparkSession configurado                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Comandos para Aplicar

### Primeira vez (ou apÃ³s mudanÃ§as no Dockerfile)

```bash
# Rebuild todas as imagens Spark
docker compose build

# Subir o cluster com as novas imagens
docker compose up -d
```

### Verificar se os JARs estÃ£o na imagem

```bash
# Listar JARs no container
docker exec fraud_spark_master ls /opt/spark/jars/ | grep -E "hadoop|aws|postgresql"
```

**SaÃ­da esperada:**
```
aws-java-sdk-bundle-1.12.262.jar
hadoop-aws-3.3.4.jar
postgresql-42.7.4.jar
```

### Testar se as env vars estÃ£o funcionando

```bash
# Verificar variÃ¡veis no container
docker exec fraud_spark_master env | grep MINIO
```

**SaÃ­da esperada:**
```
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin123@@!!_2
```

---

## ğŸ“š ReferÃªncias

- [12 Factor App - Config](https://12factor.net/config) - ConfiguraÃ§Ã£o via ambiente
- [Docker Best Practices](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/) - Baking dependencies
- [Spark Configuration](https://spark.apache.org/docs/latest/configuration.html) - spark-defaults.conf

---

## ğŸ”— Arquivos Relacionados

- [`Dockerfile.spark`](../Dockerfile.spark)
- [`spark/conf/spark-defaults.conf`](../spark/conf/spark-defaults.conf)
- [`docker-compose.yml`](../docker-compose.yml)
- [`spark/jobs/config.py`](../spark/jobs/config.py)
- [`.env.example`](../.env.example)
