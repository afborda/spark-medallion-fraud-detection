# ğŸš¨ Guia Completo: Kafka e Streaming no Pipeline

> **Ãšltima atualizaÃ§Ã£o:** 2025-12-23  
> **VersÃ£o:** 2.0 (Unificado)

---

## ğŸ“‹ Ãndice

1. [O que Ã© Kafka?](#o-que-Ã©-kafka)
2. [O Problema das 3M Mensagens](#o-problema-das-3m-mensagens)
3. [SoluÃ§Ã£o Implementada](#soluÃ§Ã£o-implementada)
4. [ConfiguraÃ§Ãµes CrÃ­ticas](#configuraÃ§Ãµes-crÃ­ticas)
5. [Troubleshooting](#troubleshooting)
6. [Comandos Ãšteis](#comandos-Ãºteis)

---

## ğŸ“š O que Ã© Kafka?

Apache Kafka Ã© uma **plataforma de streaming** que funciona como:
- **Buffer/Fila:** Armazena mensagens temporariamente
- **Pub/Sub:** Publicadores enviam, consumidores recebem
- **Log distribuÃ­do:** Persiste dados em disco

### Componentes Principais

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Producer    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚    Topic     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Consumer    â”‚
â”‚  (Gerador)   â”‚         â”‚ (transactions)â”‚         â”‚  (Spark)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                         â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ PartiÃ§Ãµes    â”‚
                         â”‚ (distribuiÃ§Ã£o)â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš¨ O Problema das 3M Mensagens

### O que Aconteceu?

No dia 11 de Dezembro de 2025, o sistema acumulou **3 milhÃµes de mensagens** no tÃ³pico Kafka `transactions` sem serem consumidas.

```
Estado do Kafka (11/Dez/2025):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Topic: transactions
Mensagens: 3,000,000 acumuladas
Tamanho: ~6 GB
Retention: 10GB (quase cheio!)
Status: âš ï¸ Kafka comeÃ§ando a dropar mensagens antigas
```

### Por que foi Problema?

#### 1. **MemÃ³ria do Spark Esgotada**
```
Spark recebe: 3M Ã— 2KB = 6GB de memÃ³ria necessÃ¡ria
Spark disponÃ­vel: 5GB (cluster de 2 workers Ã— 2.5GB cada)
Resultado: âŒ OutOfMemoryError
```

#### 2. **LatÃªncia InsuperÃ¡vel**
```
Consumo rate: 10 transaÃ§Ãµes/segundo (pior caso)
Tempo para processar backlog: 3,000,000 Ã· 10 = 300,000 segundos = 83 HORAS
Timeout padrÃ£o: 120 segundos âŒ (Spark cancela o job)
```

#### 3. **Offset Corrupto**
Spark nÃ£o sabia de qual mensagem continuar lendo:
```
last_consumed_offset = 132,088  (antiga)
current_kafka_offset = 3,000,000 (atual)
DiferenÃ§a: 2,867,912 mensagens para recuperar
```

#### 4. **RetenÃ§Ã£o do Kafka Atingindo Limite**
```
Retention configurado: 10GB
Mensagens atuais: ~6GB
EspaÃ§o livre: 4GB (somente!)
Kafka comeÃ§ou a descartar mensagens antigas
```

#### 5. **Deadlock com Micro-batches**
```
Spark Streaming (micro-batch a cada 5s):
Batch 1: 3M mensagens â†’ Tenta carregar na memÃ³ria â†’ BOOM!
Timeout â†’ Job cancela
PrÃ³ximo batch: Tenta novamente, mas offset desincronizado
```

---

## âœ… SoluÃ§Ã£o Implementada

### 1. **Limpar o Backlog do Kafka**
```bash
# Resetar consumer group para Ãºltimo offset
docker exec fraud_kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --group spark-streaming \
  --reset-offsets \
  --to-latest \
  --execute

# Resultado: Ignora 3M mensagens antigas, comeÃ§a do zero
```

### 2. **Reduzir Retention do Kafka**
```properties
# docker-compose.yml
KAFKA_LOG_RETENTION_HOURS: 24      # Era 168 (7 dias)
KAFKA_LOG_RETENTION_BYTES: 1073741824  # 1GB (era 10GB)
```

**Impacto:**
- Kafka nÃ£o accumula indefinidamente
- Auto-cleanup a cada 24h
- EspaÃ§o limitado = forÃ§a consumo rÃ¡pido

### 3. **Otimizar Spark Streaming**
```python
# spark-streaming.py
spark = SparkSession.builder \
    .config("spark.streaming.kafka.maxRatePerPartition", 10000) \
    .config("spark.streaming.backpressure.enabled", "true") \
    .config("spark.streaming.backpressure.initialRate", 5000) \
    .getOrCreate()

# ExplicaÃ§Ã£o:
# maxRatePerPartition: Max mensagens por partiÃ§Ã£o por batch
# backpressure: Ajusta rate dinamicamente se Spark estÃ¡ atrÃ¡s
```

### 4. **Aumentar Parallelismo**
```python
# Antes: 2 workers Ã— 1 core = 2 cores
# Depois: 2 workers Ã— 2 cores = 4 cores

# Antes: 5 segundo batch interval
# Depois: 2 segundo batch interval

# Resultado: 4x mais parallelismo + 2.5x mais batches/min
```

### 5. **Monitoramento ContÃ­nuo**
```bash
# Verificar lag do consumer group
docker exec fraud_kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --group spark-streaming \
  --describe

# SaÃ­da esperada:
# TOPIC    PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG
# tx       0          123456          123456          0  âœ… Tudo consumido
```

---

## ğŸ”§ ConfiguraÃ§Ãµes CrÃ­ticas

### Kafka (docker-compose.yml)
```yaml
KAFKA_LOG_RETENTION_HOURS: 24              # Limpar after 24h
KAFKA_LOG_RETENTION_BYTES: 1073741824      # 1GB mÃ¡ximo
KAFKA_LOG_SEGMENT_BYTES: 104857600         # 100MB por segmento
KAFKA_NUM_PARTITIONS: 3                    # 3 partiÃ§Ãµes para paralelismo
KAFKA_DEFAULT_REPLICATION_FACTOR: 1        # 1 rÃ©plica (dev)
```

### Spark Streaming (jobs/streaming_realtime_dashboard.py)
```python
# Taxa de leitura
maxRatePerPartition = 50000           # Max msgs/s por partiÃ§Ã£o
minPartitions = 4                     # Pelo menos 4 partiÃ§Ãµes

# Backpressure (controla velocidade)
spark.streaming.backpressure.enabled = "true"
spark.streaming.backpressure.initialRate = 25000

# Intervalo de batch
batchInterval = 2                     # 2 segundos

# Timeout
spark.streaming.kafka.maxRetries = 3
spark.streaming.kafka.metadata.max.age.ms = 30000  # 30s
```

---

## ğŸ› Troubleshooting

### Problema: "Consumer group is not active"
**Causa:** Spark parou de consumir, offset stuck
```bash
# SoluÃ§Ã£o:
docker exec fraud_kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --group spark-streaming \
  --delete

# Recria o grupo na prÃ³xima execuÃ§Ã£o
```

### Problema: "Timeout waiting for offset commit"
**Causa:** Spark processando muito lentamente
```python
# SoluÃ§Ã£o 1: Aumentar workers
docker-compose up -d spark-worker-3 spark-worker-4

# SoluÃ§Ã£o 2: Reduzir batch interval
batchInterval = 1  # De 2s para 1s

# SoluÃ§Ã£o 3: Aumentar timeout
spark.streaming.kafka.maxRetries = 5
```

### Problema: "Partition assignment has failed"
**Causa:** Kafka nÃ£o consegue rebalancear partiÃ§Ãµes
```bash
# SoluÃ§Ã£o: Reiniciar Kafka
docker-compose restart kafka

# Aguarde ~30s para rebalancear
docker exec fraud_kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --group spark-streaming \
  --describe
```

### Problema: "Message size exceeds broker's max.message.bytes"
**Causa:** TransaÃ§Ã£o muito grande
```python
# SoluÃ§Ã£o: Aumentar limite no Kafka
# docker-compose.yml
KAFKA_MAX_MESSAGE_BYTES: 16777216  # 16MB

# Depois: docker-compose restart kafka
```

---

## ğŸ“œ Comandos Ãšteis

### Monitorar Kafka em Tempo Real
```bash
# Ver tÃ³picos
docker exec fraud_kafka kafka-topics \
  --bootstrap-server localhost:9092 \
  --list

# Ver estatÃ­sticas do tÃ³pico
docker exec fraud_kafka kafka-topics \
  --bootstrap-server localhost:9092 \
  --topic transactions \
  --describe

# Contar mensagens no tÃ³pico
docker exec fraud_kafka kafka-run-class kafka.tools.JmxTool \
  --object-name kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions
```

### Consumir Mensagens Manualmente
```bash
# Ler Ãºltimas 10 mensagens
docker exec fraud_kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic transactions \
  --from-beginning \
  --max-messages 10

# Ler a partir de um offset especÃ­fico
docker exec fraud_kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic transactions \
  --partition 0 \
  --offset 1000
```

### Resetar Offsets
```bash
# Para latest (ignora tudo que existe)
docker exec fraud_kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --group spark-streaming \
  --reset-offsets \
  --to-latest \
  --execute

# Para earliest (reprocessa tudo)
docker exec fraud_kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --group spark-streaming \
  --reset-offsets \
  --to-earliest \
  --execute

# Para offset especÃ­fico
docker exec fraud_kafka kafka-consumer-groups \
  --bootstrap-server localhost:9092 \
  --group spark-streaming \
  --reset-offsets \
  --to-offset 0 \
  --execute
```

### Limpeza de Mensagens
```bash
# Deletar tÃ³pico (cuidado!)
docker exec fraud_kafka kafka-topics \
  --bootstrap-server localhost:9092 \
  --topic transactions \
  --delete

# Recri ar
docker exec fraud_kafka kafka-topics \
  --bootstrap-server localhost:9092 \
  --create \
  --topic transactions \
  --partitions 3 \
  --replication-factor 1
```

---

## ğŸ“Š MÃ©tricas de SaÃºde

### Bom Estado
```
LAG â‰¤ 100 mensagens     âœ… (Spark estÃ¡ consumindo rÃ¡pido)
Msg/sec â‰¥ 100           âœ… (Taxa de produÃ§Ã£o healthy)
Retention â‰¤ 70% do max  âœ… (EspaÃ§o disponÃ­vel)
Consumer lag trend: â†“   âœ… (Diminuindo backlog)
```

### Estado de Alerta
```
LAG > 1000 mensagens    âš ï¸ (ComeÃ§ar a escalar)
Msg/sec = 0             ğŸ”´ (Producer parou!)
Retention â‰¥ 90% do max  ğŸ”´ (Quase cheio!)
Consumer lag trend: â†‘   ğŸ”´ (Acumulando!)
```

---

## ğŸ“ LiÃ§Ãµes Aprendidas

1. **Kafka nÃ£o Ã© ilimitado** - Sempre configurar retention
2. **Spark tem limite de memÃ³ria** - Backpressure Ã© essencial
3. **Monitorar lag** - DiferenÃ§a entre produced e consumed
4. **MÃºltiplas partiÃ§Ãµes** - Aumenta paralelismo
5. **Testes de carga** - Descobrir problemas antes de produÃ§Ã£o

---

## ğŸ“š ReferÃªncias
- Kafka Documentation: https://kafka.apache.org/documentation/
- Spark Streaming Guide: https://spark.apache.org/docs/latest/streaming-programming-guide.html
- Our Project: `docs/ARQUITETURA_COMPLETA.md`, `docs/ANALISE_PROJETO_STATUS.md`
