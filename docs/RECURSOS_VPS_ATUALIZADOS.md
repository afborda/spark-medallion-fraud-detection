# üñ•Ô∏è Recursos VPS Atualizados - 8 vCores, 24 GB RAM

**Data:** 10 de dezembro de 2025  
**Autor:** Sistema de otimiza√ß√£o autom√°tica

---

## üìä Especifica√ß√µes da VPS

```yaml
Modelo: VPS-3
vCores: 8
Mem√≥ria: 24 GB
Armazenamento: 200 GB
```

---

## üîÑ Mudan√ßas Implementadas

### ‚ùå Configura√ß√£o Antiga (PROBLEM√ÅTICA)

```
SPARK CLUSTER:
- Master: sem limite
- Workers: 5 x (2 cores + 3 GB) = 10 cores + 15 GB
- TOTAL: 10 cores + ~16 GB

GERADORES:
- Streaming: 3.0 CPUs + 2 GB
- Batch: 4.0 CPUs + 8 GB

PROBLEMA:
‚úó 17 cores configurados (212% overcommit!)
‚úó 25 GB mem√≥ria (104% de uso)
```

### ‚úÖ Nova Configura√ß√£o (OTIMIZADA)

---

## üì¶ Distribui√ß√£o de Recursos por Servi√ßo

### üîß Infraestrutura (sempre ligada)

| Servi√ßo | CPU | Mem√≥ria | Limite CPU | Limite RAM |
|---------|-----|---------|-----------|-----------|
| PostgreSQL | 0.25 | 256 MB | 0.5 | 512 MB |
| Kafka | 0.25 | 512 MB | 0.5 | 1.0 GB |
| Zookeeper | 0.1 | 128 MB | 0.25 | 256 MB |
| MinIO | 0.1 | 256 MB | 0.25 | 512 MB |
| Airflow Web | 0.25 | 512 MB | 0.5 | 1.5 GB |
| Airflow Scheduler | 0.25 | 512 MB | 0.5 | 1.0 GB |
| Metabase | 0.25 | 512 MB | 0.5 | 1.5 GB |
| **SUBTOTAL** | **1.35** | **2.68 GB** | **3.0** | **6.25 GB** |

### ‚ö° Spark Cluster

| Componente | CPU | Mem√≥ria | Limite CPU | Limite RAM |
|------------|-----|---------|-----------|-----------|
| Master | 0.25 | 512 MB | 0.5 | 1.0 GB |
| Worker 1 | 0.5 | 1.0 GB | 1.0 | 2.5 GB |
| Worker 2 | 0.5 | 1.0 GB | 1.0 | 2.5 GB |
| Worker 3 | 0.5 | 1.0 GB | 1.0 | 2.5 GB |
| Worker 4 | 0.5 | 1.0 GB | 1.0 | 2.5 GB |
| ~~Worker 5~~ | ‚ùå REMOVIDO | ‚ùå | - | - |
| **SUBTOTAL** | **2.25** | **4.5 GB** | **4.5** | **11.0 GB** |

### üîÑ Geradores de Dados

| Modo | CPU | Mem√≥ria | Limite CPU | Limite RAM | Status |
|------|-----|---------|-----------|-----------|--------|
| Streaming | 0.25 | 256 MB | 0.5 | 1.0 GB | ‚úÖ Sempre ligado |
| Batch | 2.0 | 2.0 GB | 4.0 | 6.0 GB | ‚ö†Ô∏è Usar SEM streaming |

---

## üéØ Modos de Opera√ß√£o

### üü¢ MODO STREAMING (Padr√£o - 24/7)

```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë MODO STREAMING - Opera√ß√£o Normal                             ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë Infraestrutura:  3.0 cores  +  6.25 GB                       ‚ïë
‚ïë Spark Cluster:   4.5 cores  + 11.0 GB                        ‚ïë
‚ïë Streaming Gen:   0.5 cores  +  1.0 GB                        ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë TOTAL:           8.0 cores  + 18.25 GB  ‚úÖ                    ‚ïë
‚ïë MARGEM:          0 cores    +  5.75 GB (reserva sistema)     ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

JOBS SPARK ATIVOS:
- streaming_to_postgres: 2 cores + 1g executor memory
- streaming_realtime_dashboard: 2 cores + 1g executor memory
TOTAL JOBS: 4 cores (100% do cluster)
```

### üîµ MODO BATCH (Agendado - 03:00 diariamente)

```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë MODO BATCH - Processamento Pesado                            ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë Infraestrutura:  3.0 cores  +  6.25 GB                       ‚ïë
‚ïë Spark Cluster:   4.5 cores  + 11.0 GB                        ‚ïë
‚ïë Batch Generator: 4.0 cores  +  6.0 GB                        ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë TOTAL:          11.5 cores  + 23.25 GB  ‚ö†Ô∏è                    ‚ïë
‚ïë MARGEM:         -3.5 cores  +  0.75 GB (overcommit)          ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

‚ö†Ô∏è ATEN√á√ÉO: Streaming DEVE estar parado durante batch!

RECURSOS BATCH:
- Medallion Pipeline: 3 cores (75% do cluster)
- Streaming reduzido: 1 core (25% do cluster)
```

---

## üîÑ Fluxo de Recursos Automatizado

### Durante Pipeline Batch (Airflow)

```mermaid
graph LR
    A[Pipeline Batch Inicia] -->|1| B[Reduz Streaming para 1 core]
    B -->|2| C[Executa Batch com 3 cores]
    C -->|3| D[Restaura Streaming para 4 cores]
    D --> E[Pipeline Completo]
```

**Automa√ß√£o pelo Airflow:**
1. **prepare_resources**: Para streaming completo, reinicia com 1 core
2. **bronze/silver/gold**: Executa com 3 cores cada
3. **restore_resources**: Restaura streaming para 4 cores

---

## üìù Arquivos Modificados

### ‚úÖ Docker Compose

```bash
/docker-compose.yml
- Spark Workers: 5 ‚Üí 4 workers
- Worker cores: 2 ‚Üí 1 core/worker
- Worker memory: 3GB ‚Üí 2.5GB/worker
- fraud-generator: 3 CPUs ‚Üí 0.5 CPU
- fraud-generator-batch: 8GB ‚Üí 6GB
+ Limites adicionados em todos os servi√ßos
```

### ‚úÖ Airflow

```bash
/docker/docker-compose.airflow.yml
+ Webserver: limite 0.5 CPU, 1.5 GB
+ Scheduler: limite 0.5 CPU, 1.0 GB
```

### ‚úÖ DAGs Airflow

```bash
/airflow/dags/medallion_pipeline.py
- TOTAL_CORES: 10 ‚Üí 4
- STREAMING_CORES: 4 ‚Üí 1
- BATCH_CORES: 6 ‚Üí 3
- STREAMING_FULL_CORES: 10 ‚Üí 4

/airflow/dags/streaming_supervisor.py
- streaming_to_postgres cores: 4 ‚Üí 2
- streaming_realtime_dashboard cores: 2 ‚Üí 2
- TOTAL_STREAMING_CORES: 6 ‚Üí 4
- MAX_CLUSTER_USAGE: 60% ‚Üí 100%

/airflow/dags/discord_notifier.py
- Atualizado valores de cores para notifica√ß√µes
```

### ‚úÖ Scripts

```bash
/scripts/start_streaming.sh
- STREAMING_POSTGRES_CORES: 4 ‚Üí 2
- STREAMING_DASHBOARD_CORES: 2 ‚Üí 2
- TOTAL_STREAMING_CORES: 6 ‚Üí 4
```

---

## üöÄ Como Aplicar as Mudan√ßas

### 1Ô∏è‚É£ Parar Streaming Atual

```bash
docker exec fraud_spark_master pkill -9 -f "streaming" && sleep 2
```

### 2Ô∏è‚É£ Recriar Containers com Novos Limites

```bash
# Parar e remover worker 5
docker compose stop fraud_spark_worker_5
docker compose rm -f fraud_spark_worker_5

# Recriar workers com novos limites
docker compose up -d --force-recreate \
  fraud_spark_worker_1 \
  fraud_spark_worker_2 \
  fraud_spark_worker_3 \
  fraud_spark_worker_4

# Recriar servi√ßos de infraestrutura
docker compose up -d --force-recreate \
  postgres kafka zookeeper minio metabase

# Recriar Airflow
docker compose -f docker-compose.yml \
  -f docker/docker-compose.airflow.yml \
  up -d --force-recreate
```

### 3Ô∏è‚É£ Reiniciar Streaming com Novos Recursos

```bash
./scripts/start_streaming.sh
```

### 4Ô∏è‚É£ Verificar Recursos

```bash
docker stats --no-stream
```

---

## üìä Verifica√ß√£o de Recursos

### Comando para verificar uso real:

```bash
docker stats --no-stream --format \
  "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}"
```

### Verificar Spark UI:

- Master: http://localhost:8081
- Jobs: http://localhost:4040

### Verificar Airflow:

- UI: http://localhost:8888
- Login: admin/admin

---

## ‚ö†Ô∏è IMPORTANTE: Regras de Uso

### ‚úÖ PERMITIDO

- ‚úÖ Rodar streaming 24/7
- ‚úÖ Batch agendado √†s 03:00 (autom√°tico)
- ‚úÖ An√°lises leves no Metabase
- ‚úÖ Consultas SQL no PostgreSQL

### ‚ùå N√ÉO PERMITIDO

- ‚ùå Rodar batch + streaming ao mesmo tempo manualmente
- ‚ùå Executar gera√ß√µes de dados grandes durante o dia
- ‚ùå Iniciar Worker 5 (removido permanentemente)
- ‚ùå Ultrapassar limites de mem√≥ria configurados

---

## üéØ Benef√≠cios da Nova Configura√ß√£o

1. **‚úÖ Recursos dentro do limite da VPS**
   - CPU: 8.0 cores no modo streaming (100% utiliza√ß√£o eficiente)
   - RAM: 18.25 GB no modo streaming (76% da VPS, margem de 24%)

2. **‚úÖ Gerenciamento autom√°tico via Airflow**
   - Pipeline batch reduz streaming automaticamente
   - Restaura recursos ap√≥s conclus√£o

3. **‚úÖ Limites Docker evitam OOM (Out of Memory)**
   - Cada container tem limite definido
   - Sistema operacional protegido

4. **‚úÖ Monitoramento melhorado**
   - Docker stats mostra uso real vs limites
   - Alertas via Discord quando batch inicia/termina

5. **‚úÖ Performance otimizada**
   - Streaming usa 100% quando batch n√£o roda
   - Batch tem 75% dedicado quando necess√°rio

---

## üîç Troubleshooting

### Problema: Container sendo morto (OOMKilled)

```bash
# Verificar logs
docker logs <container_name> --tail 50

# Ajustar limite de mem√≥ria no docker-compose.yml
# Reiniciar container
docker compose up -d --force-recreate <service_name>
```

### Problema: Spark jobs n√£o iniciam

```bash
# Verificar recursos dispon√≠veis
curl -s http://localhost:8081/json/ | python3 -m json.tool

# Ver workers conectados
docker exec fraud_spark_master \
  curl -s http://localhost:8080/json/ | grep -i workers
```

### Problema: Batch e Streaming rodando simultaneamente

```bash
# Parar tudo
docker exec fraud_spark_master pkill -9 -f "spark-submit"

# Reiniciar apenas streaming
./scripts/start_streaming.sh
```

---

## üìà Pr√≥ximos Passos

1. **Monitorar uso por 1 semana**
   - Verificar picos de mem√≥ria
   - Ajustar limites se necess√°rio

2. **Otimizar ainda mais se necess√°rio**
   - Considerar compress√£o de dados
   - Tune Spark configurations

3. **Documentar padr√µes de uso**
   - Hor√°rios de pico
   - Consumo m√©dio por job

---

**‚úÖ CONFIGURA√á√ÉO COMPLETA E OTIMIZADA PARA VPS 8 vCores / 24 GB RAM**
