# üìä Comparativo Completo: Vers√µes do Gerador de Dados (v1 a v4)

## üéØ Resumo Executivo

Este documento compara todas as vers√µes do **Brazilian Fraud Data Generator**, mostrando a evolu√ß√£o de performance e as li√ß√µes aprendidas.

---

## üìà Tabela Comparativa Principal

| Vers√£o | M√©todo | CPU Real | Mem√≥ria | Tempo (1GB) | Velocidade | Status |
|--------|--------|----------|---------|-------------|------------|--------|
| **v1** | multiprocessing.Pool + JSON | 800% (8 cores) | ~2 GB | ~2 min | 8.3 MB/s | ‚úÖ Funcional |
| **v2** | ThreadPoolExecutor + Chunks 10K | 100% (1 core) | ~350 MB | 60 min | 0.28 MB/s | ‚úÖ Funcional (lento) |
| **v3** | ThreadPoolExecutor + Full File | 100% (1 core) | ~350 MB | 8.3 min | 2 MB/s | ‚úÖ Funcional |
| **v4** | ProcessPoolExecutor + Parquet | 400% (4 cores) | ~4 GB | 1.3 min | 13 MB/s | ‚úÖ Funcional |

---

## üìä Comparativo Visual

### ‚è±Ô∏è Tempo para Processar 1GB

```
v2 (Threading + Chunks):  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  60 min
v3 (Threading + Full):    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  8.3 min
v1 (Multiprocessing JSON): ‚ñà‚ñà  2 min
v4 (Multiprocessing Parq): ‚ñà  1.3 min ‚ö° MAIS R√ÅPIDO!
```

### üñ•Ô∏è Uso de CPU

```
v2 (Threading):
Core 1: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100%
Core 2: ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0%
Core 3: ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0%
Core 4: ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0%
TOTAL: 100% (25% do sistema)

v3 (Threading Otimizado):
Core 1: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100%
Core 2: ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0%
Core 3: ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0%
Core 4: ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 0%
TOTAL: 100% (25% do sistema)

v1 (Multiprocessing + JSON):
Core 1: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100%
Core 2: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100%
Core 3: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100%
Core 4: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100%
Core 5: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100%
Core 6: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100%
Core 7: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100%
Core 8: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100%
TOTAL: 800% (100% do sistema - 8 cores)

v4 (Multiprocessing + Parquet):
Core 1: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100%
Core 2: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100%
Core 3: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100%
Core 4: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 90%
TOTAL: 390% (97% do sistema - 4 cores) üî•
```

### üíæ Uso de Mem√≥ria RAM

```
v2: ‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  350 MB (mais econ√¥mico)
v3: ‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  350 MB (mais econ√¥mico)
v1: ‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  2 GB
v4: ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë  4 GB (mais consumidor)
```

---

## üîç An√°lise Detalhada de Cada Vers√£o

---

### üì¶ Vers√£o 1 (v1) - Baseline Original

| Caracter√≠stica | Valor |
|----------------|-------|
| **M√©todo** | `multiprocessing.Pool` |
| **Workers** | 8 |
| **Formato** | JSON (sem compress√£o) |
| **Destino** | Disco local (`/data/raw/`) |
| **Chunk Size** | Vari√°vel |

#### Performance Medida:
```
üìä M√âTRICAS v1:
‚îú‚îÄ‚îÄ Tempo (1GB): ~2 minutos
‚îú‚îÄ‚îÄ Tempo (50GB): ~2 horas
‚îú‚îÄ‚îÄ Throughput: 8.3 MB/s
‚îú‚îÄ‚îÄ CPU Usage: ~800% (8 cores)
‚îú‚îÄ‚îÄ Mem√≥ria Peak: ~2 GB
‚îî‚îÄ‚îÄ Status: ‚úÖ Funcional (baseline)
```

#### C√≥digo Principal:
```python
import multiprocessing

def generate_batch(args):
    """Worker function para multiprocessing.Pool"""
    batch_id, num_transactions = args
    transactions = []
    for i in range(num_transactions):
        tx = generate_single_transaction(...)
        transactions.append(tx)
    
    # Salva como JSON no disco local
    with open(f'/data/raw/batch_{batch_id}.json', 'w') as f:
        json.dump(transactions, f)
    return batch_id

# Execu√ß√£o paralela
with multiprocessing.Pool(processes=8) as pool:
    results = pool.map(generate_batch, batch_args)
```

#### ‚úÖ Vantagens:
- Paralelismo real (cada processo tem seu GIL)
- Alta velocidade de gera√ß√£o
- Uso eficiente de todos os cores

#### ‚ùå Desvantagens:
- Formato JSON √© ~2x maior que Parquet
- Sem compress√£o dos dados
- N√£o grava direto no Object Storage (MinIO)
- Requer etapa adicional de ingest√£o

---

### üì¶ Vers√£o 2 (v2) - Threading com Chunks Pequenos

| Caracter√≠stica | Valor |
|----------------|-------|
| **M√©todo** | `ThreadPoolExecutor` |
| **Workers** | 6 |
| **Formato** | Parquet + ZSTD |
| **Destino** | MinIO (S3-compatible) |
| **Chunk Size** | 10.000 transa√ß√µes |

#### Performance Medida:
```
üìä M√âTRICAS v2:
‚îú‚îÄ‚îÄ Tempo (1GB): 60 minutos ‚ö†Ô∏è MUITO LENTO
‚îú‚îÄ‚îÄ Tempo (50GB): ~50 horas (estimado)
‚îú‚îÄ‚îÄ Throughput: 0.28 MB/s
‚îú‚îÄ‚îÄ CPU Usage: ~100% (apenas 1 core!)
‚îú‚îÄ‚îÄ Mem√≥ria Peak: ~350 MB
‚îî‚îÄ‚îÄ Status: ‚úÖ Funcional mas invi√°vel
```

#### O Problema: GIL + Chunks Pequenos

```
üîí PROBLEMA DO GIL:
Threading em Python N√ÉO paraleliza c√≥digo CPU-bound.
Apenas 1 thread executa Python por vez!

üì¶ PROBLEMA DOS CHUNKS:
1 arquivo = 268.000 transa√ß√µes
268.000 √∑ 10.000 = 27 chunks por arquivo

Cada chunk tem overhead de:
  ‚îú‚îÄ‚îÄ Gerar dicts Python      (CPU-bound)
  ‚îú‚îÄ‚îÄ Criar DataFrame Pandas  (CPU-bound)
  ‚îú‚îÄ‚îÄ Serializar Parquet      (CPU-bound)
  ‚îú‚îÄ‚îÄ Escrever em BytesIO     (I/O)
  ‚îî‚îÄ‚îÄ Upload para MinIO       (I/O)

TOTAL: 27 √ó overhead = 60 minutos! üò±
```

#### C√≥digo Principal:
```python
from concurrent.futures import ThreadPoolExecutor

def generate_chunk(args):
    """Worker para gerar um chunk de 10K transa√ß√µes"""
    chunk_id, chunk_size = args
    transactions = []
    for i in range(chunk_size):
        tx = generate_transaction(...)
        transactions.append(tx)
    
    df = pd.DataFrame(transactions)
    buffer = BytesIO()
    df.to_parquet(buffer, compression='zstd')
    
    # Upload para MinIO
    s3_client.put_object(
        Bucket='fraud-data',
        Key=f'batch_{chunk_id}.parquet',
        Body=buffer.getvalue()
    )

# 6 workers, mas s√≥ 1 trabalha por vez (GIL)
with ThreadPoolExecutor(max_workers=6) as executor:
    futures = [executor.submit(generate_chunk, args) for args in chunk_args]
```

#### ‚ö†Ô∏è Li√ß√£o Aprendida:
> **Threading N√ÉO paraleliza c√≥digo CPU-bound em Python!**
> O GIL (Global Interpreter Lock) permite apenas 1 thread executar c√≥digo Python por vez.

---

### üì¶ Vers√£o 3 (v3) - Threading Otimizado

| Caracter√≠stica | Valor |
|----------------|-------|
| **M√©todo** | `ThreadPoolExecutor` |
| **Workers** | 4 |
| **Formato** | Parquet + ZSTD |
| **Destino** | MinIO (S3-compatible) |
| **Chunk Size** | 268.000 (arquivo inteiro) |

#### Performance Medida:
```
üìä M√âTRICAS v3:
‚îú‚îÄ‚îÄ Tempo (1GB): 8.3 minutos
‚îú‚îÄ‚îÄ Tempo (50GB): ~7 horas
‚îú‚îÄ‚îÄ Throughput: 2 MB/s
‚îú‚îÄ‚îÄ CPU Usage: ~100% (ainda 1 core)
‚îú‚îÄ‚îÄ Mem√≥ria Peak: ~350 MB
‚îî‚îÄ‚îÄ Status: ‚úÖ Funcional e est√°vel
```

#### Otimiza√ß√£o: Eliminar Overhead de Chunks

```
v2: 27 chunks √ó overhead = 60 min
v3: 1 chunk √ó overhead = 8.3 min

MELHORIA: 7.2x mais r√°pido! üéâ
(apenas removendo a fragmenta√ß√£o)
```

#### C√≥digo Principal:
```python
from concurrent.futures import ThreadPoolExecutor

TRANSACTIONS_PER_FILE = 268_000  # Arquivo completo

def generate_full_file(args):
    """Worker para gerar arquivo completo (sem chunks)"""
    file_id, num_transactions = args
    transactions = []
    
    # Gera TODAS as transa√ß√µes de uma vez
    for i in range(num_transactions):
        tx = generate_transaction(...)
        transactions.append(tx)
    
    # UMA √öNICA convers√£o para DataFrame
    df = pd.DataFrame(transactions)
    buffer = BytesIO()
    df.to_parquet(buffer, compression='zstd')
    
    # Upload para MinIO
    s3_client.put_object(
        Bucket='fraud-data',
        Key=f'batch_{file_id}.parquet',
        Body=buffer.getvalue()
    )

with ThreadPoolExecutor(max_workers=4) as executor:
    futures = [executor.submit(generate_full_file, args) for args in file_args]
```

#### ‚úÖ Vantagens sobre v2:
- 7.2x mais r√°pido
- Mesma mem√≥ria baixa (~350 MB)
- Est√°vel e confi√°vel
- Sem erros de credenciais

#### ‚ùå Ainda limitado:
- CPU: apenas 1 core (GIL)
- 4x mais lento que v1
- N√£o aproveita m√∫ltiplos cores

---

### üì¶ Vers√£o 4 (v4) - Multiprocessing com Parquet ‚≠ê ATUAL

| Caracter√≠stica | Valor |
|----------------|-------|
| **M√©todo** | `ProcessPoolExecutor` |
| **Workers** | 4 |
| **Formato** | Parquet + ZSTD |
| **Destino** | MinIO (S3-compatible) |
| **Chunk Size** | 268.000 (arquivo inteiro) |

#### Performance Medida:
```
üìä M√âTRICAS v4:
‚îú‚îÄ‚îÄ Tempo (1GB): 1.3 minutos ‚ö°
‚îú‚îÄ‚îÄ Tempo (5GB): ~6.5 minutos
‚îú‚îÄ‚îÄ Tempo (50GB): ~65 minutos
‚îú‚îÄ‚îÄ Throughput: 13 MB/s
‚îú‚îÄ‚îÄ Transa√ß√µes/segundo: 28.595
‚îú‚îÄ‚îÄ CPU Usage: ~400% (4 cores reais!)
‚îú‚îÄ‚îÄ Mem√≥ria Peak: ~4 GB
‚îî‚îÄ‚îÄ Status: ‚úÖ Funcional üéâ
```

#### A Grande Mudan√ßa: Thread ‚Üí Process

```python
# ‚ùå v3: Threading (limitado pelo GIL)
from concurrent.futures import ThreadPoolExecutor
with ThreadPoolExecutor(max_workers=4) as executor:
    # CPU: ~100% (apenas 1 core)

# ‚úÖ v4: Multiprocessing (bypassa o GIL)
from concurrent.futures import ProcessPoolExecutor
with ProcessPoolExecutor(max_workers=4) as executor:
    # CPU: ~400% (4 cores reais!)
```

#### C√≥digo Principal:
```python
from concurrent.futures import ProcessPoolExecutor

def worker_generate_and_upload_parquet(args: tuple) -> str:
    """
    Worker para ProcessPoolExecutor.
    IMPORTANTE: Fun√ß√£o top-level (picklable).
    Credenciais passadas como argumentos (n√£o herdam do ambiente).
    """
    (batch_id, num_transactions, 
     minio_endpoint, minio_access_key, minio_secret_key,
     bucket_name, object_prefix) = args
    
    import boto3
    import pandas as pd
    
    # Cria cliente boto3 no processo filho
    s3_client = boto3.client(
        's3',
        endpoint_url=minio_endpoint,
        aws_access_key_id=minio_access_key,
        aws_secret_access_key=minio_secret_key
    )
    
    # Gera transa√ß√µes
    transactions = []
    for i in range(num_transactions):
        tx = generate_transaction(...)
        transactions.append(tx)
    
    # Converte e faz upload
    df = pd.DataFrame(transactions)
    buffer = BytesIO()
    df.to_parquet(buffer, compression='zstd')
    
    s3_client.put_object(
        Bucket=bucket_name,
        Key=f'{object_prefix}/batch_{batch_id}.parquet',
        Body=buffer.getvalue()
    )
    
    return f'batch_{batch_id}.parquet'

# Execu√ß√£o com multiprocessing REAL
with ProcessPoolExecutor(max_workers=4) as executor:
    futures = []
    for batch_id in range(num_files):
        args = (
            batch_id, num_transactions,
            minio_endpoint, access_key, secret_key,  # Credenciais expl√≠citas!
            bucket_name, object_prefix
        )
        future = executor.submit(worker_generate_and_upload_parquet, args)
        futures.append(future)
```

#### ‚ö†Ô∏è Pontos Cr√≠ticos da v4:

1. **Credenciais Expl√≠citas:**
```python
# ‚ùå ERRADO: vari√°veis de ambiente n√£o propagam
def worker():
    key = os.environ.get('MINIO_ACCESS_KEY')  # None!

# ‚úÖ CORRETO: passar como argumentos
def worker(args):
    (batch_id, ..., access_key, secret_key) = args
```

2. **Fun√ß√£o Top-Level (Picklable):**
```python
# ‚ùå ERRADO: fun√ß√£o aninhada n√£o serializa
def main():
    def worker(x):  # Fun√ß√£o local
        return x * 2
    executor.submit(worker, 1)  # Erro!

# ‚úÖ CORRETO: fun√ß√£o no n√≠vel do m√≥dulo
def worker(x):  # Top-level
    return x * 2
```

3. **Trade-off de Mem√≥ria:**
```
v3: 1 processo √ó 350 MB = 350 MB total
v4: 4 processos √ó 1 GB = 4 GB total

Paga-se com mem√≥ria, ganha-se em velocidade!
```

---

## üìä Comparativo de Speedup

### Speedup Relativo (base = v2)

| Vers√£o | Tempo (1GB) | Speedup vs v2 | Speedup vs v3 |
|--------|-------------|---------------|---------------|
| v2 | 60 min | 1x | - |
| v3 | 8.3 min | 7.2x | 1x |
| v1 | 2 min | 30x | 4.1x |
| **v4** | **1.3 min** | **46x** | **6.4x** |

### Visualiza√ß√£o do Speedup:

```
SPEEDUP vs v2 (mais lento):

v2: ‚ñà (1x baseline)
v3: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (7.2x)
v1: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (30x)
v4: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà (46x) üèÜ
```

---

## üéØ Recomenda√ß√µes de Uso

### Quando Usar Cada Vers√£o:

| Cen√°rio | Vers√£o Recomendada | Motivo |
|---------|-------------------|--------|
| **Produ√ß√£o (alta performance)** | v4 | Mais r√°pido, Parquet comprimido |
| **Mem√≥ria limitada (<2GB)** | v3 | Baixo consumo de RAM |
| **Disco local apenas** | v1 | Funciona sem Object Storage |
| **Debug/Desenvolvimento** | v3 | Est√°vel, logs claros |

### Regra de Ouro:

```
üìå RESUMO:

‚úÖ Precisa de VELOCIDADE? ‚Üí v4 (ProcessPoolExecutor)
‚úÖ Precisa de ECONOMIA de RAM? ‚Üí v3 (ThreadPoolExecutor)
‚úÖ N√£o tem MinIO/S3? ‚Üí v1 (Disco local)
‚ùå NUNCA use v2 (chunks pequenos s√£o ineficientes)
```

---

## üìà Proje√ß√µes de Tempo

### Estimativas para Diferentes Volumes:

| Volume | v2 | v3 | v1 | v4 |
|--------|-----|-----|-----|-----|
| 1 GB | 60 min | 8.3 min | 2 min | 1.3 min |
| 5 GB | 5 horas | 41 min | 10 min | 6.5 min |
| 10 GB | 10 horas | 1.4 horas | 20 min | 13 min |
| 50 GB | 50 horas | 7 horas | 1.7 horas | 65 min |
| 100 GB | 100 horas | 14 horas | 3.3 horas | 2.2 horas |

### Economia de Tempo com v4:

```
üì¶ Gera√ß√£o de 50GB:

v2: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 50 horas
v3: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 7 horas
v1: ‚ñà‚ñë 1.7 horas
v4: ‚ñà 65 min ‚ö°

ECONOMIA v4 vs v3: 5.9 horas (85% de redu√ß√£o!)
ECONOMIA v4 vs v2: 49 horas (98% de redu√ß√£o!)
```

---

## üîß Configura√ß√µes de Ambiente

### Docker Compose (v4):

```yaml
# docker-compose.yml
fraud-generator-batch:
  image: brazilian-fraud-generator:latest
  environment:
    SIZE: ${SIZE:-1GB}
    WORKERS: ${WORKERS:-4}
    MINIO_ENDPOINT: http://minio:9000
    MINIO_ACCESS_KEY: minioadmin
    MINIO_SECRET_KEY: Brasil03
    OUTPUT_FORMAT: parquet
  deploy:
    resources:
      limits:
        cpus: '4'
        memory: 6G
      reservations:
        cpus: '2'
        memory: 2G
```

### Execu√ß√£o:

```bash
# Gerar 1GB com 4 workers
SIZE=1GB WORKERS=4 docker-compose run --rm fraud-generator-batch

# Gerar 5GB com 4 workers
SIZE=5GB WORKERS=4 docker-compose run --rm fraud-generator-batch

# Gerar 50GB com 8 workers (se tiver 8+ cores)
SIZE=50GB WORKERS=8 docker-compose run --rm fraud-generator-batch
```

---

## üìù Conclus√£o

### Evolu√ß√£o da Performance:

```
v2 (60 min) ‚Üí v3 (8.3 min) ‚Üí v4 (1.3 min)
     ‚îÇ              ‚îÇ              ‚îÇ
     ‚îÇ              ‚îÇ              ‚îî‚îÄ‚îÄ ProcessPoolExecutor
     ‚îÇ              ‚îî‚îÄ‚îÄ Eliminou chunks
     ‚îî‚îÄ‚îÄ Threading com chunks (PROBLEMA: GIL + overhead)

MELHORIA TOTAL: 46x mais r√°pido! üöÄ
```

### Li√ß√µes Aprendidas:

1. **Threading ‚â† Paralelismo em Python** (GIL limita a 1 core)
2. **Chunks pequenos = overhead gigante** (27 convers√µes vs 1)
3. **ProcessPoolExecutor bypassa o GIL** (cada processo tem seu GIL)
4. **Credenciais devem ser expl√≠citas** (processos n√£o herdam ambiente)
5. **Trade-off velocidade/mem√≥ria** (4x RAM para 6.4x velocidade)

---

**√öltima Atualiza√ß√£o:** 11 de dezembro de 2025  
**Projeto:** spark-medallion-fraud-detection  
**Reposit√≥rio:** github.com/afborda/spark-medallion-fraud-detection
