# üìä An√°lise de Performance: Gera√ß√£o 30GB - OOM Killer Issue

## Status Atual: ‚ùå FALHA - Exit Code 137 (OOM Killer)

### Sequ√™ncia do Problema

```
‚úÖ Fase 1 (5.2 min): Gera 644k clientes + 1.3M dispositivos
   ‚îî‚îÄ Arquivos salvos: customers.parquet (48MB) + devices.parquet (29MB)
   ‚îî‚îÄ Mem√≥ria usada: ~2-3GB

‚ùå Fase 2 (inicia, falha em ~5 min): Inicia gera√ß√£o de 240 arquivos de transa√ß√µes
   ‚îî‚îÄ Exit code 137 = OOM Killer (Linux killed process due to memory pressure)
   ‚îî‚îÄ Causa: M√∫ltiplos workers alocando simultaneamente ~268K transa√ß√µes cada
   ‚îî‚îÄ Container limit: 8GB RAM
   ‚îî‚îÄ Mem√≥ria dispon√≠vel ap√≥s Fase 1: ~5-6GB
```

---

## üîç An√°lise Detalhada: Onde Est√° a Mem√≥ria?

### Configura√ß√£o Atual (generate.py linhas 1064-1074)

```python
max_workers = min(workers, num_files, 4)  # max_workers = 4
with ThreadPoolExecutor(max_workers=max_workers) as executor:
    futures = {executor.submit(generate_and_upload_tx_parquet, i): i for i in range(num_files)}
```

### Consumo de Mem√≥ria por Worker (Fase 2)

Para cada arquivo Parquet gerado:

| Componente | Tamanho | Quantidade | Total |
|-----------|--------|-----------|-------|
| Transaction list em mem√≥ria | 134MB | 4 workers | **536MB** |
| pandas DataFrame (overhead) | 50-100MB | 4 workers | **200-400MB** |
| Parquet buffer (antes upload) | 50MB | 4 workers | **200MB** |
| **SUBTOTAL simult√¢neo** | - | - | **936MB - 1.136GB** |

### C√°lculo Te√≥rico vs Real

- **Esperado**: 936MB - 1.1GB
- **Observado**: OOM Killer acionado ap√≥s ~5-10 min de Fase 2
- **Mem√≥ria dispon√≠vel**: ~6GB (8GB total - 2GB overhead Fase 1)
- **Problema**: Poss√≠vel pico de mem√≥ria quando:
  1. 4 workers gerando transa√ß√µes simultaneamente (536MB)
  2. 4 workers criando DataFrames (200-400MB)
  3. 4 workers aguardando upload (200MB)
  4. Python GC n√£o rodando entre batches
  5. Fragmenta√ß√£o de mem√≥ria causando picos

---

## üìà Performance Alcan√ßada at√© Agora

### Teste 1GB (‚úÖ Sucesso - 72 segundos)

```
- Tamanho: 1GB
- Tempo: 72 segundos (1.2 minutos)
- Throughput: 14 MB/sec
- Workers: 4
- Mem√≥ria pico: 3GB
```

### Extrapola√ß√£o 30GB (Se mantiver 14 MB/sec)

```
30GB √∑ 14MB/sec = 2,143 segundos = 35.7 minutos
```

**Problema**: Throughput n√£o se mant√©m em 30GB (causa OOM)

### Taxa Alcan√ßada na Fase 2 (antes crash)

```
Fase 1: 644k clientes em 5.2 min = 2,082 clientes/sec

Fase 2 (antes crash): 
- Nenhum arquivo completado
- Tempo antes crash: ~10 minutos (sem progresso mensur√°vel)
- Esperado em velocidade de 1GB: 
  240 arquivos √ó 128MB = 30GB
  ~30 arquivos/min se cada arquivo levasse 2 sec
  Em ~10 min antes crash: ~300 arquivos deveriam estar prontos
  Realidade: 0 arquivos
```

---

## üí° Op√ß√µes de Solu√ß√£o

### Op√ß√£o A: Redu√ß√£o Agressiva de Workers + GC For√ßado (R√°pido - 5 min)

**Mudan√ßas**:
```python
# Linha 1064 em generate.py
max_workers = min(workers, num_files, 2)  # Reduce from 4 to 2

# E adicionar ap√≥s BatchPoolExecutor:
if len(tx_results) % 5 == 0:  # Every 5 batches instead of 10
    gc.collect()
```

**C√°lculo de Mem√≥ria**:
- 2 workers √ó 134MB = 268MB (transa√ß√µes)
- 2 workers √ó 75MB = 150MB (DataFrame overhead)
- 2 workers √ó 50MB = 100MB (parquet buffer)
- **TOTAL**: 518MB (muito mais seguro < 1GB)

**Impacto**:
- ‚úÖ Est√°vel (18.5% redu√ß√£o vs 6.5GB dispon√≠vel)
- ‚ö†Ô∏è Mais lento: ~2x throughput reduzido (7 MB/sec)
- ‚úÖ R√°pido de implementar
- **Tempo estimado 30GB**: ~71 minutos

**Likelihood de Sucesso**: 95%

---

### Op√ß√£o B: Parquet Streaming (Melhor Performance - 30 min)

**Ideia**: Em vez de acumular todas transa√ß√µes em mem√≥ria e depois converter para DataFrame, escrever direto no Parquet Writer (PyArrow streaming).

**Pseudoc√≥digo**:
```python
def generate_and_upload_tx_parquet_streaming(batch_id: int) -> str:
    # Gera transa√ß√µes em chunks menores (ex: 10K por vez)
    schema = pyarrow.schema(...)  # Define schema uma vez
    
    with tempfile.NamedTemporaryFile(...) as tmpf:
        with pyarrow.parquet.ParquetWriter(tmpf.name, schema) as writer:
            for chunk_id in range(0, TRANSACTIONS_PER_FILE, 10000):
                chunk_size = min(10000, TRANSACTIONS_PER_FILE - chunk_id)
                transactions_chunk = generate_transactions(chunk_size)
                
                # Convert apenas chunk para pandas/arrow
                df_chunk = pd.json_normalize(transactions_chunk)
                table_chunk = pyarrow.Table.from_pandas(df_chunk)
                
                # Escrever chunk direto (row group no Parquet)
                writer.write_table(table_chunk)
                
                # Limpar mem√≥ria do chunk
                del df_chunk, table_chunk, transactions_chunk
                gc.collect()
        
        # Upload arquivo final
        upload_to_minio(tmpf.name)
```

**C√°lculo de Mem√≥ria**:
- Chunk size: 10K transa√ß√µes = ~5MB lista Python
- DataFrame chunk: ~5MB (vs 134MB full)
- 4 workers √ó 5MB = 20MB (vs 536MB full)
- **TOTAL**: <100MB para chunks (95% redu√ß√£o!)

**Impacto**:
- ‚úÖ Muito est√°vel (1.5% de 6.5GB)
- ‚úÖ Mant√©m throughput alto (~12-14 MB/sec estimado)
- ‚ö†Ô∏è Implementa√ß√£o mais complexa (30 min)
- **Tempo estimado 30GB**: ~45 minutos

**Likelihood de Sucesso**: 99% (mas requer refactor)

---

### Op√ß√£o C: Reduzir TRANSACTIONS_PER_FILE (Simples - 2 min)

**Mudan√ßa**:
```python
# Linha 62
TRANSACTIONS_PER_FILE = (TARGET_FILE_SIZE_MB * 1024 * 1024) // BYTES_PER_TRANSACTION

# Reduzir TARGET_FILE_SIZE_MB de 128MB para 64MB
TARGET_FILE_SIZE_MB = 64
# Resultado: TRANSACTIONS_PER_FILE ‚âà 268K ‚Üí 134K
```

**C√°lculo de Mem√≥ria**:
- 4 workers √ó 67MB = 268MB (vs 536MB)
- DataFrame overhead √ó 4 = 100-200MB (vs 200-400MB)
- **TOTAL**: ~480MB (25% redu√ß√£o)
- **Tradeoff**: 480 arquivos em vez de 240 (2x mais I/O)

**Impacto**:
- ‚úÖ F√°cil de implementar (1 linha de c√≥digo)
- ‚úÖ Razoavelmente est√°vel (~7.3% de 6.5GB)
- ‚ö†Ô∏è Mais arquivos = mais sobrecarga MinIO
- **Tempo estimado 30GB**: ~55 minutos

**Likelihood de Sucesso**: 90%

---

## üéØ Recomenda√ß√£o: Implementar Op√ß√£o A AGORA

### Por que Op√ß√£o A?

1. **R√°pido**: 5 minutos para implementar
2. **Seguro**: 18.5% de mem√≥ria = muito margem de seguran√ßa
3. **Valida√ß√£o**: Sucesso = correr Op√ß√£o B depois
4. **Revers√≠vel**: Se precisar mais performance, subir workers

### Pipeline Proposto

1. **Fase 1**: Aplicar Op√ß√£o A (5 min)
   - Build nova imagem
   - Testar com `SIZE=5GB`
   - Se sucesso ‚Üí ir para Fase 2

2. **Fase 2**: Validar com 5GB
   - Expected: 18 minutos
   - Confirmar mem√≥ria est√°vel
   - Se OK ‚Üí 30GB full

3. **Fase 3**: Se quiser mais velocidade
   - Implementar Op√ß√£o B (30 min)
   - Testar com 10GB
   - Escalar para 30GB

---

## üìä Comparativo das Op√ß√µes

| Aspecto | Op√ß√£o A | Op√ß√£o B | Op√ß√£o C |
|--------|---------|---------|---------|
| Tempo Implementa√ß√£o | 5 min | 30 min | 2 min |
| Mem√≥ria Pico | 518MB | <100MB | 480MB |
| Tempo 30GB | ~71 min | ~45 min | ~55 min |
| Likelihood Sucesso | 95% | 99% | 90% |
| Complexidade | Nenhuma | Alta | Nenhuma |
| Recomendado | ‚úÖ AGORA | ‚úÖ DEPOIS | ‚ö†Ô∏è Backup |

---

## üöÄ Pr√≥ximos Passos

### Imediato (se concordar com Op√ß√£o A):

```bash
# 1. Edit generate.py linha 1064
#    max_workers = 4 ‚Üí max_workers = 2

# 2. Edit generate.py linha 1073
#    if len(tx_results) % 10 == 0 ‚Üí if len(tx_results) % 5 == 0

# 3. Rebuild
docker compose build fraud-generator --no-cache

# 4. Test 5GB
SIZE=5GB WORKERS=2 docker compose up fraud-generator-batch

# 5. Se OK, test 30GB full
SIZE=30GB WORKERS=2 docker compose up fraud-generator-batch
```

### Feedback Esperado

- **Sucesso Esperado**: Fase 2 completa em ~18-20 min (vs crash em ~5 min agora)
- **Tempo Total 30GB**: ~25-30 minutos
- **Mem√≥ria**: Est√°vel < 4GB durante Fase 2

---

**Data da An√°lise**: 2025-12-09  
**Teste Anterior**: 1GB em 72 segundos ‚úÖ  
**Status Atual**: Aguardando aprova√ß√£o para implementar Op√ß√£o A
