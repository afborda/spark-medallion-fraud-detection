services:
  postgres:
    image: postgres:16
    container_name: fraud_postgres
    environment:
      POSTGRES_USER: fraud_user
      POSTGRES_PASSWORD: fraud_password@@!!_2
      POSTGRES_DB: fraud_db
    ports:
      - "5432:5432"
    volumes:
      - ./postgres_data:/var/lib/postgresql/data  # ✅ Dados persistem!
  minio:
    image: quay.io/minio/minio:latest
    container_name: fraud_minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin123@@!!_2
    ports:
      - "9002:9000"
      - "9003:9001"
    volumes:
      - ./minio_data:/data  # ✅ Dados persistem entre restarts!
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: fraud_zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_log:/var/lib/zookeeper/log
  
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: fraud_kafka
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_LOG_RETENTION_HOURS: 168  # Manter logs por 7 dias
      KAFKA_LOG_RETENTION_BYTES: 10737418240  # 10GB max
    ports:
      - "9092:9092"
    volumes:
      - kafka_data:/var/lib/kafka/data
  
  # ============================================
  # SPARK CLUSTER - 1 Master + 5 Workers (3GB cada)
  # IMPORTANTE: Spark 3.5.x usa Hadoop 3.3.x + AWS SDK v1
  # que é compatível com MinIO via HTTP (path-style access)
  # Spark 4.x usa AWS SDK v2 que tem bug com endpoints HTTP customizados
  # ============================================
  spark-master:
    image: apache/spark:3.5.3
    container_name: fraud_spark_master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    environment:
      SPARK_MASTER_HOST: spark-master
      SPARK_MASTER_PORT: 7077
      SPARK_MASTER_WEBUI_PORT: 8080
    ports:
      - "8081:8080"
      - "7077:7077"
      - "4040:4040"
    volumes:
      - ./data:/data
      - ./spark/jobs:/jobs
      - ./jars:/jars

  spark-worker-1:
    image: apache/spark:3.5.3
    container_name: fraud_spark_worker_1
    depends_on:
      - spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 3g
      SPARK_WORKER_WEBUI_PORT: 8081
    ports:
      - "8082:8081"
    volumes:
      - ./data:/data
      - ./jars:/jars

  spark-worker-2:
    image: apache/spark:3.5.3
    container_name: fraud_spark_worker_2
    depends_on:
      - spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 3g
      SPARK_WORKER_WEBUI_PORT: 8081
    ports:
      - "8083:8081"
    volumes:
      - ./data:/data
      - ./jars:/jars

  spark-worker-3:
    image: apache/spark:3.5.3
    container_name: fraud_spark_worker_3
    depends_on:
      - spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 3g
      SPARK_WORKER_WEBUI_PORT: 8081
    ports:
      - "8084:8081"
    volumes:
      - ./data:/data
      - ./jars:/jars

  spark-worker-4:
    image: apache/spark:3.5.3
    container_name: fraud_spark_worker_4
    depends_on:
      - spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 3g
      SPARK_WORKER_WEBUI_PORT: 8081
    ports:
      - "8085:8081"
    volumes:
      - ./data:/data
      - ./jars:/jars

  spark-worker-5:
    image: apache/spark:3.5.3
    container_name: fraud_spark_worker_5
    depends_on:
      - spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 3g
      SPARK_WORKER_WEBUI_PORT: 8081
    ports:
      - "8086:8081"
    volumes:
      - ./data:/data
      - ./jars:/jars

# ============================================
# NAMED VOLUMES - Gerenciados pelo Docker
# ============================================
volumes:
  zookeeper_data:
  zookeeper_log:
  kafka_data:
