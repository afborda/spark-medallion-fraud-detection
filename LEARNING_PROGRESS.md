# üéì PROGRESSO DE APRENDIZADO - Fraud Detection Pipeline

> **IMPORTANTE PARA A IA:** Este arquivo cont√©m o contexto completo do projeto de aprendizado.
> O aluno est√° aprendendo passo a passo (baby steps). N√ÉO fa√ßa c√≥digo automaticamente.
> Siga a metodologia: explicar ‚Üí aluno pergunta ‚Üí aluno digita ‚Üí executar juntos.

---

## üë§ PERFIL DO ALUNO

- N√≠vel: Iniciante/Intermedi√°rio em Data Engineering
- Objetivo: Aprender construindo, n√£o copiando
- Prefer√™ncia: Explica√ß√µes em portugu√™s, passo a passo
- Frase-chave: "eu nunca fiz um projeto desses do 0, quero bb steps passo a passo, sentir que eu fiz, n√£o que foi tudo autom√°tico"

---

## üìç STATUS ATUAL

**√öltimo checkpoint completado:** 11.9 - Escala 30M transa√ß√µes ‚úÖ
**Pr√≥ximo checkpoint:** 12 - Streaming Real com Kafka
**Data da √∫ltima sess√£o:** 2025-12-01

---

## üéØ RESULTADO FINAL: 30M Transa√ß√µes

### Pipeline Executado com Sucesso!

| M√©trica | Valor |
|---------|-------|
| **Transa√ß√µes Processadas** | 30,000,000 |
| **Dados Raw (JSON)** | 19.2 GB |
| **Clientes** | 50,000 |
| **Fraudes Injetadas** | 1,500,000 (5%) |
| **Tempo Total** | ~15 min |
| **Throughput** | ~110,000 tx/s |

### Distribui√ß√£o de Risco

| N√≠vel | Total | % | Valor M√©dio | Score M√©dio |
|-------|-------|---|-------------|-------------|
| ‚úÖ NORMAL | 27,077,000 | 90.26% | R$ 334 | 0.6 |
| üî¥ CR√çTICO | 1,468,416 | 4.89% | R$ 1,493 | 71.0 |
| üü† M√âDIO | 696,770 | 2.32% | R$ 2,304 | 21.5 |
| üü° ALTO | 620,423 | 2.07% | R$ 556 | 40.5 |
| üü¢ BAIXO | 137,391 | 0.46% | R$ 1,423 | 15.0 |

### PostgreSQL

| Tabela | Registros |
|--------|-----------|
| **transactions** | 30,000,000 |
| **fraud_alerts** | 2,088,839 |

### Precis√£o da Detec√ß√£o

| M√©trica | Valor |
|---------|-------|
| Total de Alertas | 2,088,839 |
| Fraudes Reais Detectadas | 842,997 |
| **Precis√£o** | **40.36%** |

---

## üöÄ EVOLU√á√ÉO DO CLUSTER SPARK

### Antes (Single Node)
| Configura√ß√£o | Valor |
|--------------|-------|
| Imagem | bitnami/spark:3.5.0 |
| Modo | Master + Worker √∫nico |
| Cores | 1 |
| RAM | N√£o configurado |
| Vers√£o | 3.5.0 |

### Depois (Cluster Distribu√≠do)
| Configura√ß√£o | Valor |
|--------------|-------|
| Imagem | apache/spark:4.0.0-preview2 |
| Modo | 1 Master + 5 Workers |
| Cores | **10 (5√ó2)** |
| RAM | **15 GB (5√ó3GB)** |
| Vers√£o | 4.0.0-preview2 |

### Configura√ß√µes Adicionadas
```python
# Em todos os jobs Spark:
.config("spark.sql.files.maxPartitionBytes", "128m")
```

---

## üìä TESTES DE ESCALABILIDADE

### Teste 1: 50k transa√ß√µes (Local - Antes do Cluster)
| M√©trica | Valor |
|---------|-------|
| Transa√ß√µes | 50,000 |
| Clientes | 1,000 |
| Dados Raw | 11 MB |
| Dados Bronze | 2.8 MB |
| Dados Silver | 2.9 MB |
| Dados Gold | 3.2 MB |
| Fraudes | 2,545 (5.09%) |
| Valor Fraudado | R$ 7,720,557.36 |
| **Modo** | **Local (1 worker)** |
| **Tempo estimado** | **~15-30s** |

### Teste 2: 1M transa√ß√µes (Cluster 5 Workers)
| M√©trica | Valor |
|---------|-------|
| Transa√ß√µes | **1,000,000** |
| Clientes | 10,000 |
| Dados Raw | **216 MB** |
| Dados Bronze | 54 MB |
| Dados Silver | 56 MB |
| Dados Gold | 60 MB |
| Fraudes | 49,603 (5.0%) |
| **Modo** | **Cluster (5 workers √ó 2 cores)** |
| **Tempo total** | **~2min 30s** |

### üìä Estat√≠sticas de Fraude Detalhadas (1M transa√ß√µes)

| N√≠vel de Risco | Quantidade | % | Valor Total | Ticket M√©dio |
|----------------|------------|---|-------------|--------------|
| üî¥ Alto Risco | 8,259 | 0.83% | R$ 24.6M | R$ 2,982.87 |
| üü† Risco M√©dio | 200,235 | 20.02% | R$ 164.5M | R$ 821.38 |
| üü¢ Baixo Risco | 791,506 | 79.15% | R$ 201.7M | R$ 254.82 |
| **TOTAL** | **1,000,000** | 100% | **R$ 390.8M** | - |

### üîÑ Comparativo: Antes vs Depois do Cluster

| M√©trica | Antes (Local) | Depois (5 Workers) | Melhoria |
|---------|---------------|---------------------|----------|
| Transa√ß√µes | 50,000 | 1,000,000 | **20√ó mais** |
| Dados Raw | 11 MB | 216 MB | **20√ó mais** |
| Workers | 1 | 5 | **5√ó mais** |
| Cores | 1 | 10 | **10√ó mais** |
| RAM | ~1 GB | 15 GB | **15√ó mais** |
| Tempo | ~30s | ~150s | **5√ó mais** |
| **Throughput** | **~1.7k/s** | **~6.7k/s** | **4√ó mais r√°pido** |

> **Conclus√£o:** Com 20√ó mais dados, o tempo aumentou apenas 5√ó. Isso demonstra **escalabilidade sub-linear** gra√ßas ao processamento distribu√≠do.

### Tempo de Execu√ß√£o por Camada (1M transa√ß√µes)
| Camada | Tempo |
|--------|-------|
| üî∂ Bronze | 37s |
| ‚ö™ Silver | 46s |
| ü•á Gold | 34s |
| üö® Fraud Detection | 33s |
| **TOTAL** | **~2min 30s** |

### Compress√£o Parquet
| Camada | Formato | Tamanho | Compress√£o |
|--------|---------|---------|------------|
| Raw | JSON | 216 MB | - |
| Bronze | Parquet | 54 MB | 75% |
| Silver | Parquet | 56 MB | 74% |
| Gold | Parquet | 60 MB | 72% |

### Escalabilidade
| M√©trica | 50k ‚Üí 1M | Resultado |
|---------|----------|-----------|
| Dados | 20√ó mais | ‚úÖ |
| Tempo | 5√ó mais | ‚úÖ Sub-linear! |

---

## ‚úÖ CHECKPOINTS COMPLETADOS

### Checkpoint 1-5: Infraestrutura Docker ‚úÖ
- [x] docker-compose.yml criado com 6 servi√ßos
- [x] PostgreSQL 16 (porta 5432)
- [x] MinIO (portas 9002/9003) - bucket "fraud-data" criado via UI
- [x] Zookeeper 7.5.0 + Kafka 7.5.0 (porta 9092) - topic "transactions" criado
- [x] Spark Master + Worker apache/spark:3.5.3 (UI porta 8081)
- [x] Todos containers rodando

### Checkpoint 6-7: Gera√ß√£o de Dados ‚úÖ
- [x] scripts/generate_data.py criado
- [x] Fun√ß√µes: generate_customers(), generate_transactions(), save_to_json()
- [x] Formato: JSON Lines (um registro por linha) - corrigido durante a sess√£o
- [x] Dados gerados: 100 clientes + 500 transa√ß√µes (~5% fraude = ~25 fraudes)

### Checkpoint 8: Bronze Layer ‚úÖ
- [x] spark/jobs/bronze_layer.py criado
- [x] PySpark 4.0.1 instalado no venv (compat√≠vel com Spark 4.0.1 do sistema)
- [x] Convers√£o JSON ‚Üí Parquet funcionando
- [x] Metadados adicionados: _ingestion_time, _process_date
- [x] Output: data/bronze/customers/ e data/bronze/transactions/

### Checkpoint 9: Silver Layer ‚úÖ
- [x] spark/jobs/silver_layer.py criado
- [x] Limpeza de dados: dropDuplicates(), dropna()
- [x] Padroniza√ß√£o: lower(), trim() para emails e nomes
- [x] Filtros: apenas transa√ß√µes com amount > 0
- [x] Metadados: _silver_timestamp, processed_date
- [x] Output: data/silver/customers/ e data/silver/transactions/

**Conceitos aprendidos:**
- Fun√ß√µes Python: defini√ß√£o e chamada, par√¢metros vs vari√°veis globais
- `if __name__ == "__main__":` - c√≥digo que s√≥ roda quando executas o arquivo diretamente
- Transforma√ß√µes Spark: withColumn(), filter(), dropDuplicates(), dropna()

### Checkpoint 10: Gold Layer ‚úÖ
- [x] spark/jobs/gold_layer.py criado
- [x] customer_summary: total_gasto, qtd_transacoes, ticket_medio, qtd_fraudes por cliente
- [x] fraud_summary: estat√≠sticas gerais de fraude (19 fraudes, R$ 62.260,93, 3.8%)
- [x] Output: data/gold/customer_summary/ e data/gold/fraud_summary/

**Conceitos aprendidos:**
- Agrega√ß√µes: groupBy().agg(), sum(), count(), avg()
- .alias() para nomear colunas resultantes
- round() do Python vs spark_round() do Spark (tipos diferentes!)
- collect() - trazer dados do Spark para Python (usar com cuidado em Big Data!)
- .cast("int") para converter boolean para inteiro

### Checkpoint 11: Fraud Detection ‚úÖ
- [x] spark/jobs/fraud_detection.py criado
- [x] Regra 1: Valor alto (amount > R$ 1.000) ‚Üí flag high_value
- [x] Regra 2: Hor√°rio suspeito (2h-5h da manh√£) ‚Üí flag suspicious_hour
- [x] Regra 3: N√≠veis de risco combinados (Alto/M√©dio/Baixo)
- [x] Output particionado por risk_level: data/gold/fraud_detection/
- [x] Resultados: 4 Alto Risco, 83 M√©dio Risco, 413 Baixo Risco

**Conceitos aprendidos:**
- when()/otherwise() - l√≥gica condicional em colunas Spark
- col() - referenciar colunas pelo nome para opera√ß√µes
- withColumn() - criar ou substituir colunas (DataFrames s√£o imut√°veis)
- hour() e to_timestamp() - extrair hora de um timestamp
- partitionBy() - salvar dados particionados em pastas separadas

### Checkpoint 11.5: PostgreSQL Integration ‚úÖ
- [x] spark/jobs/load_to_postgres.py criado
- [x] JDBC driver baixado (postgresql-42.7.4.jar)
- [x] Conex√£o Spark ‚Üí PostgreSQL funcionando
- [x] Tabelas criadas e carregadas:
  - fraud_detections: **5,000,000 registros** (fraud_detection Gold Layer)
  - customer_summary: **50,000 registros** (customer_summary Gold Layer)
- [x] Tempo de carga: ~2 min para 5M registros

**Conex√£o PostgreSQL:**
```
Host: localhost (ou fraud_postgres no Docker)
Port: 5432
Database: fraud_db
User: fraud_user
Password: fraud_password@@!!_2
```

### Checkpoint 11.6: MinIO como Data Lake ‚úÖ
- [x] spark/jobs/bronze_to_minio.py criado
- [x] JARs Hadoop-AWS configurados (hadoop-aws, aws-java-sdk-bundle)
- [x] Bucket "fraud-data" criado via MinIO Client (mc)
- [x] Escrita s3a://fraud-data/bronze/ funcionando
- [x] Dados vis√≠veis no MinIO Console (http://localhost:9003)

**MinIO Storage (5M transa√ß√µes):**
| Path | Arquivos | Tamanho |
|------|----------|---------|
| s3a://fraud-data/bronze/customers | 3 parquet | 3 MB |
| s3a://fraud-data/bronze/transactions | 9 parquet | 411 MB |
| **Total** | **12 arquivos** | **414 MB** |

**Conex√£o MinIO:**
```
Endpoint: http://localhost:9002 (API) / http://localhost:9003 (Console)
Access Key: minioadmin
Secret Key: minioadmin123@@!!_2
Bucket: fraud-data
```

### Checkpoint 11.7: Scale Data (Cluster Distribu√≠do) ‚úÖ
- [x] Cluster Spark: 1 Master + 5 Workers
- [x] Cada Worker: 2 cores, 3GB RAM (total: 10 cores, 15GB)
- [x] Imagem Docker: apache/spark:4.0.0-preview2-scala2.13-java21-python3-r-ubuntu
- [x] Configura√ß√£o 128MB partitions em todos os jobs
- [x] Caminhos din√¢micos (/data vs data) para Docker/Local
- [x] argparse no generate_data.py (--customers, --transactions, --fraud-rate)
- [x] ‚úÖ Teste 1M: ~2min 30s (6.7k tx/s)
- [x] ‚úÖ Teste 5M: ~3min (28k tx/s)
- [x] ‚úÖ **Teste 10M: ~3.5min (47.6k tx/s)** üöÄ

**Conceitos aprendidos:**
- spark.sql.files.maxPartitionBytes - tamanho das parti√ß√µes (128m otimizado)
- SPARK_WORKER_CORES e SPARK_WORKER_MEMORY - configura√ß√£o de workers
- Diferen√ßa entre spark-submit local vs cluster (--master spark://...)
- Permiss√µes Docker (chmod 777 para volume mounts)
- Escalabilidade horizontal: 28√ó melhoria com 10 cores vs 1
- Compress√£o Parquet (~61% menor que JSON para Big Data)
- Throughput escala melhor com dados maiores (overhead fixo dilu√≠do)

---

## üéØ ARQUITETURA OBJETIVO

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ARQUITETURA LAKEHOUSE COMPLETA                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                             ‚îÇ
‚îÇ  [ShadowTraffic] ‚îÄ‚îÄ‚ñ∫ [Kafka] ‚îÄ‚îÄ‚ñ∫ [Spark Streaming] ‚îÄ‚îÄ‚ñ∫ [MinIO Data Lake]   ‚îÇ
‚îÇ                         ‚îÇ              ‚îÇ                      ‚îÇ             ‚îÇ
‚îÇ                    customers      ETL Jobs              Bronze/Silver/Gold  ‚îÇ
‚îÇ                    orders                                     ‚îÇ             ‚îÇ
‚îÇ                                                               ‚ñº             ‚îÇ
‚îÇ                                                        [PostgreSQL]         ‚îÇ
‚îÇ                                                         Data Warehouse      ‚îÇ
‚îÇ                                                               ‚îÇ             ‚îÇ
‚îÇ                                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ                                                    ‚îÇ                     ‚îÇ  ‚îÇ
‚îÇ                                               [Metabase]           [Streamlit]‚îÇ
‚îÇ                                               Dashboards           Apps      ‚îÇ
‚îÇ                                                    ‚îÇ                     ‚îÇ  ‚îÇ
‚îÇ                                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                               ‚îÇ             ‚îÇ
‚îÇ                                                          [Traefik]          ‚îÇ
‚îÇ                                                        Reverse Proxy        ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### VPS OVH Specs:
- **vCores:** 8
- **RAM:** 24 GB
- **Disco:** 200 GB
- **Objetivo:** Processar ~50 GB de dados

### üìà Proje√ß√£o para Escalas Maiores

| Volume | Transa√ß√µes | Tamanho Raw | Tempo Real | Throughput | Status |
|--------|------------|-------------|------------|------------|--------|
| ‚úÖ Teste 1 | 50K | 11 MB | ~30s | 1.7k/s | Conclu√≠do (Local) |
| ‚úÖ Teste 2 | 1M | 216 MB | ~2.5min | 6.7k/s | Conclu√≠do (Cluster) |
| ‚úÖ Teste 3 | 5M | 1.1 GB | ~3min | 28k/s | Conclu√≠do (Cluster) |
| ‚úÖ Teste 4 | 10M | 2.2 GB | ~3.5min | 47.6k/s | Conclu√≠do (Cluster) |
| ‚úÖ **Teste 5** | **30M** | **19.2 GB** | **~15min** | **110k/s** | **Conclu√≠do!** üéâ |
| üìã Teste 6 | 50M | ~32 GB | ~25min | ~55k/s | Planejado |
| üìã Final | 230M | ~50 GB | ~1h | ~60k/s | Objetivo |

### ‚úÖ Teste 3: 5M transa√ß√µes (Cluster 5 Workers)
| M√©trica | Valor |
|---------|-------|
| Transa√ß√µes | **5,000,000** |
| Clientes | 50,000 |
| Dados Raw | **1.1 GB** |
| Dados Bronze | 417 MB |
| Dados Silver | 428 MB |
| Dados Gold | 430 MB |
| Fraudes | 250,307 (5.0%) |
| **Tempo total** | **~3 min** |
| **Throughput** | **~28k transa√ß√µes/segundo** |

### ‚úÖ Teste 4: 10M transa√ß√µes (Cluster 5 Workers) üöÄ
| M√©trica | Valor |
|---------|-------|
| Transa√ß√µes | **10,000,000** |
| Clientes | 100,000 |
| Dados Raw | **2.2 GB** |
| Dados Bronze | 838 MB |
| Dados Silver | 861 MB |
| Dados Gold | 866 MB |
| Fraudes | ~500,000 (5.0%) |
| **Tempo total** | **~3.5 min (210s)** |
| **Throughput** | **~47,600 transa√ß√µes/segundo** |

### ‚úÖ Teste 5: 30M transa√ß√µes (Cluster 5 Workers) üéâ NOVO!
| M√©trica | Valor |
|---------|-------|
| Transa√ß√µes | **30,000,000** |
| Clientes | 50,000 |
| Dados Raw | **19.2 GB** |
| Fraudes Injetadas | 1,500,000 (5.0%) |
| **Tempo total** | **~15 min** |
| **Throughput** | **~110,000 transa√ß√µes/segundo** |

**Breakdown dos tempos (30M):**
| Etapa | Tempo | Throughput |
|-------|-------|------------|
| Bronze Layer | 4.5min | 110,830/s |
| Silver Layer | 5min | 100,000/s |
| Gold Layer | 5min | 100,000/s |
| **Total Pipeline** | **~15min** | **~110k tx/s** |

**Resultados de Detec√ß√£o:**
| N√≠vel | Quantidade | % |
|-------|------------|---|
| NORMAL | 27,077,000 | 90.26% |
| CR√çTICO | 1,468,416 | 4.89% |
| M√âDIO | 696,770 | 2.32% |
| ALTO | 620,423 | 2.07% |
| BAIXO | 137,391 | 0.46% |

**Breakdown dos tempos (10M):**
| Etapa | Tempo | Descri√ß√£o |
|-------|-------|-----------|
| Bronze Layer | 50s | JSON ‚Üí Parquet |
| Silver Layer | 74s | Limpeza e valida√ß√£o |
| Gold Layer | 40s | Agrega√ß√µes |
| Fraud Detection | 45s | Regras + Particionamento |
| **Total Pipeline** | **~210s** | **47.6k tx/s** |

### üöÄ Evolu√ß√£o do Throughput
| Configura√ß√£o | Transa√ß√µes | Tempo | Throughput | Melhoria |
|--------------|------------|-------|------------|----------|
| Local (1 core) | 50K | ~30s | 1,700/s | baseline |
| Cluster (10 cores) - 1M | 1M | 150s | 6,700/s | **4√ó** |
| Cluster (10 cores) - 5M | 5M | 180s | 28,000/s | **16√ó** |
| Cluster (10 cores) - 10M | 10M | 210s | 47,600/s | **28√ó** |
| Cluster (10 cores) - 30M | 30M | 900s | **110,000/s** | **65√ó** |

### üíæ Compress√£o Parquet vs JSON Raw
| Teste | Raw (JSON) | Parquet | Compress√£o |
|-------|------------|---------|------------|
| 50K | 11 MB | 3 MB | 73% |
| 1M | 216 MB | 56 MB | 74% |
| 5M | 1.1 GB | 430 MB | 61% |
| 10M | 2.2 GB | 866 MB | 61% |

---

## üîú CHECKPOINTS PENDENTES

### Fase 1: Completar Infraestrutura de Dados

### Checkpoint 11.8: MinIO como Storage Principal ‚úÖ
**Objetivo:** Migrar todo o pipeline para usar MinIO como storage principal
**Status:** ‚úÖ CONCLU√çDO

**O que foi feito:**
- [x] bronze_to_minio.py - Bronze Layer ‚Üí s3a://fraud-data/bronze/ ‚úÖ
- [x] silver_to_minio.py - Silver Layer ‚Üí s3a://fraud-data/silver/ ‚úÖ
- [x] gold_to_minio.py - Gold Layer ‚Üí s3a://fraud-data/gold/ ‚úÖ
- [x] Script unificado run_spark_job.sh para executar qualquer job
- [x] Documenta√ß√£o de erros em docs/ERROS_CONHECIDOS.md

**MinIO Storage Final (10M transa√ß√µes):**
| Path | Dados |
|------|-------|
| s3a://fraud-data/bronze/customers | 100K clientes |
| s3a://fraud-data/bronze/transactions | 10M transa√ß√µes |
| s3a://fraud-data/silver/customers | 100K clientes |
| s3a://fraud-data/silver/transactions | 10M transa√ß√µes |
| s3a://fraud-data/gold/customer_summary | 100K resumos |
| s3a://fraud-data/gold/fraud_summary | 1 resumo geral |
| s3a://fraud-data/gold/fraud_detection | 10M (particionado) |
| **Total** | **83 arquivos, 2.5 GB** |

**üö® ERROS IMPORTANTES RESOLVIDOS:**

1. **`hostname cannot be null` / `URISyntaxException`**
   - **Causa 1:** Spark 4.x usa AWS SDK v2 que tem BUG com endpoints HTTP
   - **Causa 2:** Hostname `fraud_minio` tem underscore (inv√°lido RFC 952)
   - **Solu√ß√£o:** Usar Spark 3.5.3 + hostname `minio` (service name)
   - **Documenta√ß√£o completa:** `docs/ERROS_CONHECIDOS.md`

2. **JARs corretos para MinIO:**
   ```
   jars/
   ‚îú‚îÄ‚îÄ hadoop-aws-3.3.4.jar          # Conector S3A (SDK v1)
   ‚îú‚îÄ‚îÄ aws-java-sdk-bundle-1.12.262.jar  # AWS SDK v1 (N√ÉO v2!)
   ‚îî‚îÄ‚îÄ postgresql-42.7.4.jar         # JDBC PostgreSQL
   ```

3. **Por que scripts .sh s√£o necess√°rios no cluster:**
   - `spark-submit` cria a JVM ANTES de ler o c√≥digo Python
   - Configura√ß√µes `spark.jars` no Python s√£o ignoradas
   - JARs devem ser passados via `--jars` na linha de comando
   - Solu√ß√£o: `run_spark_job.sh` script unificado

**Como executar jobs no cluster:**
```bash
./run_spark_job.sh bronze_to_minio   # RAW ‚Üí MinIO Bronze
./run_spark_job.sh silver_to_minio   # Silver ‚Üí MinIO Silver
./run_spark_job.sh gold_to_minio     # Gold ‚Üí MinIO Gold
./run_spark_job.sh bronze_layer      # RAW ‚Üí Bronze local
./run_spark_job.sh silver_layer      # Bronze ‚Üí Silver local
./run_spark_job.sh gold_layer        # Silver ‚Üí Gold local
```

#### Checkpoint 11.9: Escalar para 50M+ transa√ß√µes
**Objetivo:** Testar limites do cluster com volumes maiores

| Etapa | Volume | Transa√ß√µes | Status |
|-------|--------|------------|--------|
| ‚úÖ Teste 1 | 11 MB | 50k | Conclu√≠do |
| ‚úÖ Teste 2 | 216 MB | 1M | Conclu√≠do |
| ‚úÖ Teste 3 | 1.1 GB | 5M | Conclu√≠do |
| ‚úÖ Teste 4 | 2.2 GB | 10M | **Conclu√≠do** |
| üìã Teste 5 | ~11 GB | 50M | Pr√≥ximo |
| üìã Teste 6 | ~50 GB | 230M | Objetivo Final |

### Fase 2: Streaming Real

#### Checkpoint 12: ShadowTraffic + Kafka Producer
**Objetivo:** Gerar dados em streaming para Kafka
**Arquivo:** shadowtraffic/config.json

Conceitos:
- ShadowTraffic configura√ß√£o
- Kafka topics: customers, orders
- Gera√ß√£o cont√≠nua de dados

#### Checkpoint 13: Spark Structured Streaming
**Objetivo:** Consumir Kafka em tempo real
**Arquivo:** spark/jobs/streaming_etl.py

Conceitos:
- readStream vs read
- writeStream vs write
- Trigger, watermark, checkpointing

#### Checkpoint 14: Pipeline Streaming Completo
**Objetivo:** Kafka ‚Üí Bronze ‚Üí Silver ‚Üí Gold em tempo real

### Fase 3: Visualiza√ß√£o

#### Checkpoint 15: Metabase
**Objetivo:** Dashboards de BI conectados ao PostgreSQL

Dashboards:
- Fraudes por per√≠odo
- Customer Lifetime Value
- Sales by city/product

#### Checkpoint 16: Streamlit
**Objetivo:** App interativo de an√°lise

Features:
- Filtros din√¢micos
- Alertas de fraude
- Explora√ß√£o de dados

#### Checkpoint 17: Traefik
**Objetivo:** Reverse proxy com dom√≠nios

Conceitos:
- Routing por dom√≠nio
- HTTPS/SSL
- Load balancing

---

## üõ†Ô∏è AMBIENTE T√âCNICO

```yaml
Sistema: Ubuntu 25.04 (plucky) - VPS
IP: 54.36.100.35
Shell: zsh

Python: 3.13
PySpark: 4.0.1
Spark: 4.0.1 (SPARK_HOME=/home/ubuntu/Estudos/apache-spark/spark-4.0.1-bin-hadoop3)
Java: OpenJDK 17

Docker: docker.io (n√£o docker-ce - incompat√≠vel com Ubuntu 25.04)
```

### Comandos para iniciar sess√£o:
```bash
cd ~/Estudos/1_projeto_bank_Fraud_detection_data_pipeline
source venv/bin/activate
docker compose ps  # verificar containers
```

---

## üìÅ ESTRUTURA DO PROJETO

```
1_projeto_bank_Fraud_detection_data_pipeline/
‚îú‚îÄ‚îÄ LEARNING_PROGRESS.md    ‚Üê Este arquivo (contexto para IA)
‚îú‚îÄ‚îÄ PROJECT_PLAN.md         ‚Üê Plano completo do projeto
‚îú‚îÄ‚îÄ docker-compose.yml      ‚Üê Infraestrutura (Spark 3.5.3 + MinIO + PostgreSQL)
‚îú‚îÄ‚îÄ run_spark_job.sh        ‚Üê üÜï Script unificado para executar jobs no cluster
‚îú‚îÄ‚îÄ venv/                   ‚Üê Virtual environment Python
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îî‚îÄ‚îÄ ERROS_CONHECIDOS.md ‚Üê üÜï Documenta√ß√£o de erros e solu√ß√µes
‚îÇ
‚îú‚îÄ‚îÄ jars/                   ‚Üê JARs necess√°rios
‚îÇ   ‚îú‚îÄ‚îÄ hadoop-aws-3.3.4.jar           ‚Üê S3A connector (SDK v1)
‚îÇ   ‚îú‚îÄ‚îÄ aws-java-sdk-bundle-1.12.262.jar ‚Üê AWS SDK v1
‚îÇ   ‚îî‚îÄ‚îÄ postgresql-42.7.4.jar          ‚Üê JDBC PostgreSQL
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ generate_data.py    ‚Üê Gerador de dados sint√©ticos
‚îÇ
‚îú‚îÄ‚îÄ spark/
‚îÇ   ‚îî‚îÄ‚îÄ jobs/
‚îÇ       ‚îú‚îÄ‚îÄ bronze_layer.py     ‚Üê JSON ‚Üí Parquet local ‚úÖ
‚îÇ       ‚îú‚îÄ‚îÄ silver_layer.py     ‚Üê Limpeza local ‚úÖ
‚îÇ       ‚îú‚îÄ‚îÄ gold_layer.py       ‚Üê Agrega√ß√µes local ‚úÖ
‚îÇ       ‚îú‚îÄ‚îÄ fraud_detection.py  ‚Üê Regras de fraude ‚úÖ
‚îÇ       ‚îú‚îÄ‚îÄ bronze_to_minio.py  ‚Üê üÜï RAW ‚Üí MinIO Bronze ‚úÖ
‚îÇ       ‚îú‚îÄ‚îÄ silver_to_minio.py  ‚Üê üÜï Silver ‚Üí MinIO Silver ‚úÖ
‚îÇ       ‚îú‚îÄ‚îÄ gold_to_minio.py    ‚Üê üÜï Gold ‚Üí MinIO Gold ‚úÖ
‚îÇ       ‚îî‚îÄ‚îÄ load_to_postgres.py ‚Üê Gold ‚Üí PostgreSQL ‚úÖ
‚îÇ
‚îî‚îÄ‚îÄ data/
    ‚îú‚îÄ‚îÄ raw/                ‚Üê JSON Lines (origem)
    ‚îú‚îÄ‚îÄ bronze/             ‚Üê Parquet local ‚úÖ
    ‚îú‚îÄ‚îÄ silver/             ‚Üê Parquet local ‚úÖ
    ‚îî‚îÄ‚îÄ gold/               ‚Üê Parquet local ‚úÖ

MinIO (Data Lake):
s3a://fraud-data/
‚îú‚îÄ‚îÄ bronze/
‚îÇ   ‚îú‚îÄ‚îÄ customers/      ‚Üê 100K clientes
‚îÇ   ‚îî‚îÄ‚îÄ transactions/   ‚Üê 10M transa√ß√µes
‚îú‚îÄ‚îÄ silver/
‚îÇ   ‚îú‚îÄ‚îÄ customers/      ‚Üê 100K clientes
‚îÇ   ‚îî‚îÄ‚îÄ transactions/   ‚Üê 10M transa√ß√µes
‚îî‚îÄ‚îÄ gold/
    ‚îú‚îÄ‚îÄ customer_summary/   ‚Üê 100K resumos
    ‚îú‚îÄ‚îÄ fraud_summary/      ‚Üê 1 resumo geral
    ‚îî‚îÄ‚îÄ fraud_detection/    ‚Üê 10M (particionado por risk_level)
```

---

## üìù METODOLOGIA DE ENSINO

### Regras para a IA:

1. **N√ÉO escreva c√≥digo automaticamente** - guie o aluno
2. **Explique o conceito primeiro** (teoria breve)
3. **Mostre o c√≥digo a digitar** em blocos pequenos
4. **Espere o aluno confirmar** que digitou
5. **Execute junto** e analise o resultado
6. **Se der erro**, explique o porqu√™ antes de corrigir

### Formato de aula:
```
## üìù AULA X.Y: [Nome do Conceito]

[Explica√ß√£o te√≥rica em 2-3 par√°grafos]

---

Agora digita no arquivo [nome]:

```python
# c√≥digo aqui
```

Me avisa quando terminar!
```

---

## üêõ PROBLEMAS RESOLVIDOS (para refer√™ncia)

| Problema | Causa | Solu√ß√£o |
|----------|-------|---------|
| docker-ce n√£o instala | Ubuntu 25.04 incompat√≠vel | Usar docker.io nativo |
| Porta 9000 ocupada | Portainer usando | MinIO mudou para 9002/9003 |
| Porta 8080 ocupada | Open-WebUI usando | Spark UI mudou para 8081 |
| Bitnami Spark n√£o funciona | Imagens pagas agora | Usar apache/spark oficial |
| pip n√£o funciona | PEP 668 (externally-managed) | Criar venv |
| PySpark 3.5.3 erro | SPARK_HOME aponta p/ 4.0.1 | Instalar PySpark 4.0.1 |
| JSON corrupt record | Formato array [...] | Mudar para JSON Lines |
| **hostname cannot be null** | **Spark 4.x + AWS SDK v2 bug** | **Usar Spark 3.5.3** |
| **hostname cannot be null** | **Underscore em hostname** | **Usar `minio` n√£o `fraud_minio`** |
| **403 Forbidden MinIO** | **Credenciais erradas** | **Verificar MINIO_ROOT_PASSWORD** |
| **ClassNotFoundException S3A** | **JARs n√£o no classpath** | **--jars no spark-submit** |

---

## üöÄ COMO CONTINUAR

Quando o aluno voltar, dizer:

> "Bem-vindo de volta! Vi no LEARNING_PROGRESS.md que completaste o Bronze Layer.
> Pronto para come√ßar a Silver Layer? Vamos limpar e validar os dados!"

Primeiro passo da pr√≥xima sess√£o:
1. Verificar se containers est√£o rodando: `docker compose ps`
2. Ativar venv: `source venv/bin/activate`
3. Verificar dados bronze existem: `ls data/bronze/`
4. Come√ßar explica√ß√£o da Silver Layer

---

*√öltima atualiza√ß√£o: 2025-11-29 (MinIO Integration completado - Bronze/Silver/Gold)*
