# üéì PROGRESSO DE APRENDIZADO - Fraud Detection Pipeline

> **IMPORTANTE PARA A IA:** Este arquivo cont√©m o contexto completo do projeto de aprendizado.
> O aluno est√° aprendendo passo a passo (baby steps). N√ÉO fa√ßa c√≥digo automaticamente.
> Siga a metodologia: explicar ‚Üí aluno pergunta ‚Üí aluno digita ‚Üí executar juntos.

---

## üë§ PERFIL DO ALUNO

- N√≠vel: Iniciante/Intermedi√°rio em Data Engineering
- Objetivo: Aprender construindo, n√£o copiando
- Prefer√™ncia: Explica√ß√µes em portugu√™s, passo a passo
- Frase-chave: "eu nunca fiz um projeto desses do 0, quero bb steps passo a passo, sentir que eu fiz, n√£o que foi tudo autom√°tico"

---

## üìç STATUS ATUAL

**√öltimo checkpoint completado:** 11.7 - Scale Data (Cluster Distribu√≠do) ‚úÖ
**Pr√≥ximo checkpoint:** 11.8 - MinIO Integration
**Data da √∫ltima sess√£o:** 2025-11-29

---

## üöÄ EVOLU√á√ÉO DO CLUSTER SPARK

### Antes (Single Node)
| Configura√ß√£o | Valor |
|--------------|-------|
| Imagem | bitnami/spark:3.5.0 |
| Modo | Master + Worker √∫nico |
| Cores | 1 |
| RAM | N√£o configurado |
| Vers√£o | 3.5.0 |

### Depois (Cluster Distribu√≠do)
| Configura√ß√£o | Valor |
|--------------|-------|
| Imagem | apache/spark:4.0.0-preview2 |
| Modo | 1 Master + 5 Workers |
| Cores | **10 (5√ó2)** |
| RAM | **15 GB (5√ó3GB)** |
| Vers√£o | 4.0.0-preview2 |

### Configura√ß√µes Adicionadas
```python
# Em todos os jobs Spark:
.config("spark.sql.files.maxPartitionBytes", "128m")
```

---

## üìä TESTES DE ESCALABILIDADE

### Teste 1: 50k transa√ß√µes (Local - Antes do Cluster)
| M√©trica | Valor |
|---------|-------|
| Transa√ß√µes | 50,000 |
| Clientes | 1,000 |
| Dados Raw | 11 MB |
| Dados Bronze | 2.8 MB |
| Dados Silver | 2.9 MB |
| Dados Gold | 3.2 MB |
| Fraudes | 2,545 (5.09%) |
| Valor Fraudado | R$ 7,720,557.36 |
| **Modo** | **Local (1 worker)** |
| **Tempo estimado** | **~15-30s** |

### Teste 2: 1M transa√ß√µes (Cluster 5 Workers)
| M√©trica | Valor |
|---------|-------|
| Transa√ß√µes | **1,000,000** |
| Clientes | 10,000 |
| Dados Raw | **216 MB** |
| Dados Bronze | 54 MB |
| Dados Silver | 56 MB |
| Dados Gold | 60 MB |
| Fraudes | 49,603 (5.0%) |
| **Modo** | **Cluster (5 workers √ó 2 cores)** |
| **Tempo total** | **~2min 30s** |

### üìä Estat√≠sticas de Fraude Detalhadas (1M transa√ß√µes)

| N√≠vel de Risco | Quantidade | % | Valor Total | Ticket M√©dio |
|----------------|------------|---|-------------|--------------|
| üî¥ Alto Risco | 8,259 | 0.83% | R$ 24.6M | R$ 2,982.87 |
| üü† Risco M√©dio | 200,235 | 20.02% | R$ 164.5M | R$ 821.38 |
| üü¢ Baixo Risco | 791,506 | 79.15% | R$ 201.7M | R$ 254.82 |
| **TOTAL** | **1,000,000** | 100% | **R$ 390.8M** | - |

### üîÑ Comparativo: Antes vs Depois do Cluster

| M√©trica | Antes (Local) | Depois (5 Workers) | Melhoria |
|---------|---------------|---------------------|----------|
| Transa√ß√µes | 50,000 | 1,000,000 | **20√ó mais** |
| Dados Raw | 11 MB | 216 MB | **20√ó mais** |
| Workers | 1 | 5 | **5√ó mais** |
| Cores | 1 | 10 | **10√ó mais** |
| RAM | ~1 GB | 15 GB | **15√ó mais** |
| Tempo | ~30s | ~150s | **5√ó mais** |
| **Throughput** | **~1.7k/s** | **~6.7k/s** | **4√ó mais r√°pido** |

> **Conclus√£o:** Com 20√ó mais dados, o tempo aumentou apenas 5√ó. Isso demonstra **escalabilidade sub-linear** gra√ßas ao processamento distribu√≠do.

### Tempo de Execu√ß√£o por Camada (1M transa√ß√µes)
| Camada | Tempo |
|--------|-------|
| üî∂ Bronze | 37s |
| ‚ö™ Silver | 46s |
| ü•á Gold | 34s |
| üö® Fraud Detection | 33s |
| **TOTAL** | **~2min 30s** |

### Compress√£o Parquet
| Camada | Formato | Tamanho | Compress√£o |
|--------|---------|---------|------------|
| Raw | JSON | 216 MB | - |
| Bronze | Parquet | 54 MB | 75% |
| Silver | Parquet | 56 MB | 74% |
| Gold | Parquet | 60 MB | 72% |

### Escalabilidade
| M√©trica | 50k ‚Üí 1M | Resultado |
|---------|----------|-----------|
| Dados | 20√ó mais | ‚úÖ |
| Tempo | 5√ó mais | ‚úÖ Sub-linear! |

---

## ‚úÖ CHECKPOINTS COMPLETADOS

### Checkpoint 1-5: Infraestrutura Docker ‚úÖ
- [x] docker-compose.yml criado com 6 servi√ßos
- [x] PostgreSQL 16 (porta 5432)
- [x] MinIO (portas 9002/9003) - bucket "fraud-data" criado via UI
- [x] Zookeeper 7.5.0 + Kafka 7.5.0 (porta 9092) - topic "transactions" criado
- [x] Spark Master + Worker apache/spark:3.5.3 (UI porta 8081)
- [x] Todos containers rodando

### Checkpoint 6-7: Gera√ß√£o de Dados ‚úÖ
- [x] scripts/generate_data.py criado
- [x] Fun√ß√µes: generate_customers(), generate_transactions(), save_to_json()
- [x] Formato: JSON Lines (um registro por linha) - corrigido durante a sess√£o
- [x] Dados gerados: 100 clientes + 500 transa√ß√µes (~5% fraude = ~25 fraudes)

### Checkpoint 8: Bronze Layer ‚úÖ
- [x] spark/jobs/bronze_layer.py criado
- [x] PySpark 4.0.1 instalado no venv (compat√≠vel com Spark 4.0.1 do sistema)
- [x] Convers√£o JSON ‚Üí Parquet funcionando
- [x] Metadados adicionados: _ingestion_time, _process_date
- [x] Output: data/bronze/customers/ e data/bronze/transactions/

### Checkpoint 9: Silver Layer ‚úÖ
- [x] spark/jobs/silver_layer.py criado
- [x] Limpeza de dados: dropDuplicates(), dropna()
- [x] Padroniza√ß√£o: lower(), trim() para emails e nomes
- [x] Filtros: apenas transa√ß√µes com amount > 0
- [x] Metadados: _silver_timestamp, processed_date
- [x] Output: data/silver/customers/ e data/silver/transactions/

**Conceitos aprendidos:**
- Fun√ß√µes Python: defini√ß√£o e chamada, par√¢metros vs vari√°veis globais
- `if __name__ == "__main__":` - c√≥digo que s√≥ roda quando executas o arquivo diretamente
- Transforma√ß√µes Spark: withColumn(), filter(), dropDuplicates(), dropna()

### Checkpoint 10: Gold Layer ‚úÖ
- [x] spark/jobs/gold_layer.py criado
- [x] customer_summary: total_gasto, qtd_transacoes, ticket_medio, qtd_fraudes por cliente
- [x] fraud_summary: estat√≠sticas gerais de fraude (19 fraudes, R$ 62.260,93, 3.8%)
- [x] Output: data/gold/customer_summary/ e data/gold/fraud_summary/

**Conceitos aprendidos:**
- Agrega√ß√µes: groupBy().agg(), sum(), count(), avg()
- .alias() para nomear colunas resultantes
- round() do Python vs spark_round() do Spark (tipos diferentes!)
- collect() - trazer dados do Spark para Python (usar com cuidado em Big Data!)
- .cast("int") para converter boolean para inteiro

### Checkpoint 11: Fraud Detection ‚úÖ
- [x] spark/jobs/fraud_detection.py criado
- [x] Regra 1: Valor alto (amount > R$ 1.000) ‚Üí flag high_value
- [x] Regra 2: Hor√°rio suspeito (2h-5h da manh√£) ‚Üí flag suspicious_hour
- [x] Regra 3: N√≠veis de risco combinados (Alto/M√©dio/Baixo)
- [x] Output particionado por risk_level: data/gold/fraud_detection/
- [x] Resultados: 4 Alto Risco, 83 M√©dio Risco, 413 Baixo Risco

**Conceitos aprendidos:**
- when()/otherwise() - l√≥gica condicional em colunas Spark
- col() - referenciar colunas pelo nome para opera√ß√µes
- withColumn() - criar ou substituir colunas (DataFrames s√£o imut√°veis)
- hour() e to_timestamp() - extrair hora de um timestamp
- partitionBy() - salvar dados particionados em pastas separadas

### Checkpoint 11.5: PostgreSQL Integration ‚úÖ
- [x] spark/jobs/load_to_postgres.py criado
- [x] JDBC driver baixado (postgresql-42.7.4.jar)
- [x] Conex√£o Spark ‚Üí PostgreSQL funcionando
- [x] Tabelas criadas: fraud_transactions, fraud_summary

### Checkpoint 11.6: MinIO como Data Lake ‚úÖ
- [x] spark/jobs/bronze_to_minio.py criado
- [x] JARs Hadoop-AWS configurados
- [x] Escrita s3a://fraud-data/bronze/ funcionando
- [x] Dados vis√≠veis no MinIO Console

### Checkpoint 11.7: Scale Data (Cluster Distribu√≠do) ‚úÖ
- [x] Cluster Spark: 1 Master + 5 Workers
- [x] Cada Worker: 2 cores, 3GB RAM (total: 10 cores, 15GB)
- [x] Configura√ß√£o 128MB partitions em todos os jobs
- [x] Caminhos din√¢micos (/data vs data) para Docker/Local
- [x] argparse no generate_data.py (--customers, --transactions, --fraud-rate)
- [x] Teste com 1M de transa√ß√µes: ~2min 30s no cluster
- [x] Escalabilidade sub-linear comprovada (20√ó dados = 5√ó tempo)

**Conceitos aprendidos:**
- spark.sql.files.maxPartitionBytes - tamanho das parti√ß√µes
- SPARK_WORKER_CORES e SPARK_WORKER_MEMORY - configura√ß√£o de workers
- Diferen√ßa entre spark-submit local vs cluster (--master spark://...)
- Permiss√µes Docker (chmod 777 para volume mounts)
- Escalabilidade horizontal vs vertical
- Compress√£o Parquet (~75% menor que JSON)

---

## üéØ ARQUITETURA OBJETIVO

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ARQUITETURA LAKEHOUSE COMPLETA                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                             ‚îÇ
‚îÇ  [ShadowTraffic] ‚îÄ‚îÄ‚ñ∫ [Kafka] ‚îÄ‚îÄ‚ñ∫ [Spark Streaming] ‚îÄ‚îÄ‚ñ∫ [MinIO Data Lake]   ‚îÇ
‚îÇ                         ‚îÇ              ‚îÇ                      ‚îÇ             ‚îÇ
‚îÇ                    customers      ETL Jobs              Bronze/Silver/Gold  ‚îÇ
‚îÇ                    orders                                     ‚îÇ             ‚îÇ
‚îÇ                                                               ‚ñº             ‚îÇ
‚îÇ                                                        [PostgreSQL]         ‚îÇ
‚îÇ                                                         Data Warehouse      ‚îÇ
‚îÇ                                                               ‚îÇ             ‚îÇ
‚îÇ                                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ                                                    ‚îÇ                     ‚îÇ  ‚îÇ
‚îÇ                                               [Metabase]           [Streamlit]‚îÇ
‚îÇ                                               Dashboards           Apps      ‚îÇ
‚îÇ                                                    ‚îÇ                     ‚îÇ  ‚îÇ
‚îÇ                                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                               ‚îÇ             ‚îÇ
‚îÇ                                                          [Traefik]          ‚îÇ
‚îÇ                                                        Reverse Proxy        ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### VPS OVH Specs:
- **vCores:** 8
- **RAM:** 24 GB
- **Disco:** 200 GB
- **Objetivo:** Processar ~50 GB de dados

### üìà Proje√ß√£o para Escalas Maiores

| Volume | Transa√ß√µes | Tamanho Raw | Tempo Real | Throughput | Status |
|--------|------------|-------------|------------|------------|--------|
| ‚úÖ Teste 1 | 50K | 11 MB | ~30s | 1.7k/s | Conclu√≠do (Local) |
| ‚úÖ Teste 2 | 1M | 216 MB | ~2.5min | 6.7k/s | Conclu√≠do (Cluster) |
| ‚úÖ **Teste 3** | **5M** | **1.1 GB** | **~3min** | **28k/s** | **Conclu√≠do!** |
| üìã Teste 4 | 10M | ~2.2 GB | ~6min | ~28k/s | Pr√≥ximo |
| üìã Teste 5 | 50M | ~11 GB | ~30min | ~28k/s | Planejado |
| üìã Final | 230M | ~50 GB | ~2-3h | ~28k/s | Objetivo |

### ‚úÖ Teste 3: 5M transa√ß√µes (Cluster 5 Workers)
| M√©trica | Valor |
|---------|-------|
| Transa√ß√µes | **5,000,000** |
| Clientes | 50,000 |
| Dados Raw | **1.1 GB** |
| Dados Bronze | 417 MB |
| Dados Silver | 428 MB |
| Dados Gold | 430 MB |
| Fraudes | 250,307 (5.0%) |
| **Tempo total** | **~3 min** |
| **Throughput** | **~28k transa√ß√µes/segundo** |

### üöÄ Evolu√ß√£o do Throughput
| Configura√ß√£o | Transa√ß√µes | Tempo | Throughput | Melhoria |
|--------------|------------|-------|------------|----------|
| Local (1 core) | 50K | ~30s | 1,700/s | baseline |
| Cluster (10 cores) - 1M | 1M | 150s | 6,700/s | **4√ó** |
| Cluster (10 cores) - 5M | 5M | 180s | **28,000/s** | **16√ó** |

---

## üîú CHECKPOINTS PENDENTES

### Fase 1: Completar Infraestrutura de Dados

#### Checkpoint 11.8: MinIO como Storage Principal
**Objetivo:** Migrar todo o pipeline para usar MinIO
**Mudan√ßa:** Todos os jobs leem/escrevem em s3a://fraud-data/

#### Checkpoint 11.9: Escalar para 10M+ transa√ß√µes
**Objetivo:** Testar limites do cluster

| Etapa | Volume | Transa√ß√µes | Status |
|-------|--------|------------|--------|
| ‚úÖ Teste 1 | 11 MB | 50k | Conclu√≠do |
| ‚úÖ Teste 2 | 216 MB | 1M | Conclu√≠do |
| Teste 3 | ~2 GB | 10M | Pendente |
| Teste 4 | ~20 GB | 100M | Pendente |

### Fase 2: Streaming Real

#### Checkpoint 12: ShadowTraffic + Kafka Producer
**Objetivo:** Gerar dados em streaming para Kafka
**Arquivo:** shadowtraffic/config.json

Conceitos:
- ShadowTraffic configura√ß√£o
- Kafka topics: customers, orders
- Gera√ß√£o cont√≠nua de dados

#### Checkpoint 13: Spark Structured Streaming
**Objetivo:** Consumir Kafka em tempo real
**Arquivo:** spark/jobs/streaming_etl.py

Conceitos:
- readStream vs read
- writeStream vs write
- Trigger, watermark, checkpointing

#### Checkpoint 14: Pipeline Streaming Completo
**Objetivo:** Kafka ‚Üí Bronze ‚Üí Silver ‚Üí Gold em tempo real

### Fase 3: Visualiza√ß√£o

#### Checkpoint 15: Metabase
**Objetivo:** Dashboards de BI conectados ao PostgreSQL

Dashboards:
- Fraudes por per√≠odo
- Customer Lifetime Value
- Sales by city/product

#### Checkpoint 16: Streamlit
**Objetivo:** App interativo de an√°lise

Features:
- Filtros din√¢micos
- Alertas de fraude
- Explora√ß√£o de dados

#### Checkpoint 17: Traefik
**Objetivo:** Reverse proxy com dom√≠nios

Conceitos:
- Routing por dom√≠nio
- HTTPS/SSL
- Load balancing

---

## üõ†Ô∏è AMBIENTE T√âCNICO

```yaml
Sistema: Ubuntu 25.04 (plucky) - VPS
IP: 54.36.100.35
Shell: zsh

Python: 3.13
PySpark: 4.0.1
Spark: 4.0.1 (SPARK_HOME=/home/ubuntu/Estudos/apache-spark/spark-4.0.1-bin-hadoop3)
Java: OpenJDK 17

Docker: docker.io (n√£o docker-ce - incompat√≠vel com Ubuntu 25.04)
```

### Comandos para iniciar sess√£o:
```bash
cd ~/Estudos/1_projeto_bank_Fraud_detection_data_pipeline
source venv/bin/activate
docker compose ps  # verificar containers
```

---

## üìÅ ESTRUTURA DO PROJETO

```
1_projeto_bank_Fraud_detection_data_pipeline/
‚îú‚îÄ‚îÄ LEARNING_PROGRESS.md    ‚Üê Este arquivo (contexto para IA)
‚îú‚îÄ‚îÄ docker-compose.yml      ‚Üê Infraestrutura (6 servi√ßos)
‚îú‚îÄ‚îÄ venv/                   ‚Üê Virtual environment Python
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ generate_data.py    ‚Üê Gerador de dados sint√©ticos
‚îú‚îÄ‚îÄ spark/
‚îÇ   ‚îî‚îÄ‚îÄ jobs/
‚îÇ       ‚îú‚îÄ‚îÄ bronze_layer.py ‚Üê JSON ‚Üí Parquet ‚úÖ
‚îÇ       ‚îú‚îÄ‚îÄ silver_layer.py ‚Üê Limpeza de dados ‚úÖ
‚îÇ       ‚îú‚îÄ‚îÄ gold_layer.py   ‚Üê Agrega√ß√µes ‚úÖ
‚îÇ       ‚îî‚îÄ‚îÄ fraud_detection.py ‚Üê Regras de fraude ‚úÖ
‚îî‚îÄ‚îÄ data/
    ‚îú‚îÄ‚îÄ raw/                ‚Üê JSON Lines (origem)
    ‚îÇ   ‚îú‚îÄ‚îÄ customers.json
    ‚îÇ   ‚îî‚îÄ‚îÄ transactions.json
    ‚îú‚îÄ‚îÄ bronze/             ‚Üê Parquet bruto ‚úÖ
    ‚îÇ   ‚îú‚îÄ‚îÄ customers/
    ‚îÇ   ‚îî‚îÄ‚îÄ transactions/
    ‚îú‚îÄ‚îÄ silver/             ‚Üê Parquet limpo ‚úÖ
    ‚îÇ   ‚îú‚îÄ‚îÄ customers/
    ‚îÇ   ‚îî‚îÄ‚îÄ transactions/
    ‚îî‚îÄ‚îÄ gold/               ‚Üê Parquet agregado ‚úÖ
        ‚îú‚îÄ‚îÄ customer_summary/
        ‚îú‚îÄ‚îÄ fraud_summary/
        ‚îî‚îÄ‚îÄ fraud_detection/  ‚Üê Particionado por risk_level ‚úÖ
```

---

## üìù METODOLOGIA DE ENSINO

### Regras para a IA:

1. **N√ÉO escreva c√≥digo automaticamente** - guie o aluno
2. **Explique o conceito primeiro** (teoria breve)
3. **Mostre o c√≥digo a digitar** em blocos pequenos
4. **Espere o aluno confirmar** que digitou
5. **Execute junto** e analise o resultado
6. **Se der erro**, explique o porqu√™ antes de corrigir

### Formato de aula:
```
## üìù AULA X.Y: [Nome do Conceito]

[Explica√ß√£o te√≥rica em 2-3 par√°grafos]

---

Agora digita no arquivo [nome]:

```python
# c√≥digo aqui
```

Me avisa quando terminar!
```

---

## üêõ PROBLEMAS RESOLVIDOS (para refer√™ncia)

| Problema | Causa | Solu√ß√£o |
|----------|-------|---------|
| docker-ce n√£o instala | Ubuntu 25.04 incompat√≠vel | Usar docker.io nativo |
| Porta 9000 ocupada | Portainer usando | MinIO mudou para 9002/9003 |
| Porta 8080 ocupada | Open-WebUI usando | Spark UI mudou para 8081 |
| Bitnami Spark n√£o funciona | Imagens pagas agora | Usar apache/spark oficial |
| pip n√£o funciona | PEP 668 (externally-managed) | Criar venv |
| PySpark 3.5.3 erro | SPARK_HOME aponta p/ 4.0.1 | Instalar PySpark 4.0.1 |
| JSON corrupt record | Formato array [...] | Mudar para JSON Lines |

---

## üöÄ COMO CONTINUAR

Quando o aluno voltar, dizer:

> "Bem-vindo de volta! Vi no LEARNING_PROGRESS.md que completaste o Bronze Layer.
> Pronto para come√ßar a Silver Layer? Vamos limpar e validar os dados!"

Primeiro passo da pr√≥xima sess√£o:
1. Verificar se containers est√£o rodando: `docker compose ps`
2. Ativar venv: `source venv/bin/activate`
3. Verificar dados bronze existem: `ls data/bronze/`
4. Come√ßar explica√ß√£o da Silver Layer

---

*√öltima atualiza√ß√£o: 2025-11-29 15:00*
